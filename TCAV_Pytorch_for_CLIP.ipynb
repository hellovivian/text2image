{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac679899",
   "metadata": {},
   "source": [
    "# Notebook Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4f06f1",
   "metadata": {},
   "source": [
    "Implement TCAV using Pytorch for CLIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a8b248",
   "metadata": {},
   "source": [
    "# Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32277860",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/openai/CLIP\n",
    "# authors Katherine Crowson (https://github.com/crowsonkb, https://twitter.com/RiversHaveWings), nerdyrodent\n",
    "# authors vivian\n",
    "# The original BigGAN+CLIP method was by https://twitter.com/advadnoun\n",
    "import threading\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import math\n",
    "import random\n",
    "from urllib.request import urlopen\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('taming-transformers')\n",
    "from omegaconf import OmegaConf\n",
    "from taming.models import cond_transformer, vqgan\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as TF\n",
    "from torch.cuda import get_device_properties\n",
    "torch.backends.cudnn.benchmark = False\n",
    "from torch_optimizer import DiffGrad, AdamP, RAdam\n",
    "from CLIP import clip\n",
    "import kornia.augmentation as K\n",
    "import imageio\n",
    "from PIL import ImageFile, Image, PngImagePlugin, ImageChops\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from subprocess import Popen, PIPE\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3033a3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RN50', 'RN101', 'RN50x4', 'RN50x16', 'ViT-B/32', 'ViT-B/16']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip.available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6fad75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3410ac22",
   "metadata": {},
   "source": [
    "# Load CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e379417",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, preprocess = clip.load('ViT-B/32', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d901147",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hook:\n",
    "    \"\"\"Attaches to a module and records its activations and gradients.\"\"\"\n",
    "\n",
    "    def __init__(self, module: nn.Module):\n",
    "        self.data = None\n",
    "        self.hook = module.register_forward_hook(self.save_grad)\n",
    "        \n",
    "    def save_grad(self, module, input, output):\n",
    "        self.data = output\n",
    "        output.requires_grad_(True)\n",
    "        output.retain_grad()\n",
    "        \n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_value, exc_traceback):\n",
    "        self.hook.remove()\n",
    "        \n",
    "    @property\n",
    "    def activation(self) -> torch.Tensor:\n",
    "        return self.data\n",
    "    \n",
    "    @property\n",
    "    def gradient(self) -> torch.Tensor:\n",
    "        return self.data.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da4b2121",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping():\n",
    "    \"\"\"\n",
    "    Early stopping to stop the training when the loss does not improve after\n",
    "    certain epochs.\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        \"\"\"\n",
    "        :param patience: how many epochs to wait before stopping when loss is\n",
    "               not improving\n",
    "        :param min_delta: minimum difference between new loss and old loss for\n",
    "               new loss to be considered as an improvement\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss == None:\n",
    "            self.best_loss = val_loss\n",
    "        elif self.best_loss - val_loss > self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            # reset counter if validation loss improves\n",
    "            self.counter = 0\n",
    "        elif self.best_loss - val_loss < self.min_delta:\n",
    "            self.counter += 1\n",
    "            print(f\"INFO: Early stopping counter {self.counter} of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                print('INFO: Early stopping')\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1cac60",
   "metadata": {},
   "source": [
    "# Register hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57a45a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assist from https://web.stanford.edu/~nanbhas/blog/forward-hooks-pytorch/\n",
    "activations = {}\n",
    "gradients = {}\n",
    "def getActivation(name):\n",
    "    # the hook signature \n",
    "    def hook(model, input, output):\n",
    "        \n",
    "        output.requires_grad_(True)\n",
    "        output.retain_grad()\n",
    "        gradients[name] = output.grad\n",
    "        activations[name] = output.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "971a39aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hooks = []\n",
    "layers = np.concatenate([[model.visual.conv1], model.visual.transformer.resblocks[1::2]])\n",
    "layernames = np.concatenate([['layer0'], [f'layer{i}' for i in range(1,13,2)]], dtype=str)\n",
    "for l, n in zip(layers, layernames):\n",
    "    hooks.append(l.register_forward_hook(getActivation(n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e5ace60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# possibly needed in future if using larger dataset w/ dataloader\n",
    "\n",
    "# embedding_list = np.empty(layers.shape, dtype=object)\n",
    "# for i in range(len(embedding_list)):\n",
    "#     embedding_list[i] = []\n",
    "# for num_layer, name  in enumerate(layernames):\n",
    "#     embedding_list[num_layer].append(activations[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73aa86e9",
   "metadata": {},
   "source": [
    "# Image Encoding"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c1f0b5dc",
   "metadata": {},
   "source": [
    "image = preprocess(Image.open(\"square.jpg\")).unsqueeze(0).to(device)\n",
    "image_features = model.encode_image(image.cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b0f015",
   "metadata": {},
   "source": [
    "# Text Encoding"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ad6e1007",
   "metadata": {},
   "source": [
    "prompt = \"square shaped cat\"\n",
    "txt, weight, stop = split_prompt(prompt)\n",
    "\n",
    "text_features = model.encode_text(clip.tokenize(txt).to(device)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cca0b121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_tensors(img_filename, img_dir=\"\"):\n",
    "    image = preprocess(Image.open(img_dir + img_filename)).unsqueeze(0).to(device)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0045a045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_images(img_filename, img_dir=\"\"):\n",
    "    image = preprocess(Image.open(img_dir + img_filename)).unsqueeze(0).to(device)\n",
    "\n",
    "    image_features = model.encode_image(image.cuda())\n",
    "    return image_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b4b54b",
   "metadata": {},
   "source": [
    "Load an example image"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5747d983",
   "metadata": {},
   "source": [
    "# PIL.Image.open\n",
    "# concept_filenames[0]\n",
    "\n",
    "Image.open('tcav/concepts/striped/striped_0086.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811a5736",
   "metadata": {},
   "source": [
    "# Define Linear Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a126a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearClassifier(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear1 = torch.nn.Linear(num_features, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, input_x):\n",
    "        x = self.linear1(input_x)\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84db4f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_filenames = os.listdir('tcav/concepts/striped')\n",
    "negative_filenames = os.listdir('tcav/concepts/random_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "015a3200",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_concept = [encode_images(filename, 'tcav/concepts/striped/') for filename in positive_filenames]\n",
    "#positive_concept = torch.vstack(positive_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f923dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_concept = [encode_images(filename, 'tcav/concepts/random_0/') for filename in negative_filenames]\n",
    "#negative_concept = torch.vstack(negative_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "065e7800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_concept = positive_concept + negative_concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4591bdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "positive_concepts = torch.vstack(positive_concept)\n",
    "negative_concepts = torch.vstack(negative_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3226efc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_img_tensors = [get_img_tensors(img,'tcav/concepts/striped/') for img in positive_filenames]\n",
    "positive_img_tensors = torch.vstack(positive_img_tensors)\n",
    "negative_img_tensors = [get_img_tensors(img,'tcav/concepts/random_0/') for img in negative_filenames]\n",
    "negative_img_tensors = torch.vstack(negative_img_tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5b3ca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_img_tensors = torch.vstack([positive_img_tensors, negative_img_tensors])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f60c49",
   "metadata": {},
   "source": [
    "# Collect features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06ac35f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.encode_image(all_img_tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53ac0fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_inputs = [\"zebra\"] * len(positive_concept) + [\"not zebra\"] * len(negative_concept)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3d5ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_inputs = [clip.tokenize([text_input]).to(device) for text_input in text_inputs]\n",
    "target = torch.vstack([model.encode_text(text_input).float() for text_input in text_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a26031a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_layer_gradients = {}\n",
    "all_layer_activations = {}\n",
    "for layer, name in zip(layers, layernames):\n",
    "    layer_gradients = []\n",
    "    layer_activations = []\n",
    "    with Hook(layer) as hook:\n",
    "\n",
    "        # Do a forward and backward pass.\n",
    "        output = model.encode_image(all_img_tensors)\n",
    "        output.backward(target)\n",
    "\n",
    "        grad = hook.gradient.float()\n",
    "        act = hook.activation.float()\n",
    "        layer_gradients.append(grad)\n",
    "        layer_activations.append(act)\n",
    "    all_layer_gradients[name] = layer_gradients\n",
    "    all_layer_activations[name] = layer_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dd031139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"all_layer_gradients.pkl\",\"wb\") as f:\n",
    "    pickle.dump(all_layer_gradients,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f691e309",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_layer_activations.pkl\",\"wb\") as f:\n",
    "    pickle.dump(all_layer_activations,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618b4f69",
   "metadata": {},
   "source": [
    "# Process features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "65e7cfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data =  []\n",
    "linear_classifier_sizes = []\n",
    "for key in all_layer_gradients.keys():\n",
    "    training_data.append(all_layer_gradients[key][0].view(85,-1))\n",
    "    linear_classifier_sizes.append(all_layer_gradients[key][0].view(85,-1).shape[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd8e374",
   "metadata": {},
   "source": [
    "# Assemble training data for all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc730e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_labels = torch.tensor(positive_concepts.shape[0] * [1])\n",
    "negative_labels = torch.tensor(negative_concepts.shape[0] * [0])\n",
    "# training_data = torch.vstack([positive_concepts, negative_concepts])\n",
    "class_labels = torch.cat([positive_labels, negative_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f107aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Assemble validation data for all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c6002583",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train = int( train.shape[0] * 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7d57a8d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x7f1b65abe670>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "af4db558",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [ len_train, train.shape[0] -len_train] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ba30f3",
   "metadata": {},
   "source": [
    "# Create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "624b050c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "dataloaders = []\n",
    "val_dataloaders = []\n",
    "for train in training_data:\n",
    "    dataset = TensorDataset(train, class_labels)\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [ len_train, train.shape[0] -len_train])\n",
    "    loader = DataLoader(train_dataset, batch_size=2,\n",
    "                    pin_memory=False, shuffle=True)\n",
    "    val_loader = DataLoader(train_dataset, batch_size=2,\n",
    "                    pin_memory=False, shuffle=True)\n",
    "    dataloaders.append(loader)\n",
    "    val_dataloaders.append(val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b62cd62",
   "metadata": {},
   "source": [
    "# Create classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cdc0def2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = []\n",
    "for classifier_size in linear_classifier_sizes:\n",
    "    \n",
    "    classifiers.append(LinearClassifier(classifier_size))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1116f271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(classifier, dataloader, val_dataloader):\n",
    "    clf = classifier.cuda()\n",
    "    early_stopping = EarlyStopping()\n",
    "    optimizer = torch.optim.SGD(clf.parameters(), lr=0.001)\n",
    "    for it in range(n_epochs):\n",
    "        for i, data in enumerate(dataloader,0):\n",
    "            inputs, labels = data\n",
    "            inputs = Variable(inputs, requires_grad=True)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = clf(inputs.cuda().float())\n",
    "\n",
    "            loss = criterion(outputs.cuda().float(), labels.cuda().reshape(-1,1).float())\n",
    "            loss.backward()\n",
    "            \n",
    "            \n",
    "            optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(val_dataloader,0):\n",
    "                inputs, labels = data\n",
    "                inputs = Variable(inputs)\n",
    "                outputs = clf(inputs.cuda().float())\n",
    "\n",
    "                loss = criterion(outputs.cuda().float(), labels.cuda().reshape(-1,1).float()) \n",
    "        \n",
    "            early_stopping(loss)\n",
    "        if it % 10 == 0:\n",
    "            pass\n",
    "        if early_stopping.early_stop:\n",
    "            print(loss)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "37b30d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torch.utils.data.dataloader.DataLoader at 0x7f1b65ade9a0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f1b64662850>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f1b64662c40>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f1b64662820>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f1b64662610>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f1b65a7fcd0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f1b65a854c0>]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9248d80",
   "metadata": {},
   "source": [
    "# Training Classifiers Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c223ded7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearClassifier(\n",
      "  (linear1): Linear(in_features=37632, out_features=1, bias=True)\n",
      ")\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 4 of 5\n",
      "INFO: Early stopping counter 5 of 5\n",
      "INFO: Early stopping\n",
      "tensor(0.0622, device='cuda:0')\n",
      "trained a classifier\n",
      "LinearClassifier(\n",
      "  (linear1): Linear(in_features=38400, out_features=1, bias=True)\n",
      ")\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 4 of 5\n",
      "INFO: Early stopping counter 5 of 5\n",
      "INFO: Early stopping\n",
      "tensor(0.4219, device='cuda:0')\n",
      "trained a classifier\n",
      "LinearClassifier(\n",
      "  (linear1): Linear(in_features=38400, out_features=1, bias=True)\n",
      ")\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 4 of 5\n",
      "INFO: Early stopping counter 5 of 5\n",
      "INFO: Early stopping\n",
      "tensor(0.4266, device='cuda:0')\n",
      "trained a classifier\n",
      "LinearClassifier(\n",
      "  (linear1): Linear(in_features=38400, out_features=1, bias=True)\n",
      ")\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 4 of 5\n",
      "INFO: Early stopping counter 5 of 5\n",
      "INFO: Early stopping\n",
      "tensor(0.4683, device='cuda:0')\n",
      "trained a classifier\n",
      "LinearClassifier(\n",
      "  (linear1): Linear(in_features=38400, out_features=1, bias=True)\n",
      ")\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 4 of 5\n",
      "INFO: Early stopping counter 5 of 5\n",
      "INFO: Early stopping\n",
      "tensor(0.5918, device='cuda:0')\n",
      "trained a classifier\n",
      "LinearClassifier(\n",
      "  (linear1): Linear(in_features=38400, out_features=1, bias=True)\n",
      ")\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 4 of 5\n",
      "INFO: Early stopping counter 5 of 5\n",
      "INFO: Early stopping\n",
      "tensor(0.7382, device='cuda:0')\n",
      "trained a classifier\n",
      "LinearClassifier(\n",
      "  (linear1): Linear(in_features=38400, out_features=1, bias=True)\n",
      ")\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 4 of 5\n",
      "INFO: Early stopping counter 5 of 5\n",
      "INFO: Early stopping\n",
      "tensor(0.7368, device='cuda:0')\n",
      "trained a classifier\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "for classifier, dataloader, val_dataloader in zip(classifiers, dataloaders, val_dataloaders):\n",
    "    print(classifier)\n",
    "    train_classifier(classifier, dataloader,val_dataloader)\n",
    "    print(\"trained a classifier\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "895c8c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"cached_classifiers.pkl\",\"wb\") as f:\n",
    "    pickle.dump(classifiers,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a01bbdb",
   "metadata": {},
   "source": [
    "# Get orthogonal vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2164907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_orthogonal_vector(classifier, classifier_size):\n",
    "    weight, bias = [param for param in classifier.parameters()]\n",
    "    cav_vector = weight.squeeze().cpu().detach().numpy()\n",
    "    orthonormal_vector = np.random.randn(classifier_size)  # take a random vector\n",
    "    orthonormal_vector -= orthonormal_vector.dot(cav_vector) * cav_vector / np.linalg.norm(cav_vector)**2\n",
    "    orthonormal_vector /= np.linalg.norm(orthonormal_vector) \n",
    "    return orthonormal_vector, cav_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e831105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cavs = [get_orthogonal_vector(classifier, classifier_size) for classifier, classifier_size in zip(classifiers, linear_classifier_sizes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599946ba",
   "metadata": {},
   "source": [
    "# Check orthogonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cb4f6821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.1899124090566926e-10,\n",
       " 5.035230956143555e-10,\n",
       " 4.686241134727043e-10,\n",
       " 2.495054813797526e-11,\n",
       " -3.7813513171364166e-11,\n",
       " -8.493784451821251e-12,\n",
       " 5.064932414450274e-11]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.dot(orthonormal_vector,cav_vector) for orthonormal_vector, cav_vector in cavs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b9e46e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(3.1576, device='cuda:0')\n",
      "1\n",
      "tensor(0.9237, device='cuda:0')\n",
      "2\n",
      "tensor(2.2916, device='cuda:0')\n",
      "3\n",
      "tensor(1.3362, device='cuda:0')\n",
      "4\n",
      "tensor(0.2581, device='cuda:0')\n",
      "5\n",
      "tensor(0.9651, device='cuda:0')\n",
      "6\n",
      "tensor(-0.2086, device='cuda:0')\n",
      "7\n",
      "tensor(3.5177, device='cuda:0')\n",
      "8\n",
      "tensor(1.9983, device='cuda:0')\n",
      "9\n",
      "tensor(2.2666, device='cuda:0')\n",
      "10\n",
      "tensor(2.7793, device='cuda:0')\n",
      "11\n",
      "tensor(1.3769, device='cuda:0')\n",
      "12\n",
      "tensor(2.6567, device='cuda:0')\n",
      "13\n",
      "tensor(3.3030, device='cuda:0')\n",
      "14\n",
      "tensor(-0.0600, device='cuda:0')\n",
      "15\n",
      "tensor(1.2082, device='cuda:0')\n",
      "16\n",
      "tensor(2.0105, device='cuda:0')\n",
      "17\n",
      "tensor(2.5700, device='cuda:0')\n",
      "18\n",
      "tensor(3.3431, device='cuda:0')\n",
      "19\n",
      "tensor(-0.1400, device='cuda:0')\n",
      "20\n",
      "tensor(1.3527, device='cuda:0')\n",
      "21\n",
      "tensor(1.8662, device='cuda:0')\n",
      "22\n",
      "tensor(-0.1866, device='cuda:0')\n",
      "23\n",
      "tensor(2.8525, device='cuda:0')\n",
      "24\n",
      "tensor(0.3161, device='cuda:0')\n",
      "25\n",
      "tensor(0.6625, device='cuda:0')\n",
      "26\n",
      "tensor(4.6133, device='cuda:0')\n",
      "27\n",
      "tensor(1.4815, device='cuda:0')\n",
      "28\n",
      "tensor(2.0673, device='cuda:0')\n",
      "29\n",
      "tensor(-1.6110, device='cuda:0')\n",
      "30\n",
      "tensor(-0.6313, device='cuda:0')\n",
      "31\n",
      "tensor(1.4852, device='cuda:0')\n",
      "32\n",
      "tensor(-0.9702, device='cuda:0')\n",
      "33\n",
      "tensor(1.2242, device='cuda:0')\n",
      "34\n",
      "tensor(0.7463, device='cuda:0')\n",
      "35\n",
      "tensor(-0.8205, device='cuda:0')\n",
      "36\n",
      "tensor(2.7733, device='cuda:0')\n",
      "37\n",
      "tensor(-0.8204, device='cuda:0')\n",
      "38\n",
      "tensor(-0.4126, device='cuda:0')\n",
      "39\n",
      "tensor(2.5732, device='cuda:0')\n",
      "40\n",
      "tensor(2.8331, device='cuda:0')\n",
      "41\n",
      "tensor(0.9775, device='cuda:0')\n",
      "42\n",
      "tensor(0.0273, device='cuda:0')\n",
      "43\n",
      "tensor(1.6418, device='cuda:0')\n",
      "44\n",
      "tensor(3.1546, device='cuda:0')\n",
      "45\n",
      "tensor(0.1406, device='cuda:0')\n",
      "46\n",
      "tensor(2.8893, device='cuda:0')\n",
      "47\n",
      "tensor(-0.6109, device='cuda:0')\n",
      "48\n",
      "tensor(1.7399, device='cuda:0')\n",
      "49\n",
      "tensor(1.3440, device='cuda:0')\n",
      "50\n",
      "tensor(0.4699, device='cuda:0')\n",
      "51\n",
      "tensor(-0.1536, device='cuda:0')\n",
      "52\n",
      "tensor(-1.2936, device='cuda:0')\n",
      "53\n",
      "tensor(-2.1460, device='cuda:0')\n",
      "54\n",
      "tensor(-2.5841, device='cuda:0')\n",
      "55\n",
      "tensor(-2.1245, device='cuda:0')\n",
      "56\n",
      "tensor(-1.6007, device='cuda:0')\n",
      "57\n",
      "tensor(-2.1399, device='cuda:0')\n",
      "58\n",
      "tensor(-1.6892, device='cuda:0')\n",
      "59\n",
      "tensor(-2.4402, device='cuda:0')\n",
      "60\n",
      "tensor(-1.4207, device='cuda:0')\n",
      "61\n",
      "tensor(-2.0596, device='cuda:0')\n",
      "62\n",
      "tensor(-1.7742, device='cuda:0')\n",
      "63\n",
      "tensor(-2.5629, device='cuda:0')\n",
      "64\n",
      "tensor(-1.1148, device='cuda:0')\n",
      "65\n",
      "tensor(-1.6726, device='cuda:0')\n",
      "66\n",
      "tensor(-1.4799, device='cuda:0')\n",
      "67\n",
      "tensor(-0.8493, device='cuda:0')\n",
      "68\n",
      "tensor(-2.1513, device='cuda:0')\n",
      "69\n",
      "tensor(-0.2904, device='cuda:0')\n",
      "70\n",
      "tensor(-1.0955, device='cuda:0')\n",
      "71\n",
      "tensor(-1.4819, device='cuda:0')\n",
      "72\n",
      "tensor(-1.3047, device='cuda:0')\n",
      "73\n",
      "tensor(1.4018, device='cuda:0')\n",
      "74\n",
      "tensor(-1.2494, device='cuda:0')\n",
      "75\n",
      "tensor(-2.3232, device='cuda:0')\n",
      "76\n",
      "tensor(-1.3106, device='cuda:0')\n",
      "77\n",
      "tensor(0.1450, device='cuda:0')\n",
      "78\n",
      "tensor(-2.8356, device='cuda:0')\n",
      "79\n",
      "tensor(-1.5138, device='cuda:0')\n",
      "80\n",
      "tensor(-0.6170, device='cuda:0')\n",
      "81\n",
      "tensor(0.7691, device='cuda:0')\n",
      "82\n",
      "tensor(-0.3107, device='cuda:0')\n",
      "83\n",
      "tensor(-2.4926, device='cuda:0')\n",
      "84\n",
      "tensor(-1.1642, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(85):\n",
    "    print(i)\n",
    "    print(torch.dot(all_layer_gradients['layer0'][0].view(85,-1)[i], torch.tensor(cavs[0][1]).cuda() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f9e039ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(5.6702, device='cuda:0')\n",
      "1\n",
      "tensor(3.9695, device='cuda:0')\n",
      "2\n",
      "tensor(1.4329, device='cuda:0')\n",
      "3\n",
      "tensor(0.9419, device='cuda:0')\n",
      "4\n",
      "tensor(0.0106, device='cuda:0')\n",
      "5\n",
      "tensor(1.2248, device='cuda:0')\n",
      "6\n",
      "tensor(-0.0851, device='cuda:0')\n",
      "7\n",
      "tensor(-0.1159, device='cuda:0')\n",
      "8\n",
      "tensor(0.7661, device='cuda:0')\n",
      "9\n",
      "tensor(0.6483, device='cuda:0')\n",
      "10\n",
      "tensor(0.0589, device='cuda:0')\n",
      "11\n",
      "tensor(0.8473, device='cuda:0')\n",
      "12\n",
      "tensor(0.0159, device='cuda:0')\n",
      "13\n",
      "tensor(0.9787, device='cuda:0')\n",
      "14\n",
      "tensor(1.2873, device='cuda:0')\n",
      "15\n",
      "tensor(0.5961, device='cuda:0')\n",
      "16\n",
      "tensor(0.4017, device='cuda:0')\n",
      "17\n",
      "tensor(-0.1369, device='cuda:0')\n",
      "18\n",
      "tensor(0.7163, device='cuda:0')\n",
      "19\n",
      "tensor(0.8413, device='cuda:0')\n",
      "20\n",
      "tensor(-0.0288, device='cuda:0')\n",
      "21\n",
      "tensor(0.6438, device='cuda:0')\n",
      "22\n",
      "tensor(0.8506, device='cuda:0')\n",
      "23\n",
      "tensor(0.8276, device='cuda:0')\n",
      "24\n",
      "tensor(0.8787, device='cuda:0')\n",
      "25\n",
      "tensor(1.0171, device='cuda:0')\n",
      "26\n",
      "tensor(1.0181, device='cuda:0')\n",
      "27\n",
      "tensor(-0.0558, device='cuda:0')\n",
      "28\n",
      "tensor(-0.0678, device='cuda:0')\n",
      "29\n",
      "tensor(0.5698, device='cuda:0')\n",
      "30\n",
      "tensor(0.7449, device='cuda:0')\n",
      "31\n",
      "tensor(-0.2129, device='cuda:0')\n",
      "32\n",
      "tensor(0.8939, device='cuda:0')\n",
      "33\n",
      "tensor(-0.0617, device='cuda:0')\n",
      "34\n",
      "tensor(0.4420, device='cuda:0')\n",
      "35\n",
      "tensor(0.8251, device='cuda:0')\n",
      "36\n",
      "tensor(0.7802, device='cuda:0')\n",
      "37\n",
      "tensor(0.8709, device='cuda:0')\n",
      "38\n",
      "tensor(0.7960, device='cuda:0')\n",
      "39\n",
      "tensor(0.7357, device='cuda:0')\n",
      "40\n",
      "tensor(-0.0484, device='cuda:0')\n",
      "41\n",
      "tensor(-0.0743, device='cuda:0')\n",
      "42\n",
      "tensor(0.7149, device='cuda:0')\n",
      "43\n",
      "tensor(1.0413, device='cuda:0')\n",
      "44\n",
      "tensor(-0.0377, device='cuda:0')\n",
      "45\n",
      "tensor(-0.1663, device='cuda:0')\n",
      "46\n",
      "tensor(-0.2460, device='cuda:0')\n",
      "47\n",
      "tensor(-0.0858, device='cuda:0')\n",
      "48\n",
      "tensor(0.7927, device='cuda:0')\n",
      "49\n",
      "tensor(0.9420, device='cuda:0')\n",
      "50\n",
      "tensor(-0.9635, device='cuda:0')\n",
      "51\n",
      "tensor(-1.0350, device='cuda:0')\n",
      "52\n",
      "tensor(-0.6800, device='cuda:0')\n",
      "53\n",
      "tensor(-0.7099, device='cuda:0')\n",
      "54\n",
      "tensor(0.0151, device='cuda:0')\n",
      "55\n",
      "tensor(-1.0709, device='cuda:0')\n",
      "56\n",
      "tensor(-0.4244, device='cuda:0')\n",
      "57\n",
      "tensor(-0.7772, device='cuda:0')\n",
      "58\n",
      "tensor(-1.0782, device='cuda:0')\n",
      "59\n",
      "tensor(-0.7267, device='cuda:0')\n",
      "60\n",
      "tensor(-0.9144, device='cuda:0')\n",
      "61\n",
      "tensor(-1.2305, device='cuda:0')\n",
      "62\n",
      "tensor(-0.6857, device='cuda:0')\n",
      "63\n",
      "tensor(-0.8735, device='cuda:0')\n",
      "64\n",
      "tensor(-0.8235, device='cuda:0')\n",
      "65\n",
      "tensor(-0.2781, device='cuda:0')\n",
      "66\n",
      "tensor(0.0222, device='cuda:0')\n",
      "67\n",
      "tensor(-1.2045, device='cuda:0')\n",
      "68\n",
      "tensor(-0.0633, device='cuda:0')\n",
      "69\n",
      "tensor(-0.6936, device='cuda:0')\n",
      "70\n",
      "tensor(-0.7994, device='cuda:0')\n",
      "71\n",
      "tensor(-0.7645, device='cuda:0')\n",
      "72\n",
      "tensor(-0.9656, device='cuda:0')\n",
      "73\n",
      "tensor(-1.8796, device='cuda:0')\n",
      "74\n",
      "tensor(-0.0593, device='cuda:0')\n",
      "75\n",
      "tensor(-1.3407, device='cuda:0')\n",
      "76\n",
      "tensor(-1.1507, device='cuda:0')\n",
      "77\n",
      "tensor(-1.1619, device='cuda:0')\n",
      "78\n",
      "tensor(-0.2690, device='cuda:0')\n",
      "79\n",
      "tensor(-0.0748, device='cuda:0')\n",
      "80\n",
      "tensor(-0.2692, device='cuda:0')\n",
      "81\n",
      "tensor(-1.1729, device='cuda:0')\n",
      "82\n",
      "tensor(-1.3065, device='cuda:0')\n",
      "83\n",
      "tensor(-1.4695, device='cuda:0')\n",
      "84\n",
      "tensor(-0.0657, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(85):\n",
    "    print(i)\n",
    "    print(torch.dot(all_layer_gradients['layer1'][0].view(85,-1)[i], torch.tensor(cavs[1][1]).cuda() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d62ef92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(7.8871, device='cuda:0')\n",
      "1\n",
      "tensor(4.2670, device='cuda:0')\n",
      "2\n",
      "tensor(1.5204, device='cuda:0')\n",
      "3\n",
      "tensor(0.9167, device='cuda:0')\n",
      "4\n",
      "tensor(0.0608, device='cuda:0')\n",
      "5\n",
      "tensor(-0.0854, device='cuda:0')\n",
      "6\n",
      "tensor(0.5544, device='cuda:0')\n",
      "7\n",
      "tensor(0.8682, device='cuda:0')\n",
      "8\n",
      "tensor(0.0067, device='cuda:0')\n",
      "9\n",
      "tensor(0.0300, device='cuda:0')\n",
      "10\n",
      "tensor(1.0211, device='cuda:0')\n",
      "11\n",
      "tensor(-0.0455, device='cuda:0')\n",
      "12\n",
      "tensor(-0.2739, device='cuda:0')\n",
      "13\n",
      "tensor(-0.0963, device='cuda:0')\n",
      "14\n",
      "tensor(1.0677, device='cuda:0')\n",
      "15\n",
      "tensor(0.6390, device='cuda:0')\n",
      "16\n",
      "tensor(-0.1569, device='cuda:0')\n",
      "17\n",
      "tensor(0.4333, device='cuda:0')\n",
      "18\n",
      "tensor(0.6834, device='cuda:0')\n",
      "19\n",
      "tensor(0.7324, device='cuda:0')\n",
      "20\n",
      "tensor(0.7751, device='cuda:0')\n",
      "21\n",
      "tensor(0.6463, device='cuda:0')\n",
      "22\n",
      "tensor(0.5030, device='cuda:0')\n",
      "23\n",
      "tensor(0.0405, device='cuda:0')\n",
      "24\n",
      "tensor(0.7992, device='cuda:0')\n",
      "25\n",
      "tensor(0.7743, device='cuda:0')\n",
      "26\n",
      "tensor(0.9330, device='cuda:0')\n",
      "27\n",
      "tensor(0.0239, device='cuda:0')\n",
      "28\n",
      "tensor(0.6674, device='cuda:0')\n",
      "29\n",
      "tensor(0.4182, device='cuda:0')\n",
      "30\n",
      "tensor(-0.0596, device='cuda:0')\n",
      "31\n",
      "tensor(0.8032, device='cuda:0')\n",
      "32\n",
      "tensor(0.9661, device='cuda:0')\n",
      "33\n",
      "tensor(1.0739, device='cuda:0')\n",
      "34\n",
      "tensor(-0.2209, device='cuda:0')\n",
      "35\n",
      "tensor(-0.0424, device='cuda:0')\n",
      "36\n",
      "tensor(0.7078, device='cuda:0')\n",
      "37\n",
      "tensor(0.7547, device='cuda:0')\n",
      "38\n",
      "tensor(0.6074, device='cuda:0')\n",
      "39\n",
      "tensor(-0.1312, device='cuda:0')\n",
      "40\n",
      "tensor(0.7353, device='cuda:0')\n",
      "41\n",
      "tensor(-0.1338, device='cuda:0')\n",
      "42\n",
      "tensor(-0.0642, device='cuda:0')\n",
      "43\n",
      "tensor(0.8749, device='cuda:0')\n",
      "44\n",
      "tensor(0.6490, device='cuda:0')\n",
      "45\n",
      "tensor(-0.0914, device='cuda:0')\n",
      "46\n",
      "tensor(-0.0699, device='cuda:0')\n",
      "47\n",
      "tensor(0.6181, device='cuda:0')\n",
      "48\n",
      "tensor(-0.1484, device='cuda:0')\n",
      "49\n",
      "tensor(0.8723, device='cuda:0')\n",
      "50\n",
      "tensor(-0.8999, device='cuda:0')\n",
      "51\n",
      "tensor(-0.8893, device='cuda:0')\n",
      "52\n",
      "tensor(-0.1330, device='cuda:0')\n",
      "53\n",
      "tensor(-0.5637, device='cuda:0')\n",
      "54\n",
      "tensor(-0.8073, device='cuda:0')\n",
      "55\n",
      "tensor(-0.9770, device='cuda:0')\n",
      "56\n",
      "tensor(-0.5557, device='cuda:0')\n",
      "57\n",
      "tensor(-0.8896, device='cuda:0')\n",
      "58\n",
      "tensor(-0.9036, device='cuda:0')\n",
      "59\n",
      "tensor(-0.0834, device='cuda:0')\n",
      "60\n",
      "tensor(-0.8381, device='cuda:0')\n",
      "61\n",
      "tensor(-0.2544, device='cuda:0')\n",
      "62\n",
      "tensor(-0.7759, device='cuda:0')\n",
      "63\n",
      "tensor(-0.8614, device='cuda:0')\n",
      "64\n",
      "tensor(-0.8106, device='cuda:0')\n",
      "65\n",
      "tensor(-0.7104, device='cuda:0')\n",
      "66\n",
      "tensor(-0.0001, device='cuda:0')\n",
      "67\n",
      "tensor(-0.8717, device='cuda:0')\n",
      "68\n",
      "tensor(-0.8157, device='cuda:0')\n",
      "69\n",
      "tensor(-0.0148, device='cuda:0')\n",
      "70\n",
      "tensor(-0.6609, device='cuda:0')\n",
      "71\n",
      "tensor(-0.7425, device='cuda:0')\n",
      "72\n",
      "tensor(-0.8536, device='cuda:0')\n",
      "73\n",
      "tensor(-1.7675, device='cuda:0')\n",
      "74\n",
      "tensor(-0.2177, device='cuda:0')\n",
      "75\n",
      "tensor(-1.3445, device='cuda:0')\n",
      "76\n",
      "tensor(-0.9319, device='cuda:0')\n",
      "77\n",
      "tensor(-1.0712, device='cuda:0')\n",
      "78\n",
      "tensor(-1.2991, device='cuda:0')\n",
      "79\n",
      "tensor(-1.1497, device='cuda:0')\n",
      "80\n",
      "tensor(-1.3629, device='cuda:0')\n",
      "81\n",
      "tensor(-0.9397, device='cuda:0')\n",
      "82\n",
      "tensor(-1.2208, device='cuda:0')\n",
      "83\n",
      "tensor(-1.4255, device='cuda:0')\n",
      "84\n",
      "tensor(-0.3417, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(85):\n",
    "    print(i)\n",
    "    print(torch.dot(all_layer_gradients['layer3'][0].view(85,-1)[i], torch.tensor(cavs[2][1]).cuda() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a2cf16f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(5.0756, device='cuda:0')\n",
      "1\n",
      "tensor(3.6719, device='cuda:0')\n",
      "2\n",
      "tensor(0.8010, device='cuda:0')\n",
      "3\n",
      "tensor(0.4374, device='cuda:0')\n",
      "4\n",
      "tensor(0.3537, device='cuda:0')\n",
      "5\n",
      "tensor(0.5322, device='cuda:0')\n",
      "6\n",
      "tensor(0.0891, device='cuda:0')\n",
      "7\n",
      "tensor(0.4082, device='cuda:0')\n",
      "8\n",
      "tensor(0.0384, device='cuda:0')\n",
      "9\n",
      "tensor(0.0883, device='cuda:0')\n",
      "10\n",
      "tensor(0.0774, device='cuda:0')\n",
      "11\n",
      "tensor(0.0869, device='cuda:0')\n",
      "12\n",
      "tensor(0.0322, device='cuda:0')\n",
      "13\n",
      "tensor(0.4059, device='cuda:0')\n",
      "14\n",
      "tensor(0.4620, device='cuda:0')\n",
      "15\n",
      "tensor(0.1910, device='cuda:0')\n",
      "16\n",
      "tensor(0.2752, device='cuda:0')\n",
      "17\n",
      "tensor(0.2014, device='cuda:0')\n",
      "18\n",
      "tensor(0.2736, device='cuda:0')\n",
      "19\n",
      "tensor(0.3711, device='cuda:0')\n",
      "20\n",
      "tensor(0.2790, device='cuda:0')\n",
      "21\n",
      "tensor(0.3665, device='cuda:0')\n",
      "22\n",
      "tensor(0.3064, device='cuda:0')\n",
      "23\n",
      "tensor(0.4076, device='cuda:0')\n",
      "24\n",
      "tensor(0.3593, device='cuda:0')\n",
      "25\n",
      "tensor(0.3061, device='cuda:0')\n",
      "26\n",
      "tensor(0.4341, device='cuda:0')\n",
      "27\n",
      "tensor(0.1547, device='cuda:0')\n",
      "28\n",
      "tensor(0.3427, device='cuda:0')\n",
      "29\n",
      "tensor(0.0096, device='cuda:0')\n",
      "30\n",
      "tensor(0.3548, device='cuda:0')\n",
      "31\n",
      "tensor(0.2923, device='cuda:0')\n",
      "32\n",
      "tensor(0.0512, device='cuda:0')\n",
      "33\n",
      "tensor(0.5004, device='cuda:0')\n",
      "34\n",
      "tensor(0.1411, device='cuda:0')\n",
      "35\n",
      "tensor(0.4610, device='cuda:0')\n",
      "36\n",
      "tensor(0.0963, device='cuda:0')\n",
      "37\n",
      "tensor(0.2951, device='cuda:0')\n",
      "38\n",
      "tensor(0.2799, device='cuda:0')\n",
      "39\n",
      "tensor(0.3092, device='cuda:0')\n",
      "40\n",
      "tensor(0.3391, device='cuda:0')\n",
      "41\n",
      "tensor(0.0430, device='cuda:0')\n",
      "42\n",
      "tensor(0.2921, device='cuda:0')\n",
      "43\n",
      "tensor(0.4156, device='cuda:0')\n",
      "44\n",
      "tensor(0.0296, device='cuda:0')\n",
      "45\n",
      "tensor(0.3932, device='cuda:0')\n",
      "46\n",
      "tensor(0.0044, device='cuda:0')\n",
      "47\n",
      "tensor(0.3052, device='cuda:0')\n",
      "48\n",
      "tensor(0.0503, device='cuda:0')\n",
      "49\n",
      "tensor(0.4611, device='cuda:0')\n",
      "50\n",
      "tensor(-0.0267, device='cuda:0')\n",
      "51\n",
      "tensor(-0.2034, device='cuda:0')\n",
      "52\n",
      "tensor(-0.2486, device='cuda:0')\n",
      "53\n",
      "tensor(0.0533, device='cuda:0')\n",
      "54\n",
      "tensor(0.0631, device='cuda:0')\n",
      "55\n",
      "tensor(-0.3616, device='cuda:0')\n",
      "56\n",
      "tensor(0.0976, device='cuda:0')\n",
      "57\n",
      "tensor(0.0491, device='cuda:0')\n",
      "58\n",
      "tensor(0.0217, device='cuda:0')\n",
      "59\n",
      "tensor(-0.2367, device='cuda:0')\n",
      "60\n",
      "tensor(0.0336, device='cuda:0')\n",
      "61\n",
      "tensor(-0.3322, device='cuda:0')\n",
      "62\n",
      "tensor(-0.2198, device='cuda:0')\n",
      "63\n",
      "tensor(-0.2160, device='cuda:0')\n",
      "64\n",
      "tensor(-0.2008, device='cuda:0')\n",
      "65\n",
      "tensor(-0.1879, device='cuda:0')\n",
      "66\n",
      "tensor(-0.2120, device='cuda:0')\n",
      "67\n",
      "tensor(-0.2405, device='cuda:0')\n",
      "68\n",
      "tensor(-0.1789, device='cuda:0')\n",
      "69\n",
      "tensor(-0.1901, device='cuda:0')\n",
      "70\n",
      "tensor(0.1109, device='cuda:0')\n",
      "71\n",
      "tensor(-0.1490, device='cuda:0')\n",
      "72\n",
      "tensor(0.0483, device='cuda:0')\n",
      "73\n",
      "tensor(-0.4914, device='cuda:0')\n",
      "74\n",
      "tensor(-0.0435, device='cuda:0')\n",
      "75\n",
      "tensor(-0.3314, device='cuda:0')\n",
      "76\n",
      "tensor(-0.0133, device='cuda:0')\n",
      "77\n",
      "tensor(-0.3428, device='cuda:0')\n",
      "78\n",
      "tensor(-0.4205, device='cuda:0')\n",
      "79\n",
      "tensor(-0.3488, device='cuda:0')\n",
      "80\n",
      "tensor(-0.0808, device='cuda:0')\n",
      "81\n",
      "tensor(0.0256, device='cuda:0')\n",
      "82\n",
      "tensor(-0.3680, device='cuda:0')\n",
      "83\n",
      "tensor(-0.5857, device='cuda:0')\n",
      "84\n",
      "tensor(-0.3531, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(85):\n",
    "    print(i)\n",
    "    print(torch.dot(all_layer_gradients['layer5'][0].view(85,-1)[i], torch.tensor(cavs[3][1]).cuda() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fe0f731a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(-1.1681, device='cuda:0')\n",
      "1\n",
      "tensor(-0.4685, device='cuda:0')\n",
      "2\n",
      "tensor(0.0228, device='cuda:0')\n",
      "3\n",
      "tensor(0.1466, device='cuda:0')\n",
      "4\n",
      "tensor(0.1614, device='cuda:0')\n",
      "5\n",
      "tensor(0.0619, device='cuda:0')\n",
      "6\n",
      "tensor(0.1490, device='cuda:0')\n",
      "7\n",
      "tensor(0.1648, device='cuda:0')\n",
      "8\n",
      "tensor(0.1493, device='cuda:0')\n",
      "9\n",
      "tensor(0.1720, device='cuda:0')\n",
      "10\n",
      "tensor(0.2074, device='cuda:0')\n",
      "11\n",
      "tensor(0.1479, device='cuda:0')\n",
      "12\n",
      "tensor(0.3873, device='cuda:0')\n",
      "13\n",
      "tensor(0.1705, device='cuda:0')\n",
      "14\n",
      "tensor(0.2090, device='cuda:0')\n",
      "15\n",
      "tensor(0.2053, device='cuda:0')\n",
      "16\n",
      "tensor(0.0004, device='cuda:0')\n",
      "17\n",
      "tensor(0.0241, device='cuda:0')\n",
      "18\n",
      "tensor(0.1873, device='cuda:0')\n",
      "19\n",
      "tensor(0.1511, device='cuda:0')\n",
      "20\n",
      "tensor(0.0658, device='cuda:0')\n",
      "21\n",
      "tensor(0.2161, device='cuda:0')\n",
      "22\n",
      "tensor(0.1166, device='cuda:0')\n",
      "23\n",
      "tensor(0.2141, device='cuda:0')\n",
      "24\n",
      "tensor(0.0278, device='cuda:0')\n",
      "25\n",
      "tensor(0.0408, device='cuda:0')\n",
      "26\n",
      "tensor(0.2271, device='cuda:0')\n",
      "27\n",
      "tensor(0.1222, device='cuda:0')\n",
      "28\n",
      "tensor(0.0928, device='cuda:0')\n",
      "29\n",
      "tensor(0.1335, device='cuda:0')\n",
      "30\n",
      "tensor(0.1590, device='cuda:0')\n",
      "31\n",
      "tensor(0.0411, device='cuda:0')\n",
      "32\n",
      "tensor(0.2314, device='cuda:0')\n",
      "33\n",
      "tensor(0.0030, device='cuda:0')\n",
      "34\n",
      "tensor(0.1015, device='cuda:0')\n",
      "35\n",
      "tensor(0.3544, device='cuda:0')\n",
      "36\n",
      "tensor(0.0094, device='cuda:0')\n",
      "37\n",
      "tensor(0.0572, device='cuda:0')\n",
      "38\n",
      "tensor(0.1527, device='cuda:0')\n",
      "39\n",
      "tensor(0.1510, device='cuda:0')\n",
      "40\n",
      "tensor(0.1439, device='cuda:0')\n",
      "41\n",
      "tensor(0.0705, device='cuda:0')\n",
      "42\n",
      "tensor(0.2194, device='cuda:0')\n",
      "43\n",
      "tensor(0.0325, device='cuda:0')\n",
      "44\n",
      "tensor(0.1990, device='cuda:0')\n",
      "45\n",
      "tensor(0.2617, device='cuda:0')\n",
      "46\n",
      "tensor(0.2046, device='cuda:0')\n",
      "47\n",
      "tensor(0.0415, device='cuda:0')\n",
      "48\n",
      "tensor(0.1243, device='cuda:0')\n",
      "49\n",
      "tensor(0.2551, device='cuda:0')\n",
      "50\n",
      "tensor(-0.1673, device='cuda:0')\n",
      "51\n",
      "tensor(-0.0372, device='cuda:0')\n",
      "52\n",
      "tensor(-0.0547, device='cuda:0')\n",
      "53\n",
      "tensor(-0.0930, device='cuda:0')\n",
      "54\n",
      "tensor(-0.1184, device='cuda:0')\n",
      "55\n",
      "tensor(-0.1292, device='cuda:0')\n",
      "56\n",
      "tensor(0.0013, device='cuda:0')\n",
      "57\n",
      "tensor(-0.1781, device='cuda:0')\n",
      "58\n",
      "tensor(-0.0727, device='cuda:0')\n",
      "59\n",
      "tensor(-0.1088, device='cuda:0')\n",
      "60\n",
      "tensor(0.0291, device='cuda:0')\n",
      "61\n",
      "tensor(-0.0114, device='cuda:0')\n",
      "62\n",
      "tensor(0.0197, device='cuda:0')\n",
      "63\n",
      "tensor(0.0767, device='cuda:0')\n",
      "64\n",
      "tensor(0.0197, device='cuda:0')\n",
      "65\n",
      "tensor(-0.0225, device='cuda:0')\n",
      "66\n",
      "tensor(0.0664, device='cuda:0')\n",
      "67\n",
      "tensor(-0.1958, device='cuda:0')\n",
      "68\n",
      "tensor(0.0281, device='cuda:0')\n",
      "69\n",
      "tensor(-0.0661, device='cuda:0')\n",
      "70\n",
      "tensor(-0.0966, device='cuda:0')\n",
      "71\n",
      "tensor(0.0476, device='cuda:0')\n",
      "72\n",
      "tensor(0.0599, device='cuda:0')\n",
      "73\n",
      "tensor(-0.1180, device='cuda:0')\n",
      "74\n",
      "tensor(-0.0408, device='cuda:0')\n",
      "75\n",
      "tensor(-0.0827, device='cuda:0')\n",
      "76\n",
      "tensor(-0.0916, device='cuda:0')\n",
      "77\n",
      "tensor(-0.1130, device='cuda:0')\n",
      "78\n",
      "tensor(-0.1097, device='cuda:0')\n",
      "79\n",
      "tensor(-0.0906, device='cuda:0')\n",
      "80\n",
      "tensor(0.0612, device='cuda:0')\n",
      "81\n",
      "tensor(-0.0865, device='cuda:0')\n",
      "82\n",
      "tensor(-0.0639, device='cuda:0')\n",
      "83\n",
      "tensor(0.0776, device='cuda:0')\n",
      "84\n",
      "tensor(-0.1268, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(85):\n",
    "    print(i)\n",
    "    print(torch.dot(all_layer_gradients['layer7'][0].view(85,-1)[i], torch.tensor(cavs[4][1]).cuda() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6406c53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(4.5534, device='cuda:0')\n",
      "1\n",
      "tensor(0.9605, device='cuda:0')\n",
      "2\n",
      "tensor(0.0407, device='cuda:0')\n",
      "3\n",
      "tensor(0.0317, device='cuda:0')\n",
      "4\n",
      "tensor(0.0326, device='cuda:0')\n",
      "5\n",
      "tensor(0.0408, device='cuda:0')\n",
      "6\n",
      "tensor(0.0415, device='cuda:0')\n",
      "7\n",
      "tensor(0.0314, device='cuda:0')\n",
      "8\n",
      "tensor(0.0179, device='cuda:0')\n",
      "9\n",
      "tensor(0.0268, device='cuda:0')\n",
      "10\n",
      "tensor(0.0683, device='cuda:0')\n",
      "11\n",
      "tensor(0.0242, device='cuda:0')\n",
      "12\n",
      "tensor(0.0112, device='cuda:0')\n",
      "13\n",
      "tensor(0.0377, device='cuda:0')\n",
      "14\n",
      "tensor(0.0097, device='cuda:0')\n",
      "15\n",
      "tensor(0.0306, device='cuda:0')\n",
      "16\n",
      "tensor(0.0244, device='cuda:0')\n",
      "17\n",
      "tensor(0.0053, device='cuda:0')\n",
      "18\n",
      "tensor(0.0475, device='cuda:0')\n",
      "19\n",
      "tensor(0.0257, device='cuda:0')\n",
      "20\n",
      "tensor(0.0352, device='cuda:0')\n",
      "21\n",
      "tensor(0.0253, device='cuda:0')\n",
      "22\n",
      "tensor(0.0428, device='cuda:0')\n",
      "23\n",
      "tensor(0.0569, device='cuda:0')\n",
      "24\n",
      "tensor(0.0069, device='cuda:0')\n",
      "25\n",
      "tensor(0.0200, device='cuda:0')\n",
      "26\n",
      "tensor(0.0146, device='cuda:0')\n",
      "27\n",
      "tensor(0.0383, device='cuda:0')\n",
      "28\n",
      "tensor(0.0244, device='cuda:0')\n",
      "29\n",
      "tensor(0.0205, device='cuda:0')\n",
      "30\n",
      "tensor(0.0394, device='cuda:0')\n",
      "31\n",
      "tensor(0.0543, device='cuda:0')\n",
      "32\n",
      "tensor(0.0140, device='cuda:0')\n",
      "33\n",
      "tensor(0.0613, device='cuda:0')\n",
      "34\n",
      "tensor(0.0119, device='cuda:0')\n",
      "35\n",
      "tensor(0.0137, device='cuda:0')\n",
      "36\n",
      "tensor(0.0317, device='cuda:0')\n",
      "37\n",
      "tensor(0.0274, device='cuda:0')\n",
      "38\n",
      "tensor(0.0271, device='cuda:0')\n",
      "39\n",
      "tensor(0.0116, device='cuda:0')\n",
      "40\n",
      "tensor(0.0319, device='cuda:0')\n",
      "41\n",
      "tensor(0.0320, device='cuda:0')\n",
      "42\n",
      "tensor(0.0915, device='cuda:0')\n",
      "43\n",
      "tensor(0.0383, device='cuda:0')\n",
      "44\n",
      "tensor(0.0566, device='cuda:0')\n",
      "45\n",
      "tensor(0.0837, device='cuda:0')\n",
      "46\n",
      "tensor(0.0286, device='cuda:0')\n",
      "47\n",
      "tensor(0.0209, device='cuda:0')\n",
      "48\n",
      "tensor(0.0330, device='cuda:0')\n",
      "49\n",
      "tensor(0.0536, device='cuda:0')\n",
      "50\n",
      "tensor(-0.0311, device='cuda:0')\n",
      "51\n",
      "tensor(0.0091, device='cuda:0')\n",
      "52\n",
      "tensor(-0.0306, device='cuda:0')\n",
      "53\n",
      "tensor(0.0184, device='cuda:0')\n",
      "54\n",
      "tensor(-0.0045, device='cuda:0')\n",
      "55\n",
      "tensor(-0.0248, device='cuda:0')\n",
      "56\n",
      "tensor(0.0031, device='cuda:0')\n",
      "57\n",
      "tensor(-0.0172, device='cuda:0')\n",
      "58\n",
      "tensor(0.0039, device='cuda:0')\n",
      "59\n",
      "tensor(-0.0204, device='cuda:0')\n",
      "60\n",
      "tensor(0.0053, device='cuda:0')\n",
      "61\n",
      "tensor(0.0157, device='cuda:0')\n",
      "62\n",
      "tensor(0.0032, device='cuda:0')\n",
      "63\n",
      "tensor(0.0117, device='cuda:0')\n",
      "64\n",
      "tensor(0.0101, device='cuda:0')\n",
      "65\n",
      "tensor(0.0098, device='cuda:0')\n",
      "66\n",
      "tensor(0.0138, device='cuda:0')\n",
      "67\n",
      "tensor(-0.0306, device='cuda:0')\n",
      "68\n",
      "tensor(0.0066, device='cuda:0')\n",
      "69\n",
      "tensor(-0.0280, device='cuda:0')\n",
      "70\n",
      "tensor(0.0127, device='cuda:0')\n",
      "71\n",
      "tensor(0.0158, device='cuda:0')\n",
      "72\n",
      "tensor(0.0189, device='cuda:0')\n",
      "73\n",
      "tensor(0.0042, device='cuda:0')\n",
      "74\n",
      "tensor(0.0042, device='cuda:0')\n",
      "75\n",
      "tensor(5.2242e-05, device='cuda:0')\n",
      "76\n",
      "tensor(-0.0086, device='cuda:0')\n",
      "77\n",
      "tensor(-0.0018, device='cuda:0')\n",
      "78\n",
      "tensor(0.0203, device='cuda:0')\n",
      "79\n",
      "tensor(-0.0030, device='cuda:0')\n",
      "80\n",
      "tensor(-0.0015, device='cuda:0')\n",
      "81\n",
      "tensor(-0.0053, device='cuda:0')\n",
      "82\n",
      "tensor(0.0017, device='cuda:0')\n",
      "83\n",
      "tensor(-0.0010, device='cuda:0')\n",
      "84\n",
      "tensor(-0.0094, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(85):\n",
    "    print(i)\n",
    "    print(torch.dot(all_layer_gradients['layer9'][0].view(85,-1)[i], torch.tensor(cavs[5][1]).cuda() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "84944f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(4.5974, device='cuda:0')\n",
      "1\n",
      "tensor(5.0867, device='cuda:0')\n",
      "2\n",
      "tensor(0., device='cuda:0')\n",
      "3\n",
      "tensor(0., device='cuda:0')\n",
      "4\n",
      "tensor(0., device='cuda:0')\n",
      "5\n",
      "tensor(0., device='cuda:0')\n",
      "6\n",
      "tensor(0., device='cuda:0')\n",
      "7\n",
      "tensor(0., device='cuda:0')\n",
      "8\n",
      "tensor(0., device='cuda:0')\n",
      "9\n",
      "tensor(0., device='cuda:0')\n",
      "10\n",
      "tensor(0., device='cuda:0')\n",
      "11\n",
      "tensor(0., device='cuda:0')\n",
      "12\n",
      "tensor(0., device='cuda:0')\n",
      "13\n",
      "tensor(0., device='cuda:0')\n",
      "14\n",
      "tensor(0., device='cuda:0')\n",
      "15\n",
      "tensor(0., device='cuda:0')\n",
      "16\n",
      "tensor(0., device='cuda:0')\n",
      "17\n",
      "tensor(0., device='cuda:0')\n",
      "18\n",
      "tensor(0., device='cuda:0')\n",
      "19\n",
      "tensor(0., device='cuda:0')\n",
      "20\n",
      "tensor(0., device='cuda:0')\n",
      "21\n",
      "tensor(0., device='cuda:0')\n",
      "22\n",
      "tensor(0., device='cuda:0')\n",
      "23\n",
      "tensor(0., device='cuda:0')\n",
      "24\n",
      "tensor(0., device='cuda:0')\n",
      "25\n",
      "tensor(0., device='cuda:0')\n",
      "26\n",
      "tensor(0., device='cuda:0')\n",
      "27\n",
      "tensor(0., device='cuda:0')\n",
      "28\n",
      "tensor(0., device='cuda:0')\n",
      "29\n",
      "tensor(0., device='cuda:0')\n",
      "30\n",
      "tensor(0., device='cuda:0')\n",
      "31\n",
      "tensor(0., device='cuda:0')\n",
      "32\n",
      "tensor(0., device='cuda:0')\n",
      "33\n",
      "tensor(0., device='cuda:0')\n",
      "34\n",
      "tensor(0., device='cuda:0')\n",
      "35\n",
      "tensor(0., device='cuda:0')\n",
      "36\n",
      "tensor(0., device='cuda:0')\n",
      "37\n",
      "tensor(0., device='cuda:0')\n",
      "38\n",
      "tensor(0., device='cuda:0')\n",
      "39\n",
      "tensor(0., device='cuda:0')\n",
      "40\n",
      "tensor(0., device='cuda:0')\n",
      "41\n",
      "tensor(0., device='cuda:0')\n",
      "42\n",
      "tensor(0., device='cuda:0')\n",
      "43\n",
      "tensor(0., device='cuda:0')\n",
      "44\n",
      "tensor(0., device='cuda:0')\n",
      "45\n",
      "tensor(0., device='cuda:0')\n",
      "46\n",
      "tensor(0., device='cuda:0')\n",
      "47\n",
      "tensor(0., device='cuda:0')\n",
      "48\n",
      "tensor(0., device='cuda:0')\n",
      "49\n",
      "tensor(0., device='cuda:0')\n",
      "50\n",
      "tensor(0., device='cuda:0')\n",
      "51\n",
      "tensor(0., device='cuda:0')\n",
      "52\n",
      "tensor(0., device='cuda:0')\n",
      "53\n",
      "tensor(0., device='cuda:0')\n",
      "54\n",
      "tensor(0., device='cuda:0')\n",
      "55\n",
      "tensor(0., device='cuda:0')\n",
      "56\n",
      "tensor(0., device='cuda:0')\n",
      "57\n",
      "tensor(0., device='cuda:0')\n",
      "58\n",
      "tensor(0., device='cuda:0')\n",
      "59\n",
      "tensor(0., device='cuda:0')\n",
      "60\n",
      "tensor(0., device='cuda:0')\n",
      "61\n",
      "tensor(0., device='cuda:0')\n",
      "62\n",
      "tensor(0., device='cuda:0')\n",
      "63\n",
      "tensor(0., device='cuda:0')\n",
      "64\n",
      "tensor(0., device='cuda:0')\n",
      "65\n",
      "tensor(0., device='cuda:0')\n",
      "66\n",
      "tensor(0., device='cuda:0')\n",
      "67\n",
      "tensor(0., device='cuda:0')\n",
      "68\n",
      "tensor(0., device='cuda:0')\n",
      "69\n",
      "tensor(0., device='cuda:0')\n",
      "70\n",
      "tensor(0., device='cuda:0')\n",
      "71\n",
      "tensor(0., device='cuda:0')\n",
      "72\n",
      "tensor(0., device='cuda:0')\n",
      "73\n",
      "tensor(0., device='cuda:0')\n",
      "74\n",
      "tensor(0., device='cuda:0')\n",
      "75\n",
      "tensor(0., device='cuda:0')\n",
      "76\n",
      "tensor(0., device='cuda:0')\n",
      "77\n",
      "tensor(0., device='cuda:0')\n",
      "78\n",
      "tensor(0., device='cuda:0')\n",
      "79\n",
      "tensor(0., device='cuda:0')\n",
      "80\n",
      "tensor(0., device='cuda:0')\n",
      "81\n",
      "tensor(0., device='cuda:0')\n",
      "82\n",
      "tensor(0., device='cuda:0')\n",
      "83\n",
      "tensor(0., device='cuda:0')\n",
      "84\n",
      "tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(85):\n",
    "    print(i)\n",
    "    print(torch.dot(all_layer_gradients['layer11'][0].view(85,-1)[i], torch.tensor(cavs[6][1]).cuda() ) )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4c1cccef",
   "metadata": {},
   "source": [
    "Reference code from gradcam for backprop\n",
    "\n",
    "\n",
    "\n",
    "def gradCAM(\n",
    "    model: nn.Module,\n",
    "    input: torch.Tensor,\n",
    "    target: torch.Tensor,\n",
    "    layer: nn.Module\n",
    ") -> torch.Tensor:\n",
    "    # Zero out any gradients at the input.\n",
    "    if input.grad is not None:\n",
    "        input.grad.data.zero_()\n",
    "        \n",
    "    # Disable gradient settings.\n",
    "    requires_grad = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        requires_grad[name] = param.requires_grad\n",
    "        param.requires_grad_(False)\n",
    "        \n",
    "    # Attach a hook to the model at the desired layer.\n",
    "    assert isinstance(layer, nn.Module)\n",
    "    with Hook(layer) as hook:        \n",
    "        # Do a forward and backward pass.\n",
    "        output = model(input)\n",
    "        output.backward(target)\n",
    "\n",
    "        grad = hook.gradient.float()\n",
    "        act = hook.activation.float()\n",
    "    \n",
    "        # Global average pool gradient across spatial dimension\n",
    "        # to obtain importance weights.\n",
    "        alpha = grad.mean(dim=(2, 3), keepdim=True)\n",
    "        # Weighted combination of activation maps over channel\n",
    "        # dimension.\n",
    "        gradcam = torch.sum(act * alpha, dim=1, keepdim=True)\n",
    "        # We only want neurons with positive influence so we\n",
    "        # clamp any negative ones.\n",
    "        gradcam = torch.clamp(gradcam, min=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37233b85",
   "metadata": {},
   "source": [
    "You need labels to get gradients, to get a loss to backpropagate with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebda776",
   "metadata": {},
   "source": [
    "# Calculate TCAV score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5e277ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = preprocess(Image.open('tcav/concepts/striped/striped_0086.jpg')).unsqueeze(0).to(device)\n",
    "image_features = model.encode_image(image.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2295b480",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(image.cuda(), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05d5c062",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.encode_image(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a32f1781",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward(torch.ones(1,1024).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "2496f7f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 512])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.visual.proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c3ab68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0596237182617188"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.dot(image_features.squeeze().cpu().detach().numpy(), np.ones(512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50b2e2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.1542e-01, -2.0203e-02, -3.9154e-02, -1.3452e-01, -4.5815e-03,\n",
       "        2.4207e-01,  3.3594e-01,  2.3926e-01,  5.3711e-01,  1.2854e-01,\n",
       "        1.4709e-01,  5.0873e-02,  3.2080e-01, -6.7871e-01, -8.2886e-02,\n",
       "       -1.5857e-01,  9.5947e-01, -2.1716e-01,  2.1716e-01,  1.6797e-01,\n",
       "       -6.3818e-01,  9.3262e-02, -1.2964e-01, -5.0732e-01, -2.5024e-03,\n",
       "        3.2349e-01,  2.5314e-02,  1.9495e-01,  1.7224e-01, -4.6436e-01,\n",
       "       -2.4796e-02,  5.9814e-02,  5.2551e-02,  4.0649e-01, -5.7959e-01,\n",
       "        8.2642e-02,  3.6475e-01,  3.4351e-01,  1.1102e-01,  9.0186e-01,\n",
       "       -3.9398e-02, -2.1167e-01,  2.1082e-01,  1.8823e-01, -4.5776e-01,\n",
       "        5.9570e-01,  3.8477e-01,  5.1025e-01, -1.8396e-01, -4.0723e-01,\n",
       "       -2.1130e-01,  2.7026e-01,  2.0471e-01, -5.2295e-01, -3.7012e-01,\n",
       "       -3.8391e-02,  5.6934e-01,  2.6337e-02, -6.5613e-02,  5.0720e-02,\n",
       "        9.2822e-01,  2.8516e-01, -2.4707e-01, -7.3120e-02, -3.8647e-01,\n",
       "        2.2559e-01,  5.2719e-03,  2.5122e-01, -1.3269e-01, -8.0566e-02,\n",
       "        1.1560e-01, -3.4473e-01, -2.4353e-02, -6.4551e-01,  2.7783e-01,\n",
       "       -4.6997e-01, -3.9722e-01, -1.0925e-01, -4.7852e-02, -2.2534e-01,\n",
       "       -4.7363e-02,  3.4698e-02, -5.3516e-01, -7.3828e-01,  2.8418e-01,\n",
       "        3.3032e-01,  5.6152e-01, -1.8713e-01,  3.5791e-01, -1.0187e-01,\n",
       "        1.9580e-01, -6.8604e-02, -8.1953e+00,  4.6631e-01, -3.9062e-01,\n",
       "        4.2755e-02, -2.8687e-01, -7.1289e-01, -6.5234e-01, -1.3391e-01,\n",
       "       -1.0242e-01,  2.9346e-01, -1.2384e-01,  3.5425e-01,  4.8755e-01,\n",
       "       -1.6602e-01, -1.4082e+00,  3.4668e-01, -1.8420e-01, -1.9763e-01,\n",
       "        1.6663e-01, -1.5479e-01,  4.5312e-01, -2.0703e-01,  9.0454e-02,\n",
       "       -2.7710e-02,  4.4312e-01, -4.3652e-01, -5.2643e-02,  1.8445e-01,\n",
       "        3.4180e-02, -3.0542e-01, -1.2500e-01, -3.1464e-02,  1.6281e-02,\n",
       "       -5.1562e-01, -4.3140e-01, -3.4576e-02,  2.5781e-01,  3.3179e-01,\n",
       "        1.4136e-01, -3.2104e-01, -4.2554e-01,  1.0332e+00,  2.2327e-01,\n",
       "       -3.7964e-01, -2.8906e-01, -7.1729e-01, -7.5732e-01, -3.5675e-02,\n",
       "       -2.7856e-01, -3.7354e-01, -4.3359e-01,  4.1479e-01, -3.3228e-01,\n",
       "        3.5718e-01,  1.0857e-02,  4.4702e-01, -4.5361e-01, -3.0487e-02,\n",
       "       -5.9357e-02,  6.3782e-02, -1.5100e-01, -4.3555e-01,  3.6572e-01,\n",
       "       -3.3765e-01,  5.9082e-01,  3.3276e-01,  2.5116e-02,  1.9312e-01,\n",
       "        2.5146e-01, -4.0552e-01, -4.5898e-01, -1.1371e-01, -7.2327e-02,\n",
       "       -4.8027e-03, -3.1274e-01,  1.6919e-01,  7.2754e-01,  1.2421e-01,\n",
       "       -3.3447e-01, -2.0630e-02,  2.0325e-01, -3.3521e-01,  7.0923e-02,\n",
       "        5.9479e-02, -1.6748e-01, -4.1992e-02, -3.4619e-01,  1.8402e-02,\n",
       "       -1.7920e-01, -2.7075e-01, -5.9113e-02, -1.2274e-01, -1.7175e-01,\n",
       "        2.5317e-01, -2.2534e-01,  7.2708e-03, -2.4854e-01, -5.8014e-02,\n",
       "        1.5869e-01, -3.2495e-01,  1.6602e-02,  1.4844e-01,  4.4580e-01,\n",
       "        3.7573e-01,  1.4685e-01, -4.8535e-01, -1.1992e+00, -6.0547e-02,\n",
       "        3.5889e-01, -2.6001e-01, -5.4550e-03,  4.2920e-01,  5.1855e-01,\n",
       "        1.5210e-01, -2.1301e-01, -6.0742e-01,  4.5239e-01, -1.1365e-01,\n",
       "       -4.0503e-01,  3.2031e-01,  4.5337e-01,  1.1957e-01,  3.5553e-02,\n",
       "        2.9126e-01, -2.0203e-01,  2.5171e-01,  6.4160e-01,  3.5742e-01,\n",
       "        3.3789e-01,  2.1973e-01, -1.7664e-01, -1.0522e-01, -1.0638e-01,\n",
       "        1.1200e-02, -8.3801e-02, -1.8481e-01,  2.4414e-01,  2.2400e-01,\n",
       "       -2.7905e-01,  1.8872e-01,  4.3506e-01,  3.9575e-01, -2.1936e-01,\n",
       "        3.3301e-01,  1.4673e-01,  3.1079e-01, -6.5088e-01, -3.3423e-01,\n",
       "        2.0471e-01,  2.1106e-01,  2.2314e-01, -2.0264e-02, -1.6418e-01,\n",
       "       -5.0964e-03,  1.7715e-02, -5.3857e-01, -2.7319e-01,  1.1597e-01,\n",
       "        1.3440e-01,  4.9658e-01,  1.0187e-01,  1.3489e-01, -7.3608e-02,\n",
       "        1.5366e-02, -3.0322e-01,  3.9111e-01,  1.1846e+00,  2.4951e-01,\n",
       "       -7.6355e-02,  1.8631e-02, -5.4053e-01,  1.1032e-02,  2.2385e-02,\n",
       "       -2.9846e-02,  4.0552e-01, -2.2131e-01,  6.0303e-01, -3.6646e-01,\n",
       "       -2.6685e-01,  9.8572e-02,  2.6688e-02, -2.9404e-02,  1.2402e-01,\n",
       "       -1.5112e-01,  3.4912e-01,  2.2144e-01, -3.6719e-01, -2.9761e-01,\n",
       "        3.8672e-01,  1.0046e-01, -1.9824e-01, -3.2153e-01,  6.0608e-02,\n",
       "        1.5129e-02, -5.0586e-01, -3.2776e-02, -3.3765e-01,  2.3962e-01,\n",
       "       -3.2935e-01,  1.3794e-01,  1.5747e-01,  5.5029e-01,  8.6914e-02,\n",
       "       -6.0181e-02,  4.2334e-01,  3.1006e-01,  1.3367e-01,  2.9199e-01,\n",
       "       -8.2581e-02, -2.5220e-01, -1.1865e-01,  6.2744e-01,  1.1890e-01,\n",
       "       -4.1724e-01,  9.9731e-02,  1.4148e-01,  4.3359e-01,  7.2205e-02,\n",
       "       -5.9174e-02, -1.0876e-01,  1.0322e+00,  2.0035e-02,  5.4785e-01,\n",
       "       -2.4915e-01, -1.6800e-02,  5.8252e-01, -1.9873e-01, -6.6064e-01,\n",
       "        1.2659e-01,  9.8193e-01,  6.2790e-03,  6.9519e-02,  1.8909e-01,\n",
       "       -2.0618e-01, -2.4094e-02, -3.6279e-01,  7.5146e-01,  5.8008e-01,\n",
       "       -3.8306e-01,  9.7839e-02,  8.0750e-02,  4.3823e-02,  1.2964e-01,\n",
       "       -5.4053e-01,  2.0508e-01,  8.4473e-02, -2.5317e-01,  4.2786e-02,\n",
       "        8.8577e-03, -1.1917e-02, -3.6865e-01,  1.5759e-01, -2.5589e-02,\n",
       "        1.2622e-01,  1.1345e-02,  2.9037e-02,  5.9766e-01,  3.5191e-03,\n",
       "        5.2734e-01, -8.3618e-02,  5.6934e-01, -6.4551e-01, -8.0017e-02,\n",
       "       -3.2861e-01,  1.1102e-01,  6.9275e-02, -4.3274e-02,  5.5176e-02,\n",
       "        3.6035e-01, -1.7004e-01,  1.8030e-01,  1.1841e-01, -7.8711e-01,\n",
       "       -6.1865e-01,  6.5186e-02, -5.2100e-01, -2.9395e-01,  2.0154e-01,\n",
       "        2.7832e-01,  1.0846e-01,  6.8115e-02,  2.9199e-01,  1.4816e-02,\n",
       "        2.0654e-01,  1.1885e+00,  2.4475e-01, -6.4844e-01,  2.5284e-02,\n",
       "        2.4768e-01, -2.4304e-01, -5.6702e-02, -1.9373e-01,  6.6284e-02,\n",
       "        7.6318e-01, -4.3243e-02,  3.1519e-01, -1.6125e-01, -6.4111e-01,\n",
       "        1.4429e-01, -3.5547e-01, -3.4082e-01,  1.6504e-01,  1.6211e-01,\n",
       "        1.8463e-02,  6.4502e-01,  2.9907e-01, -9.4873e-01, -3.1738e-01,\n",
       "       -2.1375e-01, -5.6445e-01,  2.8223e-01,  7.1240e-01,  1.5332e-01,\n",
       "        3.0835e-01,  9.6497e-02, -2.4976e-01,  5.4248e-01, -3.6133e-01,\n",
       "        8.2568e-01,  8.5266e-02,  3.2056e-01,  2.3511e-01, -2.8589e-01,\n",
       "       -5.4785e-01,  3.0835e-01, -2.4048e-01,  1.8079e-01, -6.7822e-01,\n",
       "       -6.7188e-01, -7.6050e-02, -5.5389e-02,  5.6348e-01, -3.2654e-02,\n",
       "        1.3477e-01, -2.9395e-01, -1.3371e-03,  1.3306e-01, -3.8501e-01,\n",
       "       -1.1475e-01,  5.2832e-01, -1.6870e-01,  4.0527e-02,  2.3694e-01,\n",
       "       -9.5154e-02,  1.1835e-01,  1.3770e-01, -9.6802e-02, -1.6650e-01,\n",
       "       -1.7847e-01,  3.6548e-01, -6.6895e-01, -1.6479e-01,  1.8152e-01,\n",
       "        2.2876e-01,  1.2964e-01, -1.3245e-01,  2.4243e-01, -2.4548e-01,\n",
       "        3.7231e-01, -4.9243e-01, -1.7639e-01, -3.1396e-01,  1.1774e-01,\n",
       "       -1.5112e-01,  3.9697e-01,  1.7163e-01, -2.5708e-01,  2.7637e-01,\n",
       "        3.3862e-01,  4.0283e-01, -2.8625e-02,  5.1956e-03,  2.0239e-01,\n",
       "        2.6465e-01, -4.4312e-01, -4.9469e-02,  3.1250e-01, -1.8127e-01,\n",
       "        4.7559e-01, -6.1133e-01,  4.4751e-01, -2.9956e-01,  1.7664e-01,\n",
       "       -3.9087e-01,  1.0010e-01, -7.4402e-02, -8.5999e-02, -6.6406e-02,\n",
       "        4.5776e-01, -2.0642e-01, -2.1790e-01,  2.5537e-01, -2.3474e-01,\n",
       "        1.1145e-01,  3.9771e-01, -4.4800e-01, -1.1310e-01,  2.1667e-01,\n",
       "       -2.6562e-01, -3.1128e-01,  6.9580e-01, -3.6694e-01,  5.5615e-01,\n",
       "       -1.0645e-01, -1.3489e-01,  4.9658e-01, -7.9041e-02, -6.4148e-02,\n",
       "        2.3849e-02,  2.9639e-01, -2.9144e-02,  2.2241e-01,  4.6216e-01,\n",
       "       -7.5977e-01, -1.0492e-01, -7.1167e-02, -3.5400e-01,  9.7119e-01,\n",
       "       -2.3224e-02,  3.3887e-01], dtype=float16)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_features.squeeze().cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "188a0e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61c0aaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_classifiers = np.load(\"classifiers_perclass_perlayer_smeared_dotted_knitted_spiralled_chequered.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cebafa79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearClassifier(\n",
       "  (linear1): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_classifiers[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8b2abb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (replearn2)",
   "language": "python",
   "name": "replearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
