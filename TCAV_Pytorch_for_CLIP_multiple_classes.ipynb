{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac679899",
   "metadata": {},
   "source": [
    "# Notebook Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4f06f1",
   "metadata": {},
   "source": [
    "Implement TCAV using Pytorch for CLIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a8b248",
   "metadata": {},
   "source": [
    "# Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32277860",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/openai/CLIP\n",
    "# authors Katherine Crowson (https://github.com/crowsonkb, https://twitter.com/RiversHaveWings), nerdyrodent\n",
    "# authors vivian\n",
    "# The original BigGAN+CLIP method was by https://twitter.com/advadnoun\n",
    "import threading\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import math\n",
    "import random\n",
    "from urllib.request import urlopen\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('taming-transformers')\n",
    "from omegaconf import OmegaConf\n",
    "from taming.models import cond_transformer, vqgan\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as TF\n",
    "from torch.cuda import get_device_properties\n",
    "torch.backends.cudnn.benchmark = False\n",
    "from torch_optimizer import DiffGrad, AdamP, RAdam\n",
    "from CLIP import clip\n",
    "import kornia.augmentation as K\n",
    "import imageio\n",
    "from PIL import ImageFile, Image, PngImagePlugin, ImageChops\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from subprocess import Popen, PIPE\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3033a3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RN50', 'RN101', 'RN50x4', 'RN50x16', 'ViT-B/32', 'ViT-B/16']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip.available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6fad75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3410ac22",
   "metadata": {},
   "source": [
    "# Load CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e379417",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, preprocess = clip.load('ViT-B/32', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d901147",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hook:\n",
    "    \"\"\"Attaches to a module and records its activations and gradients.\"\"\"\n",
    "\n",
    "    def __init__(self, module: nn.Module):\n",
    "        self.data = None\n",
    "        self.hook = module.register_forward_hook(self.save_grad)\n",
    "        \n",
    "    def save_grad(self, module, input, output):\n",
    "        self.data = output\n",
    "        output.requires_grad_(True)\n",
    "        output.retain_grad()\n",
    "        \n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_value, exc_traceback):\n",
    "        self.hook.remove()\n",
    "        \n",
    "    @property\n",
    "    def activation(self) -> torch.Tensor:\n",
    "        return self.data\n",
    "    \n",
    "    @property\n",
    "    def gradient(self) -> torch.Tensor:\n",
    "        return self.data.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da4b2121",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping():\n",
    "    \"\"\"\n",
    "    Early stopping to stop the training when the loss does not improve after\n",
    "    certain epochs.\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        \"\"\"\n",
    "        :param patience: how many epochs to wait before stopping when loss is\n",
    "               not improving\n",
    "        :param min_delta: minimum difference between new loss and old loss for\n",
    "               new loss to be considered as an improvement\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss == None:\n",
    "            self.best_loss = val_loss\n",
    "        elif self.best_loss - val_loss > self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            # reset counter if validation loss improves\n",
    "            self.counter = 0\n",
    "        elif self.best_loss - val_loss < self.min_delta:\n",
    "            self.counter += 1\n",
    "            print(f\"INFO: Early stopping counter {self.counter} of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                print('INFO: Early stopping')\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e5ace60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# possibly needed in future if using larger dataset w/ dataloader\n",
    "\n",
    "# embedding_list = np.empty(layers.shape, dtype=object)\n",
    "# for i in range(len(embedding_list)):\n",
    "#     embedding_list[i] = []\n",
    "# for num_layer, name  in enumerate(layernames):\n",
    "#     embedding_list[num_layer].append(activations[name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73aa86e9",
   "metadata": {},
   "source": [
    "# Image Encoding"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c1f0b5dc",
   "metadata": {},
   "source": [
    "image = preprocess(Image.open(\"square.jpg\")).unsqueeze(0).to(device)\n",
    "image_features = model.encode_image(image.cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b0f015",
   "metadata": {},
   "source": [
    "# Text Encoding"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ad6e1007",
   "metadata": {},
   "source": [
    "prompt = \"square shaped cat\"\n",
    "txt, weight, stop = split_prompt(prompt)\n",
    "\n",
    "text_features = model.encode_text(clip.tokenize(txt).to(device)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cca0b121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_tensors(img_filename, img_dir=\"\"):\n",
    "    image = preprocess(Image.open(img_dir + img_filename)).unsqueeze(0).to(device)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0045a045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_images(img_filename, img_dir=\"\"):\n",
    "    image = preprocess(Image.open(img_dir + img_filename)).unsqueeze(0).to(device)\n",
    "\n",
    "    image_features = model.encode_image(image.cuda())\n",
    "    return image_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b4b54b",
   "metadata": {},
   "source": [
    "Load an example image"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5747d983",
   "metadata": {},
   "source": [
    "# PIL.Image.open\n",
    "# concept_filenames[0]\n",
    "\n",
    "Image.open('tcav/concepts/striped/striped_0086.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811a5736",
   "metadata": {},
   "source": [
    "# Define Linear Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a126a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearClassifier(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear1 = torch.nn.Linear(num_features, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, input_x):\n",
    "        x = self.linear1(input_x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84db4f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_filenames = os.listdir('tcav/concepts/striped')\n",
    "negative_filenames = os.listdir('tcav/concepts/random_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "015a3200",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_concept = [encode_images(filename, 'tcav/concepts/striped/') for filename in positive_filenames]\n",
    "#positive_concept = torch.vstack(positive_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f923dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_concept = [encode_images(filename, 'tcav/concepts/random_0/') for filename in negative_filenames]\n",
    "#negative_concept = torch.vstack(negative_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "065e7800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_concept = positive_concept + negative_concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4591bdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_concepts = torch.vstack(positive_concept)\n",
    "negative_concepts = torch.vstack(negative_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3226efc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_img_tensors = [get_img_tensors(img,'tcav/concepts/striped/') for img in positive_filenames]\n",
    "positive_img_tensors = torch.vstack(positive_img_tensors)\n",
    "negative_img_tensors = [get_img_tensors(img,'tcav/concepts/random_0/') for img in negative_filenames]\n",
    "negative_img_tensors = torch.vstack(negative_img_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5b3ca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_img_tensors = torch.vstack([positive_img_tensors, negative_img_tensors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6121aa50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folder = '/home/valentinedhauteville/dataset/tcav/concepts/'\n",
    "image_classes = ['smeared','dotted', 'knitted', 'spiralled', 'chequered']\n",
    "image_tensors = np.zeros((len(image_classes),2), dtype=object) # [{positive, negative}, image_class]\n",
    "num_rand_folders = 4\n",
    "for num_class, img_class in enumerate(image_classes):\n",
    "    class_folder  = folder + img_class + '/'\n",
    "    random_folder = folder + f'random_{num_class % 4}/'\n",
    "    pos_files = os.listdir(class_folder)\n",
    "    neg_files = os.listdir(random_folder)\n",
    "    image_tensors[num_class,0] = torch.vstack([get_img_tensors(img, class_folder) for img in pos_files]) # positive tensors\n",
    "    image_tensors[num_class,1] = torch.vstack([get_img_tensors(img, random_folder) for img in neg_files]) # negative tensors\n",
    "    \n",
    "#     pos_encoding = [encode_images(filename) for filename in pos_files]\n",
    "#     neg_encoding = [encode_images(filename) for filename in neg_files]\n",
    "#     pos_concepts = torch.vstack(pos_encoding)\n",
    "#     neg_concepts = torch.vstack(neg_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8952e10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([85, 3, 224, 224])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_img_tensors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fd7b57",
   "metadata": {},
   "source": [
    "## Get image class embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1cac60",
   "metadata": {},
   "source": [
    "### Register hooks for activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "57a45a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assist from https://web.stanford.edu/~nanbhas/blog/forward-hooks-pytorch/\n",
    "activations = {}\n",
    "gradients = {}\n",
    "def getActivation(name):\n",
    "    # the hook signature \n",
    "    def hook(model, input, output):\n",
    "        \n",
    "        output.requires_grad_(True)\n",
    "        output.retain_grad()\n",
    "        gradients[name] = output.grad\n",
    "        activations[name] = output.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "971a39aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hooks = []\n",
    "layers = np.concatenate([[model.visual.conv1], model.visual.transformer.resblocks[1::2], [model.visual]])\n",
    "layernames = np.concatenate([['layer0'], [f'layer{i}' for i in range(1,13,2)],['full']], dtype=str)\n",
    "for l, n in zip(layers, layernames):\n",
    "    hooks.append(l.register_forward_hook(getActivation(n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1766d84",
   "metadata": {},
   "source": [
    "### Push images through model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cadfc7da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 768, 7, 7])\n",
      "torch.Size([50, 120, 768])\n",
      "torch.Size([50, 120, 768])\n",
      "torch.Size([50, 120, 768])\n",
      "torch.Size([50, 120, 768])\n",
      "torch.Size([50, 120, 768])\n",
      "torch.Size([50, 120, 768])\n",
      "torch.Size([120, 512])\n",
      "torch.Size([120, 768, 7, 7])\n",
      "torch.Size([50, 120, 768])\n",
      "torch.Size([50, 120, 768])\n",
      "torch.Size([50, 120, 768])\n",
      "torch.Size([50, 120, 768])\n",
      "torch.Size([50, 120, 768])\n",
      "torch.Size([50, 120, 768])\n",
      "torch.Size([120, 512])\n",
      "torch.Size([120, 768, 7, 7])\n",
      "torch.Size([50, 120, 768])\n",
      "torch.Size([50, 120, 768])\n",
      "torch.Size([50, 120, 768])\n",
      "torch.Size([50, 120, 768])\n",
      "torch.Size([50, 120, 768])\n",
      "torch.Size([50, 120, 768])\n",
      "torch.Size([120, 512])\n",
      "torch.Size([120, 768, 7, 7])\n",
      "torch.Size([50, 120, 768])\n",
      "torch.Size([50, 120, 768])\n",
      "torch.Size([50, 120, 768])\n",
      "torch.Size([50, 120, 768])\n",
      "torch.Size([50, 120, 768])\n",
      "torch.Size([50, 120, 768])\n",
      "torch.Size([120, 512])\n",
      "torch.Size([120, 768, 7, 7])\n",
      "torch.Size([50, 120, 768])\n",
      "torch.Size([50, 120, 768])\n",
      "torch.Size([50, 120, 768])\n",
      "torch.Size([50, 120, 768])\n",
      "torch.Size([50, 120, 768])\n",
      "torch.Size([50, 120, 768])\n",
      "torch.Size([120, 512])\n",
      "torch.Size([100, 768, 7, 7])\n",
      "torch.Size([50, 100, 768])\n",
      "torch.Size([50, 100, 768])\n",
      "torch.Size([50, 100, 768])\n",
      "torch.Size([50, 100, 768])\n",
      "torch.Size([50, 100, 768])\n",
      "torch.Size([50, 100, 768])\n",
      "torch.Size([100, 512])\n",
      "torch.Size([90, 768, 7, 7])\n",
      "torch.Size([50, 90, 768])\n",
      "torch.Size([50, 90, 768])\n",
      "torch.Size([50, 90, 768])\n",
      "torch.Size([50, 90, 768])\n",
      "torch.Size([50, 90, 768])\n",
      "torch.Size([50, 90, 768])\n",
      "torch.Size([90, 512])\n",
      "torch.Size([95, 768, 7, 7])\n",
      "torch.Size([50, 95, 768])\n",
      "torch.Size([50, 95, 768])\n",
      "torch.Size([50, 95, 768])\n",
      "torch.Size([50, 95, 768])\n",
      "torch.Size([50, 95, 768])\n",
      "torch.Size([50, 95, 768])\n",
      "torch.Size([95, 512])\n",
      "torch.Size([97, 768, 7, 7])\n",
      "torch.Size([50, 97, 768])\n",
      "torch.Size([50, 97, 768])\n",
      "torch.Size([50, 97, 768])\n",
      "torch.Size([50, 97, 768])\n",
      "torch.Size([50, 97, 768])\n",
      "torch.Size([50, 97, 768])\n",
      "torch.Size([97, 512])\n",
      "torch.Size([93, 768, 7, 7])\n",
      "torch.Size([50, 93, 768])\n",
      "torch.Size([50, 93, 768])\n",
      "torch.Size([50, 93, 768])\n",
      "torch.Size([50, 93, 768])\n",
      "torch.Size([50, 93, 768])\n",
      "torch.Size([50, 93, 768])\n",
      "torch.Size([93, 512])\n"
     ]
    }
   ],
   "source": [
    "# concept_embeddings = np.zeros((len(image_classes),2), dtype=object) # shape=[class, {positive, negative}]\n",
    "per_layer_embeddings = np.zeros((len(image_classes), 2, len(layers)), dtype=object)\n",
    "\n",
    "for pos_or_neg in [0,1]:\n",
    "    for i in range(len(image_classes)):\n",
    "#         concept_embeddings[i, pos_or_neg] = model.encode_image(image_tensors[i, pos_or_neg])\n",
    "        model.encode_image(image_tensors[i, pos_or_neg]) # push through model\n",
    "\n",
    "        # pull activations from each layer (incl. final layer with full visual)\n",
    "        for layer, name in enumerate(layernames):\n",
    "            per_layer_embeddings[i, pos_or_neg, layer] = activations[name]\n",
    "            print(activations[name].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f7de1518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = f\"{[f'{i}_' for i in image_classes]}_per_layer_embeddings.pkl\"\n",
    "filename = \"smeared_dotted_knitted_spiralled_chequered_per_layer_embeddings.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a09e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename,\"wb\") as f:\n",
    "    pickle.dump(per_layer_embeddings,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b22a3a",
   "metadata": {},
   "source": [
    "### Create target dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "42db4bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = np.zeros((len(image_classes)), dtype=object)\n",
    "for i in range(len(image_classes)):\n",
    "    positive_labels = torch.tensor(image_tensors[i,0].shape[0] * [1])\n",
    "    negative_labels = torch.tensor(image_tensors[i,1].shape[0] * [0])\n",
    "    class_labels[i] = torch.cat([positive_labels, negative_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "796a139d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 3, 224, 224])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "class_dataloaders = np.zeros((len(image_classes),3), dtype=object)\n",
    "for i in range(len(image_classes)):\n",
    "    # dataloaders = []\n",
    "    # val_dataloaders = []\n",
    "    # test_dataloaders = []\n",
    "    for train in training_data:\n",
    "        dataset = TensorDataset(train, class_labels)\n",
    "        train_dataset, val_dataset = torch.utils.data.random_split(dataset, [ len_train, train.shape[0] -len_train])\n",
    "        loader = DataLoader(train_dataset, batch_size=2,\n",
    "                        pin_memory=False, shuffle=True)\n",
    "        val_loader = DataLoader(train_dataset, batch_size=2,\n",
    "                        pin_memory=False, shuffle=True)\n",
    "        dataloaders.append(loader)\n",
    "        val_dataloaders.append(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f60c49",
   "metadata": {},
   "source": [
    "# Collect features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06ac35f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.encode_image(all_img_tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53ac0fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_inputs = [\"zebra\"] * len(positive_concept) + [\"not zebra\"] * len(negative_concept)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3d5ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_inputs = [clip.tokenize([text_input]).to(device) for text_input in text_inputs]\n",
    "target = torch.vstack([model.encode_text(text_input).float() for text_input in text_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a26031a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_layer_gradients = {}\n",
    "all_layer_activations = {}\n",
    "for layer, name in zip(layers, layernames):\n",
    "    layer_gradients = []\n",
    "    layer_activations = []\n",
    "    with Hook(layer) as hook:\n",
    "\n",
    "        # Do a forward and backward pass.\n",
    "        output = model.encode_image(all_img_tensors)\n",
    "        output.backward(target)\n",
    "\n",
    "        grad = hook.gradient.float()\n",
    "        act = hook.activation.float()\n",
    "        layer_gradients.append(grad)\n",
    "        layer_activations.append(act)\n",
    "    all_layer_gradients[name] = layer_gradients\n",
    "    all_layer_activations[name] = layer_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dd031139",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_layer_gradients.pkl\",\"wb\") as f:\n",
    "    pickle.dump(all_layer_gradients,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f691e309",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_layer_activations.pkl\",\"wb\") as f:\n",
    "    pickle.dump(all_layer_activations,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618b4f69",
   "metadata": {},
   "source": [
    "# Process features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "65e7cfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data =  []\n",
    "linear_classifier_sizes = []\n",
    "for key in all_layer_gradients.keys():\n",
    "    training_data.append(all_layer_gradients[key][0].view(85,-1))\n",
    "    linear_classifier_sizes.append(all_layer_gradients[key][0].view(85,-1).shape[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd8e374",
   "metadata": {},
   "source": [
    "# Assemble training data for all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc730e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_labels = torch.tensor(positive_concepts.shape[0] * [1])\n",
    "negative_labels = torch.tensor(negative_concepts.shape[0] * [0])\n",
    "# training_data = torch.vstack([positive_concepts, negative_concepts])\n",
    "class_labels = torch.cat([positive_labels, negative_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d1ea31",
   "metadata": {},
   "source": [
    "Assemble validation data for all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c6002583",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train = int( train.shape[0] * 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7d57a8d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x7f1b65abe670>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "af4db558",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [ len_train, train.shape[0]-len_train] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ba30f3",
   "metadata": {},
   "source": [
    "# Create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "624b050c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "dataloaders = []\n",
    "val_dataloaders = []\n",
    "for train in training_data:\n",
    "    dataset = TensorDataset(train, class_labels)\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [ len_train, train.shape[0] -len_train])\n",
    "    loader = DataLoader(train_dataset, batch_size=2,\n",
    "                    pin_memory=False, shuffle=True)\n",
    "    val_loader = DataLoader(train_dataset, batch_size=2,\n",
    "                    pin_memory=False, shuffle=True)\n",
    "    dataloaders.append(loader)\n",
    "    val_dataloaders.append(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b62cd62",
   "metadata": {},
   "source": [
    "# Create classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cdc0def2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = []\n",
    "for classifier_size in linear_classifier_sizes:\n",
    "    \n",
    "    classifiers.append(LinearClassifier(classifier_size))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaccf7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1116f271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(classifier, dataloader, val_dataloader):\n",
    "    clf = classifier.cuda()\n",
    "    early_stopping = EarlyStopping()\n",
    "    optimizer = torch.optim.SGD(clf.parameters(), lr=0.001)\n",
    "    for it in range(n_epochs):\n",
    "        for i, data in enumerate(dataloader,0):\n",
    "            inputs, labels = data\n",
    "            inputs = Variable(inputs, requires_grad=True)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = clf(inputs.cuda().float())\n",
    "\n",
    "            loss = criterion(outputs.cuda().float(), labels.cuda().reshape(-1,1).float())\n",
    "            loss.backward()\n",
    "            \n",
    "            \n",
    "            optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(val_dataloader,0):\n",
    "                inputs, labels = data\n",
    "                inputs = Variable(inputs)\n",
    "                outputs = clf(inputs.cuda().float())\n",
    "\n",
    "                loss = criterion(outputs.cuda().float(), labels.cuda().reshape(-1,1).float()) \n",
    "        \n",
    "            early_stopping(loss)\n",
    "        if it % 10 == 0:\n",
    "            pass\n",
    "        if early_stopping.early_stop:\n",
    "            print(loss)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "37b30d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torch.utils.data.dataloader.DataLoader at 0x7f1b65ade9a0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f1b64662850>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f1b64662c40>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f1b64662820>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f1b64662610>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f1b65a7fcd0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f1b65a854c0>]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9248d80",
   "metadata": {},
   "source": [
    "# Training Classifiers Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c223ded7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearClassifier(\n",
      "  (linear1): Linear(in_features=37632, out_features=1, bias=True)\n",
      ")\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 4 of 5\n",
      "INFO: Early stopping counter 5 of 5\n",
      "INFO: Early stopping\n",
      "tensor(0.0622, device='cuda:0')\n",
      "trained a classifier\n",
      "LinearClassifier(\n",
      "  (linear1): Linear(in_features=38400, out_features=1, bias=True)\n",
      ")\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 4 of 5\n",
      "INFO: Early stopping counter 5 of 5\n",
      "INFO: Early stopping\n",
      "tensor(0.4219, device='cuda:0')\n",
      "trained a classifier\n",
      "LinearClassifier(\n",
      "  (linear1): Linear(in_features=38400, out_features=1, bias=True)\n",
      ")\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 4 of 5\n",
      "INFO: Early stopping counter 5 of 5\n",
      "INFO: Early stopping\n",
      "tensor(0.4266, device='cuda:0')\n",
      "trained a classifier\n",
      "LinearClassifier(\n",
      "  (linear1): Linear(in_features=38400, out_features=1, bias=True)\n",
      ")\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 4 of 5\n",
      "INFO: Early stopping counter 5 of 5\n",
      "INFO: Early stopping\n",
      "tensor(0.4683, device='cuda:0')\n",
      "trained a classifier\n",
      "LinearClassifier(\n",
      "  (linear1): Linear(in_features=38400, out_features=1, bias=True)\n",
      ")\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 4 of 5\n",
      "INFO: Early stopping counter 5 of 5\n",
      "INFO: Early stopping\n",
      "tensor(0.5918, device='cuda:0')\n",
      "trained a classifier\n",
      "LinearClassifier(\n",
      "  (linear1): Linear(in_features=38400, out_features=1, bias=True)\n",
      ")\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 4 of 5\n",
      "INFO: Early stopping counter 5 of 5\n",
      "INFO: Early stopping\n",
      "tensor(0.7382, device='cuda:0')\n",
      "trained a classifier\n",
      "LinearClassifier(\n",
      "  (linear1): Linear(in_features=38400, out_features=1, bias=True)\n",
      ")\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 4 of 5\n",
      "INFO: Early stopping counter 5 of 5\n",
      "INFO: Early stopping\n",
      "tensor(0.7368, device='cuda:0')\n",
      "trained a classifier\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "for classifier, dataloader, val_dataloader in zip(classifiers, dataloaders, val_dataloaders):\n",
    "    print(classifier)\n",
    "    train_classifier(classifier, dataloader,val_dataloader)\n",
    "    print(\"trained a classifier\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "895c8c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"cached_classifiers.pkl\",\"wb\") as f:\n",
    "    pickle.dump(classifiers,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a01bbdb",
   "metadata": {},
   "source": [
    "# Get orthogonal vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2164907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_orthogonal_vector(classifier, classifier_size):\n",
    "    weight, bias = [param for param in classifier.parameters()]\n",
    "    cav_vector = weight.squeeze().cpu().detach().numpy()\n",
    "    orthonormal_vector = np.random.randn(classifier_size)  # take a random vector\n",
    "    orthonormal_vector -= orthonormal_vector.dot(cav_vector) * cav_vector / np.linalg.norm(cav_vector)**2\n",
    "    orthonormal_vector /= np.linalg.norm(orthonormal_vector) \n",
    "    return orthonormal_vector, cav_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e831105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cavs = [get_orthogonal_vector(classifier, classifier_size) for classifier, classifier_size in zip(classifiers, linear_classifier_sizes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599946ba",
   "metadata": {},
   "source": [
    "# Check orthogonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cb4f6821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.1899124090566926e-10,\n",
       " 5.035230956143555e-10,\n",
       " 4.686241134727043e-10,\n",
       " 2.495054813797526e-11,\n",
       " -3.7813513171364166e-11,\n",
       " -8.493784451821251e-12,\n",
       " 5.064932414450274e-11]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.dot(orthonormal_vector,cav_vector) for orthonormal_vector, cav_vector in cavs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b9e46e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(3.1576, device='cuda:0')\n",
      "1\n",
      "tensor(0.9237, device='cuda:0')\n",
      "2\n",
      "tensor(2.2916, device='cuda:0')\n",
      "3\n",
      "tensor(1.3362, device='cuda:0')\n",
      "4\n",
      "tensor(0.2581, device='cuda:0')\n",
      "5\n",
      "tensor(0.9651, device='cuda:0')\n",
      "6\n",
      "tensor(-0.2086, device='cuda:0')\n",
      "7\n",
      "tensor(3.5177, device='cuda:0')\n",
      "8\n",
      "tensor(1.9983, device='cuda:0')\n",
      "9\n",
      "tensor(2.2666, device='cuda:0')\n",
      "10\n",
      "tensor(2.7793, device='cuda:0')\n",
      "11\n",
      "tensor(1.3769, device='cuda:0')\n",
      "12\n",
      "tensor(2.6567, device='cuda:0')\n",
      "13\n",
      "tensor(3.3030, device='cuda:0')\n",
      "14\n",
      "tensor(-0.0600, device='cuda:0')\n",
      "15\n",
      "tensor(1.2082, device='cuda:0')\n",
      "16\n",
      "tensor(2.0105, device='cuda:0')\n",
      "17\n",
      "tensor(2.5700, device='cuda:0')\n",
      "18\n",
      "tensor(3.3431, device='cuda:0')\n",
      "19\n",
      "tensor(-0.1400, device='cuda:0')\n",
      "20\n",
      "tensor(1.3527, device='cuda:0')\n",
      "21\n",
      "tensor(1.8662, device='cuda:0')\n",
      "22\n",
      "tensor(-0.1866, device='cuda:0')\n",
      "23\n",
      "tensor(2.8525, device='cuda:0')\n",
      "24\n",
      "tensor(0.3161, device='cuda:0')\n",
      "25\n",
      "tensor(0.6625, device='cuda:0')\n",
      "26\n",
      "tensor(4.6133, device='cuda:0')\n",
      "27\n",
      "tensor(1.4815, device='cuda:0')\n",
      "28\n",
      "tensor(2.0673, device='cuda:0')\n",
      "29\n",
      "tensor(-1.6110, device='cuda:0')\n",
      "30\n",
      "tensor(-0.6313, device='cuda:0')\n",
      "31\n",
      "tensor(1.4852, device='cuda:0')\n",
      "32\n",
      "tensor(-0.9702, device='cuda:0')\n",
      "33\n",
      "tensor(1.2242, device='cuda:0')\n",
      "34\n",
      "tensor(0.7463, device='cuda:0')\n",
      "35\n",
      "tensor(-0.8205, device='cuda:0')\n",
      "36\n",
      "tensor(2.7733, device='cuda:0')\n",
      "37\n",
      "tensor(-0.8204, device='cuda:0')\n",
      "38\n",
      "tensor(-0.4126, device='cuda:0')\n",
      "39\n",
      "tensor(2.5732, device='cuda:0')\n",
      "40\n",
      "tensor(2.8331, device='cuda:0')\n",
      "41\n",
      "tensor(0.9775, device='cuda:0')\n",
      "42\n",
      "tensor(0.0273, device='cuda:0')\n",
      "43\n",
      "tensor(1.6418, device='cuda:0')\n",
      "44\n",
      "tensor(3.1546, device='cuda:0')\n",
      "45\n",
      "tensor(0.1406, device='cuda:0')\n",
      "46\n",
      "tensor(2.8893, device='cuda:0')\n",
      "47\n",
      "tensor(-0.6109, device='cuda:0')\n",
      "48\n",
      "tensor(1.7399, device='cuda:0')\n",
      "49\n",
      "tensor(1.3440, device='cuda:0')\n",
      "50\n",
      "tensor(0.4699, device='cuda:0')\n",
      "51\n",
      "tensor(-0.1536, device='cuda:0')\n",
      "52\n",
      "tensor(-1.2936, device='cuda:0')\n",
      "53\n",
      "tensor(-2.1460, device='cuda:0')\n",
      "54\n",
      "tensor(-2.5841, device='cuda:0')\n",
      "55\n",
      "tensor(-2.1245, device='cuda:0')\n",
      "56\n",
      "tensor(-1.6007, device='cuda:0')\n",
      "57\n",
      "tensor(-2.1399, device='cuda:0')\n",
      "58\n",
      "tensor(-1.6892, device='cuda:0')\n",
      "59\n",
      "tensor(-2.4402, device='cuda:0')\n",
      "60\n",
      "tensor(-1.4207, device='cuda:0')\n",
      "61\n",
      "tensor(-2.0596, device='cuda:0')\n",
      "62\n",
      "tensor(-1.7742, device='cuda:0')\n",
      "63\n",
      "tensor(-2.5629, device='cuda:0')\n",
      "64\n",
      "tensor(-1.1148, device='cuda:0')\n",
      "65\n",
      "tensor(-1.6726, device='cuda:0')\n",
      "66\n",
      "tensor(-1.4799, device='cuda:0')\n",
      "67\n",
      "tensor(-0.8493, device='cuda:0')\n",
      "68\n",
      "tensor(-2.1513, device='cuda:0')\n",
      "69\n",
      "tensor(-0.2904, device='cuda:0')\n",
      "70\n",
      "tensor(-1.0955, device='cuda:0')\n",
      "71\n",
      "tensor(-1.4819, device='cuda:0')\n",
      "72\n",
      "tensor(-1.3047, device='cuda:0')\n",
      "73\n",
      "tensor(1.4018, device='cuda:0')\n",
      "74\n",
      "tensor(-1.2494, device='cuda:0')\n",
      "75\n",
      "tensor(-2.3232, device='cuda:0')\n",
      "76\n",
      "tensor(-1.3106, device='cuda:0')\n",
      "77\n",
      "tensor(0.1450, device='cuda:0')\n",
      "78\n",
      "tensor(-2.8356, device='cuda:0')\n",
      "79\n",
      "tensor(-1.5138, device='cuda:0')\n",
      "80\n",
      "tensor(-0.6170, device='cuda:0')\n",
      "81\n",
      "tensor(0.7691, device='cuda:0')\n",
      "82\n",
      "tensor(-0.3107, device='cuda:0')\n",
      "83\n",
      "tensor(-2.4926, device='cuda:0')\n",
      "84\n",
      "tensor(-1.1642, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(85):\n",
    "    print(i)\n",
    "    print(torch.dot(all_layer_gradients['layer0'][0].view(85,-1)[i], torch.tensor(cavs[0][1]).cuda() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f9e039ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(5.6702, device='cuda:0')\n",
      "1\n",
      "tensor(3.9695, device='cuda:0')\n",
      "2\n",
      "tensor(1.4329, device='cuda:0')\n",
      "3\n",
      "tensor(0.9419, device='cuda:0')\n",
      "4\n",
      "tensor(0.0106, device='cuda:0')\n",
      "5\n",
      "tensor(1.2248, device='cuda:0')\n",
      "6\n",
      "tensor(-0.0851, device='cuda:0')\n",
      "7\n",
      "tensor(-0.1159, device='cuda:0')\n",
      "8\n",
      "tensor(0.7661, device='cuda:0')\n",
      "9\n",
      "tensor(0.6483, device='cuda:0')\n",
      "10\n",
      "tensor(0.0589, device='cuda:0')\n",
      "11\n",
      "tensor(0.8473, device='cuda:0')\n",
      "12\n",
      "tensor(0.0159, device='cuda:0')\n",
      "13\n",
      "tensor(0.9787, device='cuda:0')\n",
      "14\n",
      "tensor(1.2873, device='cuda:0')\n",
      "15\n",
      "tensor(0.5961, device='cuda:0')\n",
      "16\n",
      "tensor(0.4017, device='cuda:0')\n",
      "17\n",
      "tensor(-0.1369, device='cuda:0')\n",
      "18\n",
      "tensor(0.7163, device='cuda:0')\n",
      "19\n",
      "tensor(0.8413, device='cuda:0')\n",
      "20\n",
      "tensor(-0.0288, device='cuda:0')\n",
      "21\n",
      "tensor(0.6438, device='cuda:0')\n",
      "22\n",
      "tensor(0.8506, device='cuda:0')\n",
      "23\n",
      "tensor(0.8276, device='cuda:0')\n",
      "24\n",
      "tensor(0.8787, device='cuda:0')\n",
      "25\n",
      "tensor(1.0171, device='cuda:0')\n",
      "26\n",
      "tensor(1.0181, device='cuda:0')\n",
      "27\n",
      "tensor(-0.0558, device='cuda:0')\n",
      "28\n",
      "tensor(-0.0678, device='cuda:0')\n",
      "29\n",
      "tensor(0.5698, device='cuda:0')\n",
      "30\n",
      "tensor(0.7449, device='cuda:0')\n",
      "31\n",
      "tensor(-0.2129, device='cuda:0')\n",
      "32\n",
      "tensor(0.8939, device='cuda:0')\n",
      "33\n",
      "tensor(-0.0617, device='cuda:0')\n",
      "34\n",
      "tensor(0.4420, device='cuda:0')\n",
      "35\n",
      "tensor(0.8251, device='cuda:0')\n",
      "36\n",
      "tensor(0.7802, device='cuda:0')\n",
      "37\n",
      "tensor(0.8709, device='cuda:0')\n",
      "38\n",
      "tensor(0.7960, device='cuda:0')\n",
      "39\n",
      "tensor(0.7357, device='cuda:0')\n",
      "40\n",
      "tensor(-0.0484, device='cuda:0')\n",
      "41\n",
      "tensor(-0.0743, device='cuda:0')\n",
      "42\n",
      "tensor(0.7149, device='cuda:0')\n",
      "43\n",
      "tensor(1.0413, device='cuda:0')\n",
      "44\n",
      "tensor(-0.0377, device='cuda:0')\n",
      "45\n",
      "tensor(-0.1663, device='cuda:0')\n",
      "46\n",
      "tensor(-0.2460, device='cuda:0')\n",
      "47\n",
      "tensor(-0.0858, device='cuda:0')\n",
      "48\n",
      "tensor(0.7927, device='cuda:0')\n",
      "49\n",
      "tensor(0.9420, device='cuda:0')\n",
      "50\n",
      "tensor(-0.9635, device='cuda:0')\n",
      "51\n",
      "tensor(-1.0350, device='cuda:0')\n",
      "52\n",
      "tensor(-0.6800, device='cuda:0')\n",
      "53\n",
      "tensor(-0.7099, device='cuda:0')\n",
      "54\n",
      "tensor(0.0151, device='cuda:0')\n",
      "55\n",
      "tensor(-1.0709, device='cuda:0')\n",
      "56\n",
      "tensor(-0.4244, device='cuda:0')\n",
      "57\n",
      "tensor(-0.7772, device='cuda:0')\n",
      "58\n",
      "tensor(-1.0782, device='cuda:0')\n",
      "59\n",
      "tensor(-0.7267, device='cuda:0')\n",
      "60\n",
      "tensor(-0.9144, device='cuda:0')\n",
      "61\n",
      "tensor(-1.2305, device='cuda:0')\n",
      "62\n",
      "tensor(-0.6857, device='cuda:0')\n",
      "63\n",
      "tensor(-0.8735, device='cuda:0')\n",
      "64\n",
      "tensor(-0.8235, device='cuda:0')\n",
      "65\n",
      "tensor(-0.2781, device='cuda:0')\n",
      "66\n",
      "tensor(0.0222, device='cuda:0')\n",
      "67\n",
      "tensor(-1.2045, device='cuda:0')\n",
      "68\n",
      "tensor(-0.0633, device='cuda:0')\n",
      "69\n",
      "tensor(-0.6936, device='cuda:0')\n",
      "70\n",
      "tensor(-0.7994, device='cuda:0')\n",
      "71\n",
      "tensor(-0.7645, device='cuda:0')\n",
      "72\n",
      "tensor(-0.9656, device='cuda:0')\n",
      "73\n",
      "tensor(-1.8796, device='cuda:0')\n",
      "74\n",
      "tensor(-0.0593, device='cuda:0')\n",
      "75\n",
      "tensor(-1.3407, device='cuda:0')\n",
      "76\n",
      "tensor(-1.1507, device='cuda:0')\n",
      "77\n",
      "tensor(-1.1619, device='cuda:0')\n",
      "78\n",
      "tensor(-0.2690, device='cuda:0')\n",
      "79\n",
      "tensor(-0.0748, device='cuda:0')\n",
      "80\n",
      "tensor(-0.2692, device='cuda:0')\n",
      "81\n",
      "tensor(-1.1729, device='cuda:0')\n",
      "82\n",
      "tensor(-1.3065, device='cuda:0')\n",
      "83\n",
      "tensor(-1.4695, device='cuda:0')\n",
      "84\n",
      "tensor(-0.0657, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(85):\n",
    "    print(i)\n",
    "    print(torch.dot(all_layer_gradients['layer1'][0].view(85,-1)[i], torch.tensor(cavs[1][1]).cuda() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d62ef92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(7.8871, device='cuda:0')\n",
      "1\n",
      "tensor(4.2670, device='cuda:0')\n",
      "2\n",
      "tensor(1.5204, device='cuda:0')\n",
      "3\n",
      "tensor(0.9167, device='cuda:0')\n",
      "4\n",
      "tensor(0.0608, device='cuda:0')\n",
      "5\n",
      "tensor(-0.0854, device='cuda:0')\n",
      "6\n",
      "tensor(0.5544, device='cuda:0')\n",
      "7\n",
      "tensor(0.8682, device='cuda:0')\n",
      "8\n",
      "tensor(0.0067, device='cuda:0')\n",
      "9\n",
      "tensor(0.0300, device='cuda:0')\n",
      "10\n",
      "tensor(1.0211, device='cuda:0')\n",
      "11\n",
      "tensor(-0.0455, device='cuda:0')\n",
      "12\n",
      "tensor(-0.2739, device='cuda:0')\n",
      "13\n",
      "tensor(-0.0963, device='cuda:0')\n",
      "14\n",
      "tensor(1.0677, device='cuda:0')\n",
      "15\n",
      "tensor(0.6390, device='cuda:0')\n",
      "16\n",
      "tensor(-0.1569, device='cuda:0')\n",
      "17\n",
      "tensor(0.4333, device='cuda:0')\n",
      "18\n",
      "tensor(0.6834, device='cuda:0')\n",
      "19\n",
      "tensor(0.7324, device='cuda:0')\n",
      "20\n",
      "tensor(0.7751, device='cuda:0')\n",
      "21\n",
      "tensor(0.6463, device='cuda:0')\n",
      "22\n",
      "tensor(0.5030, device='cuda:0')\n",
      "23\n",
      "tensor(0.0405, device='cuda:0')\n",
      "24\n",
      "tensor(0.7992, device='cuda:0')\n",
      "25\n",
      "tensor(0.7743, device='cuda:0')\n",
      "26\n",
      "tensor(0.9330, device='cuda:0')\n",
      "27\n",
      "tensor(0.0239, device='cuda:0')\n",
      "28\n",
      "tensor(0.6674, device='cuda:0')\n",
      "29\n",
      "tensor(0.4182, device='cuda:0')\n",
      "30\n",
      "tensor(-0.0596, device='cuda:0')\n",
      "31\n",
      "tensor(0.8032, device='cuda:0')\n",
      "32\n",
      "tensor(0.9661, device='cuda:0')\n",
      "33\n",
      "tensor(1.0739, device='cuda:0')\n",
      "34\n",
      "tensor(-0.2209, device='cuda:0')\n",
      "35\n",
      "tensor(-0.0424, device='cuda:0')\n",
      "36\n",
      "tensor(0.7078, device='cuda:0')\n",
      "37\n",
      "tensor(0.7547, device='cuda:0')\n",
      "38\n",
      "tensor(0.6074, device='cuda:0')\n",
      "39\n",
      "tensor(-0.1312, device='cuda:0')\n",
      "40\n",
      "tensor(0.7353, device='cuda:0')\n",
      "41\n",
      "tensor(-0.1338, device='cuda:0')\n",
      "42\n",
      "tensor(-0.0642, device='cuda:0')\n",
      "43\n",
      "tensor(0.8749, device='cuda:0')\n",
      "44\n",
      "tensor(0.6490, device='cuda:0')\n",
      "45\n",
      "tensor(-0.0914, device='cuda:0')\n",
      "46\n",
      "tensor(-0.0699, device='cuda:0')\n",
      "47\n",
      "tensor(0.6181, device='cuda:0')\n",
      "48\n",
      "tensor(-0.1484, device='cuda:0')\n",
      "49\n",
      "tensor(0.8723, device='cuda:0')\n",
      "50\n",
      "tensor(-0.8999, device='cuda:0')\n",
      "51\n",
      "tensor(-0.8893, device='cuda:0')\n",
      "52\n",
      "tensor(-0.1330, device='cuda:0')\n",
      "53\n",
      "tensor(-0.5637, device='cuda:0')\n",
      "54\n",
      "tensor(-0.8073, device='cuda:0')\n",
      "55\n",
      "tensor(-0.9770, device='cuda:0')\n",
      "56\n",
      "tensor(-0.5557, device='cuda:0')\n",
      "57\n",
      "tensor(-0.8896, device='cuda:0')\n",
      "58\n",
      "tensor(-0.9036, device='cuda:0')\n",
      "59\n",
      "tensor(-0.0834, device='cuda:0')\n",
      "60\n",
      "tensor(-0.8381, device='cuda:0')\n",
      "61\n",
      "tensor(-0.2544, device='cuda:0')\n",
      "62\n",
      "tensor(-0.7759, device='cuda:0')\n",
      "63\n",
      "tensor(-0.8614, device='cuda:0')\n",
      "64\n",
      "tensor(-0.8106, device='cuda:0')\n",
      "65\n",
      "tensor(-0.7104, device='cuda:0')\n",
      "66\n",
      "tensor(-0.0001, device='cuda:0')\n",
      "67\n",
      "tensor(-0.8717, device='cuda:0')\n",
      "68\n",
      "tensor(-0.8157, device='cuda:0')\n",
      "69\n",
      "tensor(-0.0148, device='cuda:0')\n",
      "70\n",
      "tensor(-0.6609, device='cuda:0')\n",
      "71\n",
      "tensor(-0.7425, device='cuda:0')\n",
      "72\n",
      "tensor(-0.8536, device='cuda:0')\n",
      "73\n",
      "tensor(-1.7675, device='cuda:0')\n",
      "74\n",
      "tensor(-0.2177, device='cuda:0')\n",
      "75\n",
      "tensor(-1.3445, device='cuda:0')\n",
      "76\n",
      "tensor(-0.9319, device='cuda:0')\n",
      "77\n",
      "tensor(-1.0712, device='cuda:0')\n",
      "78\n",
      "tensor(-1.2991, device='cuda:0')\n",
      "79\n",
      "tensor(-1.1497, device='cuda:0')\n",
      "80\n",
      "tensor(-1.3629, device='cuda:0')\n",
      "81\n",
      "tensor(-0.9397, device='cuda:0')\n",
      "82\n",
      "tensor(-1.2208, device='cuda:0')\n",
      "83\n",
      "tensor(-1.4255, device='cuda:0')\n",
      "84\n",
      "tensor(-0.3417, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(85):\n",
    "    print(i)\n",
    "    print(torch.dot(all_layer_gradients['layer3'][0].view(85,-1)[i], torch.tensor(cavs[2][1]).cuda() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a2cf16f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(5.0756, device='cuda:0')\n",
      "1\n",
      "tensor(3.6719, device='cuda:0')\n",
      "2\n",
      "tensor(0.8010, device='cuda:0')\n",
      "3\n",
      "tensor(0.4374, device='cuda:0')\n",
      "4\n",
      "tensor(0.3537, device='cuda:0')\n",
      "5\n",
      "tensor(0.5322, device='cuda:0')\n",
      "6\n",
      "tensor(0.0891, device='cuda:0')\n",
      "7\n",
      "tensor(0.4082, device='cuda:0')\n",
      "8\n",
      "tensor(0.0384, device='cuda:0')\n",
      "9\n",
      "tensor(0.0883, device='cuda:0')\n",
      "10\n",
      "tensor(0.0774, device='cuda:0')\n",
      "11\n",
      "tensor(0.0869, device='cuda:0')\n",
      "12\n",
      "tensor(0.0322, device='cuda:0')\n",
      "13\n",
      "tensor(0.4059, device='cuda:0')\n",
      "14\n",
      "tensor(0.4620, device='cuda:0')\n",
      "15\n",
      "tensor(0.1910, device='cuda:0')\n",
      "16\n",
      "tensor(0.2752, device='cuda:0')\n",
      "17\n",
      "tensor(0.2014, device='cuda:0')\n",
      "18\n",
      "tensor(0.2736, device='cuda:0')\n",
      "19\n",
      "tensor(0.3711, device='cuda:0')\n",
      "20\n",
      "tensor(0.2790, device='cuda:0')\n",
      "21\n",
      "tensor(0.3665, device='cuda:0')\n",
      "22\n",
      "tensor(0.3064, device='cuda:0')\n",
      "23\n",
      "tensor(0.4076, device='cuda:0')\n",
      "24\n",
      "tensor(0.3593, device='cuda:0')\n",
      "25\n",
      "tensor(0.3061, device='cuda:0')\n",
      "26\n",
      "tensor(0.4341, device='cuda:0')\n",
      "27\n",
      "tensor(0.1547, device='cuda:0')\n",
      "28\n",
      "tensor(0.3427, device='cuda:0')\n",
      "29\n",
      "tensor(0.0096, device='cuda:0')\n",
      "30\n",
      "tensor(0.3548, device='cuda:0')\n",
      "31\n",
      "tensor(0.2923, device='cuda:0')\n",
      "32\n",
      "tensor(0.0512, device='cuda:0')\n",
      "33\n",
      "tensor(0.5004, device='cuda:0')\n",
      "34\n",
      "tensor(0.1411, device='cuda:0')\n",
      "35\n",
      "tensor(0.4610, device='cuda:0')\n",
      "36\n",
      "tensor(0.0963, device='cuda:0')\n",
      "37\n",
      "tensor(0.2951, device='cuda:0')\n",
      "38\n",
      "tensor(0.2799, device='cuda:0')\n",
      "39\n",
      "tensor(0.3092, device='cuda:0')\n",
      "40\n",
      "tensor(0.3391, device='cuda:0')\n",
      "41\n",
      "tensor(0.0430, device='cuda:0')\n",
      "42\n",
      "tensor(0.2921, device='cuda:0')\n",
      "43\n",
      "tensor(0.4156, device='cuda:0')\n",
      "44\n",
      "tensor(0.0296, device='cuda:0')\n",
      "45\n",
      "tensor(0.3932, device='cuda:0')\n",
      "46\n",
      "tensor(0.0044, device='cuda:0')\n",
      "47\n",
      "tensor(0.3052, device='cuda:0')\n",
      "48\n",
      "tensor(0.0503, device='cuda:0')\n",
      "49\n",
      "tensor(0.4611, device='cuda:0')\n",
      "50\n",
      "tensor(-0.0267, device='cuda:0')\n",
      "51\n",
      "tensor(-0.2034, device='cuda:0')\n",
      "52\n",
      "tensor(-0.2486, device='cuda:0')\n",
      "53\n",
      "tensor(0.0533, device='cuda:0')\n",
      "54\n",
      "tensor(0.0631, device='cuda:0')\n",
      "55\n",
      "tensor(-0.3616, device='cuda:0')\n",
      "56\n",
      "tensor(0.0976, device='cuda:0')\n",
      "57\n",
      "tensor(0.0491, device='cuda:0')\n",
      "58\n",
      "tensor(0.0217, device='cuda:0')\n",
      "59\n",
      "tensor(-0.2367, device='cuda:0')\n",
      "60\n",
      "tensor(0.0336, device='cuda:0')\n",
      "61\n",
      "tensor(-0.3322, device='cuda:0')\n",
      "62\n",
      "tensor(-0.2198, device='cuda:0')\n",
      "63\n",
      "tensor(-0.2160, device='cuda:0')\n",
      "64\n",
      "tensor(-0.2008, device='cuda:0')\n",
      "65\n",
      "tensor(-0.1879, device='cuda:0')\n",
      "66\n",
      "tensor(-0.2120, device='cuda:0')\n",
      "67\n",
      "tensor(-0.2405, device='cuda:0')\n",
      "68\n",
      "tensor(-0.1789, device='cuda:0')\n",
      "69\n",
      "tensor(-0.1901, device='cuda:0')\n",
      "70\n",
      "tensor(0.1109, device='cuda:0')\n",
      "71\n",
      "tensor(-0.1490, device='cuda:0')\n",
      "72\n",
      "tensor(0.0483, device='cuda:0')\n",
      "73\n",
      "tensor(-0.4914, device='cuda:0')\n",
      "74\n",
      "tensor(-0.0435, device='cuda:0')\n",
      "75\n",
      "tensor(-0.3314, device='cuda:0')\n",
      "76\n",
      "tensor(-0.0133, device='cuda:0')\n",
      "77\n",
      "tensor(-0.3428, device='cuda:0')\n",
      "78\n",
      "tensor(-0.4205, device='cuda:0')\n",
      "79\n",
      "tensor(-0.3488, device='cuda:0')\n",
      "80\n",
      "tensor(-0.0808, device='cuda:0')\n",
      "81\n",
      "tensor(0.0256, device='cuda:0')\n",
      "82\n",
      "tensor(-0.3680, device='cuda:0')\n",
      "83\n",
      "tensor(-0.5857, device='cuda:0')\n",
      "84\n",
      "tensor(-0.3531, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(85):\n",
    "    print(i)\n",
    "    print(torch.dot(all_layer_gradients['layer5'][0].view(85,-1)[i], torch.tensor(cavs[3][1]).cuda() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fe0f731a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(-1.1681, device='cuda:0')\n",
      "1\n",
      "tensor(-0.4685, device='cuda:0')\n",
      "2\n",
      "tensor(0.0228, device='cuda:0')\n",
      "3\n",
      "tensor(0.1466, device='cuda:0')\n",
      "4\n",
      "tensor(0.1614, device='cuda:0')\n",
      "5\n",
      "tensor(0.0619, device='cuda:0')\n",
      "6\n",
      "tensor(0.1490, device='cuda:0')\n",
      "7\n",
      "tensor(0.1648, device='cuda:0')\n",
      "8\n",
      "tensor(0.1493, device='cuda:0')\n",
      "9\n",
      "tensor(0.1720, device='cuda:0')\n",
      "10\n",
      "tensor(0.2074, device='cuda:0')\n",
      "11\n",
      "tensor(0.1479, device='cuda:0')\n",
      "12\n",
      "tensor(0.3873, device='cuda:0')\n",
      "13\n",
      "tensor(0.1705, device='cuda:0')\n",
      "14\n",
      "tensor(0.2090, device='cuda:0')\n",
      "15\n",
      "tensor(0.2053, device='cuda:0')\n",
      "16\n",
      "tensor(0.0004, device='cuda:0')\n",
      "17\n",
      "tensor(0.0241, device='cuda:0')\n",
      "18\n",
      "tensor(0.1873, device='cuda:0')\n",
      "19\n",
      "tensor(0.1511, device='cuda:0')\n",
      "20\n",
      "tensor(0.0658, device='cuda:0')\n",
      "21\n",
      "tensor(0.2161, device='cuda:0')\n",
      "22\n",
      "tensor(0.1166, device='cuda:0')\n",
      "23\n",
      "tensor(0.2141, device='cuda:0')\n",
      "24\n",
      "tensor(0.0278, device='cuda:0')\n",
      "25\n",
      "tensor(0.0408, device='cuda:0')\n",
      "26\n",
      "tensor(0.2271, device='cuda:0')\n",
      "27\n",
      "tensor(0.1222, device='cuda:0')\n",
      "28\n",
      "tensor(0.0928, device='cuda:0')\n",
      "29\n",
      "tensor(0.1335, device='cuda:0')\n",
      "30\n",
      "tensor(0.1590, device='cuda:0')\n",
      "31\n",
      "tensor(0.0411, device='cuda:0')\n",
      "32\n",
      "tensor(0.2314, device='cuda:0')\n",
      "33\n",
      "tensor(0.0030, device='cuda:0')\n",
      "34\n",
      "tensor(0.1015, device='cuda:0')\n",
      "35\n",
      "tensor(0.3544, device='cuda:0')\n",
      "36\n",
      "tensor(0.0094, device='cuda:0')\n",
      "37\n",
      "tensor(0.0572, device='cuda:0')\n",
      "38\n",
      "tensor(0.1527, device='cuda:0')\n",
      "39\n",
      "tensor(0.1510, device='cuda:0')\n",
      "40\n",
      "tensor(0.1439, device='cuda:0')\n",
      "41\n",
      "tensor(0.0705, device='cuda:0')\n",
      "42\n",
      "tensor(0.2194, device='cuda:0')\n",
      "43\n",
      "tensor(0.0325, device='cuda:0')\n",
      "44\n",
      "tensor(0.1990, device='cuda:0')\n",
      "45\n",
      "tensor(0.2617, device='cuda:0')\n",
      "46\n",
      "tensor(0.2046, device='cuda:0')\n",
      "47\n",
      "tensor(0.0415, device='cuda:0')\n",
      "48\n",
      "tensor(0.1243, device='cuda:0')\n",
      "49\n",
      "tensor(0.2551, device='cuda:0')\n",
      "50\n",
      "tensor(-0.1673, device='cuda:0')\n",
      "51\n",
      "tensor(-0.0372, device='cuda:0')\n",
      "52\n",
      "tensor(-0.0547, device='cuda:0')\n",
      "53\n",
      "tensor(-0.0930, device='cuda:0')\n",
      "54\n",
      "tensor(-0.1184, device='cuda:0')\n",
      "55\n",
      "tensor(-0.1292, device='cuda:0')\n",
      "56\n",
      "tensor(0.0013, device='cuda:0')\n",
      "57\n",
      "tensor(-0.1781, device='cuda:0')\n",
      "58\n",
      "tensor(-0.0727, device='cuda:0')\n",
      "59\n",
      "tensor(-0.1088, device='cuda:0')\n",
      "60\n",
      "tensor(0.0291, device='cuda:0')\n",
      "61\n",
      "tensor(-0.0114, device='cuda:0')\n",
      "62\n",
      "tensor(0.0197, device='cuda:0')\n",
      "63\n",
      "tensor(0.0767, device='cuda:0')\n",
      "64\n",
      "tensor(0.0197, device='cuda:0')\n",
      "65\n",
      "tensor(-0.0225, device='cuda:0')\n",
      "66\n",
      "tensor(0.0664, device='cuda:0')\n",
      "67\n",
      "tensor(-0.1958, device='cuda:0')\n",
      "68\n",
      "tensor(0.0281, device='cuda:0')\n",
      "69\n",
      "tensor(-0.0661, device='cuda:0')\n",
      "70\n",
      "tensor(-0.0966, device='cuda:0')\n",
      "71\n",
      "tensor(0.0476, device='cuda:0')\n",
      "72\n",
      "tensor(0.0599, device='cuda:0')\n",
      "73\n",
      "tensor(-0.1180, device='cuda:0')\n",
      "74\n",
      "tensor(-0.0408, device='cuda:0')\n",
      "75\n",
      "tensor(-0.0827, device='cuda:0')\n",
      "76\n",
      "tensor(-0.0916, device='cuda:0')\n",
      "77\n",
      "tensor(-0.1130, device='cuda:0')\n",
      "78\n",
      "tensor(-0.1097, device='cuda:0')\n",
      "79\n",
      "tensor(-0.0906, device='cuda:0')\n",
      "80\n",
      "tensor(0.0612, device='cuda:0')\n",
      "81\n",
      "tensor(-0.0865, device='cuda:0')\n",
      "82\n",
      "tensor(-0.0639, device='cuda:0')\n",
      "83\n",
      "tensor(0.0776, device='cuda:0')\n",
      "84\n",
      "tensor(-0.1268, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(85):\n",
    "    print(i)\n",
    "    print(torch.dot(all_layer_gradients['layer7'][0].view(85,-1)[i], torch.tensor(cavs[4][1]).cuda() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6406c53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(4.5534, device='cuda:0')\n",
      "1\n",
      "tensor(0.9605, device='cuda:0')\n",
      "2\n",
      "tensor(0.0407, device='cuda:0')\n",
      "3\n",
      "tensor(0.0317, device='cuda:0')\n",
      "4\n",
      "tensor(0.0326, device='cuda:0')\n",
      "5\n",
      "tensor(0.0408, device='cuda:0')\n",
      "6\n",
      "tensor(0.0415, device='cuda:0')\n",
      "7\n",
      "tensor(0.0314, device='cuda:0')\n",
      "8\n",
      "tensor(0.0179, device='cuda:0')\n",
      "9\n",
      "tensor(0.0268, device='cuda:0')\n",
      "10\n",
      "tensor(0.0683, device='cuda:0')\n",
      "11\n",
      "tensor(0.0242, device='cuda:0')\n",
      "12\n",
      "tensor(0.0112, device='cuda:0')\n",
      "13\n",
      "tensor(0.0377, device='cuda:0')\n",
      "14\n",
      "tensor(0.0097, device='cuda:0')\n",
      "15\n",
      "tensor(0.0306, device='cuda:0')\n",
      "16\n",
      "tensor(0.0244, device='cuda:0')\n",
      "17\n",
      "tensor(0.0053, device='cuda:0')\n",
      "18\n",
      "tensor(0.0475, device='cuda:0')\n",
      "19\n",
      "tensor(0.0257, device='cuda:0')\n",
      "20\n",
      "tensor(0.0352, device='cuda:0')\n",
      "21\n",
      "tensor(0.0253, device='cuda:0')\n",
      "22\n",
      "tensor(0.0428, device='cuda:0')\n",
      "23\n",
      "tensor(0.0569, device='cuda:0')\n",
      "24\n",
      "tensor(0.0069, device='cuda:0')\n",
      "25\n",
      "tensor(0.0200, device='cuda:0')\n",
      "26\n",
      "tensor(0.0146, device='cuda:0')\n",
      "27\n",
      "tensor(0.0383, device='cuda:0')\n",
      "28\n",
      "tensor(0.0244, device='cuda:0')\n",
      "29\n",
      "tensor(0.0205, device='cuda:0')\n",
      "30\n",
      "tensor(0.0394, device='cuda:0')\n",
      "31\n",
      "tensor(0.0543, device='cuda:0')\n",
      "32\n",
      "tensor(0.0140, device='cuda:0')\n",
      "33\n",
      "tensor(0.0613, device='cuda:0')\n",
      "34\n",
      "tensor(0.0119, device='cuda:0')\n",
      "35\n",
      "tensor(0.0137, device='cuda:0')\n",
      "36\n",
      "tensor(0.0317, device='cuda:0')\n",
      "37\n",
      "tensor(0.0274, device='cuda:0')\n",
      "38\n",
      "tensor(0.0271, device='cuda:0')\n",
      "39\n",
      "tensor(0.0116, device='cuda:0')\n",
      "40\n",
      "tensor(0.0319, device='cuda:0')\n",
      "41\n",
      "tensor(0.0320, device='cuda:0')\n",
      "42\n",
      "tensor(0.0915, device='cuda:0')\n",
      "43\n",
      "tensor(0.0383, device='cuda:0')\n",
      "44\n",
      "tensor(0.0566, device='cuda:0')\n",
      "45\n",
      "tensor(0.0837, device='cuda:0')\n",
      "46\n",
      "tensor(0.0286, device='cuda:0')\n",
      "47\n",
      "tensor(0.0209, device='cuda:0')\n",
      "48\n",
      "tensor(0.0330, device='cuda:0')\n",
      "49\n",
      "tensor(0.0536, device='cuda:0')\n",
      "50\n",
      "tensor(-0.0311, device='cuda:0')\n",
      "51\n",
      "tensor(0.0091, device='cuda:0')\n",
      "52\n",
      "tensor(-0.0306, device='cuda:0')\n",
      "53\n",
      "tensor(0.0184, device='cuda:0')\n",
      "54\n",
      "tensor(-0.0045, device='cuda:0')\n",
      "55\n",
      "tensor(-0.0248, device='cuda:0')\n",
      "56\n",
      "tensor(0.0031, device='cuda:0')\n",
      "57\n",
      "tensor(-0.0172, device='cuda:0')\n",
      "58\n",
      "tensor(0.0039, device='cuda:0')\n",
      "59\n",
      "tensor(-0.0204, device='cuda:0')\n",
      "60\n",
      "tensor(0.0053, device='cuda:0')\n",
      "61\n",
      "tensor(0.0157, device='cuda:0')\n",
      "62\n",
      "tensor(0.0032, device='cuda:0')\n",
      "63\n",
      "tensor(0.0117, device='cuda:0')\n",
      "64\n",
      "tensor(0.0101, device='cuda:0')\n",
      "65\n",
      "tensor(0.0098, device='cuda:0')\n",
      "66\n",
      "tensor(0.0138, device='cuda:0')\n",
      "67\n",
      "tensor(-0.0306, device='cuda:0')\n",
      "68\n",
      "tensor(0.0066, device='cuda:0')\n",
      "69\n",
      "tensor(-0.0280, device='cuda:0')\n",
      "70\n",
      "tensor(0.0127, device='cuda:0')\n",
      "71\n",
      "tensor(0.0158, device='cuda:0')\n",
      "72\n",
      "tensor(0.0189, device='cuda:0')\n",
      "73\n",
      "tensor(0.0042, device='cuda:0')\n",
      "74\n",
      "tensor(0.0042, device='cuda:0')\n",
      "75\n",
      "tensor(5.2242e-05, device='cuda:0')\n",
      "76\n",
      "tensor(-0.0086, device='cuda:0')\n",
      "77\n",
      "tensor(-0.0018, device='cuda:0')\n",
      "78\n",
      "tensor(0.0203, device='cuda:0')\n",
      "79\n",
      "tensor(-0.0030, device='cuda:0')\n",
      "80\n",
      "tensor(-0.0015, device='cuda:0')\n",
      "81\n",
      "tensor(-0.0053, device='cuda:0')\n",
      "82\n",
      "tensor(0.0017, device='cuda:0')\n",
      "83\n",
      "tensor(-0.0010, device='cuda:0')\n",
      "84\n",
      "tensor(-0.0094, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(85):\n",
    "    print(i)\n",
    "    print(torch.dot(all_layer_gradients['layer9'][0].view(85,-1)[i], torch.tensor(cavs[5][1]).cuda() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "84944f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(4.5974, device='cuda:0')\n",
      "1\n",
      "tensor(5.0867, device='cuda:0')\n",
      "2\n",
      "tensor(0., device='cuda:0')\n",
      "3\n",
      "tensor(0., device='cuda:0')\n",
      "4\n",
      "tensor(0., device='cuda:0')\n",
      "5\n",
      "tensor(0., device='cuda:0')\n",
      "6\n",
      "tensor(0., device='cuda:0')\n",
      "7\n",
      "tensor(0., device='cuda:0')\n",
      "8\n",
      "tensor(0., device='cuda:0')\n",
      "9\n",
      "tensor(0., device='cuda:0')\n",
      "10\n",
      "tensor(0., device='cuda:0')\n",
      "11\n",
      "tensor(0., device='cuda:0')\n",
      "12\n",
      "tensor(0., device='cuda:0')\n",
      "13\n",
      "tensor(0., device='cuda:0')\n",
      "14\n",
      "tensor(0., device='cuda:0')\n",
      "15\n",
      "tensor(0., device='cuda:0')\n",
      "16\n",
      "tensor(0., device='cuda:0')\n",
      "17\n",
      "tensor(0., device='cuda:0')\n",
      "18\n",
      "tensor(0., device='cuda:0')\n",
      "19\n",
      "tensor(0., device='cuda:0')\n",
      "20\n",
      "tensor(0., device='cuda:0')\n",
      "21\n",
      "tensor(0., device='cuda:0')\n",
      "22\n",
      "tensor(0., device='cuda:0')\n",
      "23\n",
      "tensor(0., device='cuda:0')\n",
      "24\n",
      "tensor(0., device='cuda:0')\n",
      "25\n",
      "tensor(0., device='cuda:0')\n",
      "26\n",
      "tensor(0., device='cuda:0')\n",
      "27\n",
      "tensor(0., device='cuda:0')\n",
      "28\n",
      "tensor(0., device='cuda:0')\n",
      "29\n",
      "tensor(0., device='cuda:0')\n",
      "30\n",
      "tensor(0., device='cuda:0')\n",
      "31\n",
      "tensor(0., device='cuda:0')\n",
      "32\n",
      "tensor(0., device='cuda:0')\n",
      "33\n",
      "tensor(0., device='cuda:0')\n",
      "34\n",
      "tensor(0., device='cuda:0')\n",
      "35\n",
      "tensor(0., device='cuda:0')\n",
      "36\n",
      "tensor(0., device='cuda:0')\n",
      "37\n",
      "tensor(0., device='cuda:0')\n",
      "38\n",
      "tensor(0., device='cuda:0')\n",
      "39\n",
      "tensor(0., device='cuda:0')\n",
      "40\n",
      "tensor(0., device='cuda:0')\n",
      "41\n",
      "tensor(0., device='cuda:0')\n",
      "42\n",
      "tensor(0., device='cuda:0')\n",
      "43\n",
      "tensor(0., device='cuda:0')\n",
      "44\n",
      "tensor(0., device='cuda:0')\n",
      "45\n",
      "tensor(0., device='cuda:0')\n",
      "46\n",
      "tensor(0., device='cuda:0')\n",
      "47\n",
      "tensor(0., device='cuda:0')\n",
      "48\n",
      "tensor(0., device='cuda:0')\n",
      "49\n",
      "tensor(0., device='cuda:0')\n",
      "50\n",
      "tensor(0., device='cuda:0')\n",
      "51\n",
      "tensor(0., device='cuda:0')\n",
      "52\n",
      "tensor(0., device='cuda:0')\n",
      "53\n",
      "tensor(0., device='cuda:0')\n",
      "54\n",
      "tensor(0., device='cuda:0')\n",
      "55\n",
      "tensor(0., device='cuda:0')\n",
      "56\n",
      "tensor(0., device='cuda:0')\n",
      "57\n",
      "tensor(0., device='cuda:0')\n",
      "58\n",
      "tensor(0., device='cuda:0')\n",
      "59\n",
      "tensor(0., device='cuda:0')\n",
      "60\n",
      "tensor(0., device='cuda:0')\n",
      "61\n",
      "tensor(0., device='cuda:0')\n",
      "62\n",
      "tensor(0., device='cuda:0')\n",
      "63\n",
      "tensor(0., device='cuda:0')\n",
      "64\n",
      "tensor(0., device='cuda:0')\n",
      "65\n",
      "tensor(0., device='cuda:0')\n",
      "66\n",
      "tensor(0., device='cuda:0')\n",
      "67\n",
      "tensor(0., device='cuda:0')\n",
      "68\n",
      "tensor(0., device='cuda:0')\n",
      "69\n",
      "tensor(0., device='cuda:0')\n",
      "70\n",
      "tensor(0., device='cuda:0')\n",
      "71\n",
      "tensor(0., device='cuda:0')\n",
      "72\n",
      "tensor(0., device='cuda:0')\n",
      "73\n",
      "tensor(0., device='cuda:0')\n",
      "74\n",
      "tensor(0., device='cuda:0')\n",
      "75\n",
      "tensor(0., device='cuda:0')\n",
      "76\n",
      "tensor(0., device='cuda:0')\n",
      "77\n",
      "tensor(0., device='cuda:0')\n",
      "78\n",
      "tensor(0., device='cuda:0')\n",
      "79\n",
      "tensor(0., device='cuda:0')\n",
      "80\n",
      "tensor(0., device='cuda:0')\n",
      "81\n",
      "tensor(0., device='cuda:0')\n",
      "82\n",
      "tensor(0., device='cuda:0')\n",
      "83\n",
      "tensor(0., device='cuda:0')\n",
      "84\n",
      "tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(85):\n",
    "    print(i)\n",
    "    print(torch.dot(all_layer_gradients['layer11'][0].view(85,-1)[i], torch.tensor(cavs[6][1]).cuda() ) )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4c1cccef",
   "metadata": {},
   "source": [
    "Reference code from gradcam for backprop\n",
    "\n",
    "\n",
    "\n",
    "def gradCAM(\n",
    "    model: nn.Module,\n",
    "    input: torch.Tensor,\n",
    "    target: torch.Tensor,\n",
    "    layer: nn.Module\n",
    ") -> torch.Tensor:\n",
    "    # Zero out any gradients at the input.\n",
    "    if input.grad is not None:\n",
    "        input.grad.data.zero_()\n",
    "        \n",
    "    # Disable gradient settings.\n",
    "    requires_grad = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        requires_grad[name] = param.requires_grad\n",
    "        param.requires_grad_(False)\n",
    "        \n",
    "    # Attach a hook to the model at the desired layer.\n",
    "    assert isinstance(layer, nn.Module)\n",
    "    with Hook(layer) as hook:        \n",
    "        # Do a forward and backward pass.\n",
    "        output = model(input)\n",
    "        output.backward(target)\n",
    "\n",
    "        grad = hook.gradient.float()\n",
    "        act = hook.activation.float()\n",
    "    \n",
    "        # Global average pool gradient across spatial dimension\n",
    "        # to obtain importance weights.\n",
    "        alpha = grad.mean(dim=(2, 3), keepdim=True)\n",
    "        # Weighted combination of activation maps over channel\n",
    "        # dimension.\n",
    "        gradcam = torch.sum(act * alpha, dim=1, keepdim=True)\n",
    "        # We only want neurons with positive influence so we\n",
    "        # clamp any negative ones.\n",
    "        gradcam = torch.clamp(gradcam, min=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37233b85",
   "metadata": {},
   "source": [
    "You need labels to get gradients, to get a loss to backpropagate with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebda776",
   "metadata": {},
   "source": [
    "# Calculate TCAV score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e5e277ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = preprocess(Image.open('tcav/concepts/striped/striped_0086.jpg')).unsqueeze(0).to(device)\n",
    "image_features = model.encode_image(image.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "2295b480",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(image.cuda(), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "05d5c062",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.encode_image(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a32f1781",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward(torch.ones(1,1024).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "2496f7f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 512])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.visual.proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3ab68d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (maxreplearn)",
   "language": "python",
   "name": "maxreplearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
