{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac679899",
   "metadata": {},
   "source": [
    "# Notebook Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4f06f1",
   "metadata": {},
   "source": [
    "Implement TCAV using Pytorch for CLIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a8b248",
   "metadata": {},
   "source": [
    "# Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32277860",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/openai/CLIP\n",
    "# authors Katherine Crowson (https://github.com/crowsonkb, https://twitter.com/RiversHaveWings), nerdyrodent\n",
    "# authors vivian\n",
    "# The original BigGAN+CLIP method was by https://twitter.com/advadnoun\n",
    "import threading\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import math\n",
    "import random\n",
    "from urllib.request import urlopen\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('taming-transformers')\n",
    "from omegaconf import OmegaConf\n",
    "from taming.models import cond_transformer, vqgan\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as TF\n",
    "from torch.cuda import get_device_properties\n",
    "torch.backends.cudnn.benchmark = False\n",
    "from torch_optimizer import DiffGrad, AdamP, RAdam\n",
    "from CLIP import clip\n",
    "import kornia.augmentation as K\n",
    "import imageio\n",
    "from PIL import ImageFile, Image, PngImagePlugin, ImageChops\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from subprocess import Popen, PIPE\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3033a3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RN50', 'RN101', 'RN50x4', 'RN50x16', 'ViT-B/32', 'ViT-B/16']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip.available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6fad75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3410ac22",
   "metadata": {},
   "source": [
    "# Load CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e379417",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, preprocess = clip.load('ViT-B/32', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d901147",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hook:\n",
    "    \"\"\"Attaches to a module and records its activations and gradients.\"\"\"\n",
    "\n",
    "    def __init__(self, module: nn.Module):\n",
    "        self.data = None\n",
    "        self.hook = module.register_forward_hook(self.save_grad)\n",
    "        \n",
    "    def save_grad(self, module, input, output):\n",
    "        self.data = output\n",
    "        output.requires_grad_(True)\n",
    "        output.retain_grad()\n",
    "        \n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_value, exc_traceback):\n",
    "        self.hook.remove()\n",
    "        \n",
    "    @property\n",
    "    def activation(self) -> torch.Tensor:\n",
    "        return self.data\n",
    "    \n",
    "    @property\n",
    "    def gradient(self) -> torch.Tensor:\n",
    "        return self.data.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da4b2121",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping():\n",
    "    \"\"\"\n",
    "    Early stopping to stop the training when the loss does not improve after\n",
    "    certain epochs.\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        \"\"\"\n",
    "        :param patience: how many epochs to wait before stopping when loss is\n",
    "               not improving\n",
    "        :param min_delta: minimum difference between new loss and old loss for\n",
    "               new loss to be considered as an improvement\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss == None:\n",
    "            self.best_loss = val_loss\n",
    "        elif self.best_loss - val_loss > self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            # reset counter if validation loss improves\n",
    "            self.counter = 0\n",
    "        elif self.best_loss - val_loss < self.min_delta:\n",
    "            self.counter += 1\n",
    "            print(f\"INFO: Early stopping counter {self.counter} of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                print('INFO: Early stopping')\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e5ace60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# possibly needed in future if using larger dataset w/ dataloader\n",
    "\n",
    "# embedding_list = np.empty(layers.shape, dtype=object)\n",
    "# for i in range(len(embedding_list)):\n",
    "#     embedding_list[i] = []\n",
    "# for num_layer, name  in enumerate(layernames):\n",
    "#     embedding_list[num_layer].append(activations[name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73aa86e9",
   "metadata": {},
   "source": [
    "# Image Encoding"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c1f0b5dc",
   "metadata": {},
   "source": [
    "image = preprocess(Image.open(\"square.jpg\")).unsqueeze(0).to(device)\n",
    "image_features = model.encode_image(image.cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b0f015",
   "metadata": {},
   "source": [
    "# Text Encoding"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ad6e1007",
   "metadata": {},
   "source": [
    "prompt = \"square shaped cat\"\n",
    "txt, weight, stop = split_prompt(prompt)\n",
    "\n",
    "text_features = model.encode_text(clip.tokenize(txt).to(device)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cca0b121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_tensors(img_filename, img_dir=\"\"):\n",
    "    image = preprocess(Image.open(img_dir + img_filename)).unsqueeze(0).to(device)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0045a045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_images(img_filename, img_dir=\"\"):\n",
    "    image = preprocess(Image.open(img_dir + img_filename)).unsqueeze(0).to(device)\n",
    "\n",
    "    image_features = model.encode_image(image.cuda())\n",
    "    return image_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b4b54b",
   "metadata": {},
   "source": [
    "Load an example image"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5747d983",
   "metadata": {},
   "source": [
    "# PIL.Image.open\n",
    "# concept_filenames[0]\n",
    "\n",
    "Image.open('tcav/concepts/striped/striped_0086.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811a5736",
   "metadata": {},
   "source": [
    "# Define Linear Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a126a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearClassifier(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear1 = torch.nn.Linear(num_features, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, input_x):\n",
    "        x = self.linear1(input_x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84db4f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_filenames = os.listdir('tcav/concepts/striped')\n",
    "negative_filenames = os.listdir('tcav/concepts/random_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "015a3200",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_concept = [encode_images(filename, 'tcav/concepts/striped/') for filename in positive_filenames]\n",
    "#positive_concept = torch.vstack(positive_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f923dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_concept = [encode_images(filename, 'tcav/concepts/random_0/') for filename in negative_filenames]\n",
    "#negative_concept = torch.vstack(negative_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "065e7800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_concept = positive_concept + negative_concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4591bdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_concepts = torch.vstack(positive_concept)\n",
    "negative_concepts = torch.vstack(negative_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3226efc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_img_tensors = [get_img_tensors(img,'tcav/concepts/striped/') for img in positive_filenames]\n",
    "positive_img_tensors = torch.vstack(positive_img_tensors)\n",
    "negative_img_tensors = [get_img_tensors(img,'tcav/concepts/random_0/') for img in negative_filenames]\n",
    "negative_img_tensors = torch.vstack(negative_img_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5b3ca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_img_tensors = torch.vstack([positive_img_tensors, negative_img_tensors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6121aa50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folder = '/home/valentinedhauteville/dataset/tcav/concepts/'\n",
    "# image_classes = ['smeared','dotted', 'knitted', 'spiralled', 'chequered']\n",
    "image_classes = ['giraffe','light','vegetable','fish','book', 'baby', 'street']\n",
    "image_tensors = np.zeros((len(image_classes),2), dtype=object) # [{positive, negative}, image_class]\n",
    "num_rand_folders = 5\n",
    "for num_class, img_class in enumerate(image_classes):\n",
    "    class_folder  = folder + img_class + '/'\n",
    "    random_folder = folder + f'random_{num_class % num_rand_folders}/'\n",
    "    pos_files = os.listdir(class_folder)\n",
    "    neg_files = os.listdir(random_folder)[:len(pos_files)]\n",
    "    image_tensors[num_class,0] = torch.vstack([get_img_tensors(img, class_folder) for img in pos_files]) # positive tensors\n",
    "    image_tensors[num_class,1] = torch.vstack([get_img_tensors(img, random_folder) for img in neg_files]) # negative tensors\n",
    "    \n",
    "#     pos_encoding = [encode_images(filename) for filename in pos_files]\n",
    "#     neg_encoding = [encode_images(filename) for filename in neg_files]\n",
    "#     pos_concepts = torch.vstack(pos_encoding)\n",
    "#     neg_concepts = torch.vstack(neg_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8952e10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([85, 3, 224, 224])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_img_tensors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88027eb8",
   "metadata": {},
   "source": [
    "## Get image class embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1cac60",
   "metadata": {},
   "source": [
    "### Register hooks for activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "57a45a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assist from https://web.stanford.edu/~nanbhas/blog/forward-hooks-pytorch/\n",
    "activations = {}\n",
    "gradients = {}\n",
    "def getActivation(name):\n",
    "    # the hook signature \n",
    "    def hook(model, input, output):\n",
    "        \n",
    "        output.requires_grad_(True)\n",
    "        output.retain_grad()\n",
    "        gradients[name] = output.grad\n",
    "        activations[name] = output.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "971a39aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hooks = []\n",
    "layers = np.concatenate([[model.visual.conv1], model.visual.transformer.resblocks[1::2], [model.visual]])\n",
    "layernames = np.concatenate([['layer0'], [f'layer{i}' for i in range(1,13,2)],['full']], dtype=str)\n",
    "for l, n in zip(layers, layernames):\n",
    "    hooks.append(l.register_forward_hook(getActivation(n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3260448",
   "metadata": {},
   "source": [
    "### Push images through model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "58ba49d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([93, 768, 7, 7])\n",
      "torch.Size([50, 93, 768])\n",
      "torch.Size([50, 93, 768])\n",
      "torch.Size([50, 93, 768])\n",
      "torch.Size([50, 93, 768])\n",
      "torch.Size([50, 93, 768])\n",
      "torch.Size([50, 93, 768])\n",
      "torch.Size([93, 512])\n",
      "torch.Size([94, 768, 7, 7])\n",
      "torch.Size([50, 94, 768])\n",
      "torch.Size([50, 94, 768])\n",
      "torch.Size([50, 94, 768])\n",
      "torch.Size([50, 94, 768])\n",
      "torch.Size([50, 94, 768])\n",
      "torch.Size([50, 94, 768])\n",
      "torch.Size([94, 512])\n",
      "torch.Size([91, 768, 7, 7])\n",
      "torch.Size([50, 91, 768])\n",
      "torch.Size([50, 91, 768])\n",
      "torch.Size([50, 91, 768])\n",
      "torch.Size([50, 91, 768])\n",
      "torch.Size([50, 91, 768])\n",
      "torch.Size([50, 91, 768])\n",
      "torch.Size([91, 512])\n",
      "torch.Size([88, 768, 7, 7])\n",
      "torch.Size([50, 88, 768])\n",
      "torch.Size([50, 88, 768])\n",
      "torch.Size([50, 88, 768])\n",
      "torch.Size([50, 88, 768])\n",
      "torch.Size([50, 88, 768])\n",
      "torch.Size([50, 88, 768])\n",
      "torch.Size([88, 512])\n",
      "torch.Size([97, 768, 7, 7])\n",
      "torch.Size([50, 97, 768])\n",
      "torch.Size([50, 97, 768])\n",
      "torch.Size([50, 97, 768])\n",
      "torch.Size([50, 97, 768])\n",
      "torch.Size([50, 97, 768])\n",
      "torch.Size([50, 97, 768])\n",
      "torch.Size([97, 512])\n",
      "torch.Size([96, 768, 7, 7])\n",
      "torch.Size([50, 96, 768])\n",
      "torch.Size([50, 96, 768])\n",
      "torch.Size([50, 96, 768])\n",
      "torch.Size([50, 96, 768])\n",
      "torch.Size([50, 96, 768])\n",
      "torch.Size([50, 96, 768])\n",
      "torch.Size([96, 512])\n",
      "torch.Size([75, 768, 7, 7])\n",
      "torch.Size([50, 75, 768])\n",
      "torch.Size([50, 75, 768])\n",
      "torch.Size([50, 75, 768])\n",
      "torch.Size([50, 75, 768])\n",
      "torch.Size([50, 75, 768])\n",
      "torch.Size([50, 75, 768])\n",
      "torch.Size([75, 512])\n",
      "torch.Size([93, 768, 7, 7])\n",
      "torch.Size([50, 93, 768])\n",
      "torch.Size([50, 93, 768])\n",
      "torch.Size([50, 93, 768])\n",
      "torch.Size([50, 93, 768])\n",
      "torch.Size([50, 93, 768])\n",
      "torch.Size([50, 93, 768])\n",
      "torch.Size([93, 512])\n",
      "torch.Size([94, 768, 7, 7])\n",
      "torch.Size([50, 94, 768])\n",
      "torch.Size([50, 94, 768])\n",
      "torch.Size([50, 94, 768])\n",
      "torch.Size([50, 94, 768])\n",
      "torch.Size([50, 94, 768])\n",
      "torch.Size([50, 94, 768])\n",
      "torch.Size([94, 512])\n",
      "torch.Size([91, 768, 7, 7])\n",
      "torch.Size([50, 91, 768])\n",
      "torch.Size([50, 91, 768])\n",
      "torch.Size([50, 91, 768])\n",
      "torch.Size([50, 91, 768])\n",
      "torch.Size([50, 91, 768])\n",
      "torch.Size([50, 91, 768])\n",
      "torch.Size([91, 512])\n",
      "torch.Size([88, 768, 7, 7])\n",
      "torch.Size([50, 88, 768])\n",
      "torch.Size([50, 88, 768])\n",
      "torch.Size([50, 88, 768])\n",
      "torch.Size([50, 88, 768])\n",
      "torch.Size([50, 88, 768])\n",
      "torch.Size([50, 88, 768])\n",
      "torch.Size([88, 512])\n",
      "torch.Size([97, 768, 7, 7])\n",
      "torch.Size([50, 97, 768])\n",
      "torch.Size([50, 97, 768])\n",
      "torch.Size([50, 97, 768])\n",
      "torch.Size([50, 97, 768])\n",
      "torch.Size([50, 97, 768])\n",
      "torch.Size([50, 97, 768])\n",
      "torch.Size([97, 512])\n",
      "torch.Size([96, 768, 7, 7])\n",
      "torch.Size([50, 96, 768])\n",
      "torch.Size([50, 96, 768])\n",
      "torch.Size([50, 96, 768])\n",
      "torch.Size([50, 96, 768])\n",
      "torch.Size([50, 96, 768])\n",
      "torch.Size([50, 96, 768])\n",
      "torch.Size([96, 512])\n",
      "torch.Size([75, 768, 7, 7])\n",
      "torch.Size([50, 75, 768])\n",
      "torch.Size([50, 75, 768])\n",
      "torch.Size([50, 75, 768])\n",
      "torch.Size([50, 75, 768])\n",
      "torch.Size([50, 75, 768])\n",
      "torch.Size([50, 75, 768])\n",
      "torch.Size([75, 512])\n"
     ]
    }
   ],
   "source": [
    "# concept_embeddings = np.zeros((len(image_classes),2), dtype=object) # shape=[class, {positive, negative}]\n",
    "per_layer_embeddings = np.zeros((len(image_classes), 2, len(layers)), dtype=object)\n",
    "\n",
    "for pos_or_neg in [0,1]:\n",
    "    for i in range(len(image_classes)):\n",
    "#         concept_embeddings[i, pos_or_neg] = model.encode_image(image_tensors[i, pos_or_neg])\n",
    "        model.encode_image(image_tensors[i, pos_or_neg]) # push through model\n",
    "\n",
    "        # pull activations from each layer (incl. final layer with full visual)\n",
    "        for layer, name in enumerate(layernames):\n",
    "            per_layer_embeddings[i, pos_or_neg, layer] = activations[name]\n",
    "            print(activations[name].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "76347d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = f\"{[f'{i}_' for i in image_classes]}_per_layer_embeddings.pkl\"\n",
    "# filename = \"smeared_dotted_knitted_spiralled_chequered_per_layer_embeddings.pkl\"\n",
    "filename = \"'giraffe','light','vegetable','fish','book', 'baby', 'street'embeddings.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b557c299",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename,\"wb\") as f:\n",
    "    pickle.dump(per_layer_embeddings,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104a9ab3",
   "metadata": {},
   "source": [
    "### flatten embedding layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "680dd28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_data = np.zeros((len(image_classes), len(layers)), dtype=object)\n",
    "for i in range(len(image_classes)):\n",
    "    for layer in range(len(layers)):\n",
    "        pos_size = image_tensors[i,0].shape[0]\n",
    "        neg_size = image_tensors[i,1].shape[0]\n",
    "        pos_flat = per_layer_embeddings[i,0,layer].reshape(pos_size, -1)\n",
    "        neg_flat = per_layer_embeddings[i,1,layer].reshape(neg_size, -1)\n",
    "        flattened_data[i,layer] = torch.cat([pos_flat, neg_flat])\n",
    "#         training_data.append(all_layer_gradients[key][0].view(85,-1))\n",
    "#         linear_classifier_sizes.append(all_layer_gradients[key][0].view(85,-1).shape[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5e8ca1",
   "metadata": {},
   "source": [
    "### Create target dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "06322b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = np.zeros((len(image_classes)), dtype=object)\n",
    "for i in range(len(image_classes)):\n",
    "    positive_labels = torch.tensor(image_tensors[i,0].shape[0] * [1])\n",
    "    negative_labels = torch.tensor(image_tensors[i,1].shape[0] * [0])\n",
    "    class_labels[i] = torch.cat([positive_labels, negative_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d544afc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "class_dataloaders = np.zeros((len(image_classes), len(layers), 3), dtype=object)\n",
    "data = flattened_data # shape [num_classes, num_layers, [+ activations, - activations]]\n",
    "for i in range(len(image_classes)):\n",
    "    len_train = int(0.7 * data[i,0].shape[0])\n",
    "    len_val   = int(0.125 * data[i,0].shape[0])\n",
    "    len_test  = data[i,0].shape[0] - len_train - len_val\n",
    "\n",
    "    for layer in range(len(layers)):\n",
    "        dataset = TensorDataset(data[i,layer], class_labels[i])\n",
    "        torch.manual_seed(0)\n",
    "        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [len_train, len_val, len_test])\n",
    "        class_dataloaders[i,layer,0] = DataLoader(train_dataset, batch_size=2,\n",
    "                                                  pin_memory=False, shuffle=True)\n",
    "        class_dataloaders[i,layer,1] = DataLoader(val_dataset, batch_size=2,\n",
    "                                                  pin_memory=False, shuffle=True)\n",
    "        class_dataloaders[i,layer,2] = DataLoader(test_dataset, batch_size=2,\n",
    "                                                  pin_memory=False, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9e04e7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_layer_sizes = np.zeros((len(image_classes), len(layers)),dtype=int)\n",
    "for i in range(len(image_classes)):\n",
    "    for l in range(len(layers)):\n",
    "        class_layer_sizes[i,l] = int(data[i,l][0].shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffc020c",
   "metadata": {},
   "source": [
    "## make classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1a27f7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = np.zeros((len(image_classes), len(layers)), dtype=object)\n",
    "for i in range(len(image_classes)):\n",
    "    for l in range(len(layers)):\n",
    "        classifiers[i,l] = LinearClassifier(class_layer_sizes[i,l])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7885ce",
   "metadata": {},
   "source": [
    "# TRAIN Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e85885a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(classifier, dataloader, val_dataloader):\n",
    "    clf = classifier.cuda()\n",
    "    early_stopping = EarlyStopping(patience=3)\n",
    "    optimizer = torch.optim.SGD(clf.parameters(), lr=0.001)\n",
    "    for it in range(n_epochs):\n",
    "        for i, data in enumerate(dataloader,0):\n",
    "            inputs, labels = data\n",
    "            inputs = Variable(inputs, requires_grad=True)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = clf(inputs.cuda().float())\n",
    "\n",
    "            loss = criterion(outputs.cuda().float(), labels.cuda().reshape(-1,1).float())\n",
    "            loss.backward()\n",
    "            \n",
    "            \n",
    "            optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(val_dataloader,0):\n",
    "                inputs, labels = data\n",
    "                inputs = Variable(inputs)\n",
    "                outputs = clf(inputs.cuda().float())\n",
    "\n",
    "                loss = criterion(outputs.cuda().float(), labels.cuda().reshape(-1,1).float()) \n",
    "        \n",
    "            early_stopping(loss)\n",
    "        if it % 10 == 0:\n",
    "            print(loss)\n",
    "            pass\n",
    "        if early_stopping.early_stop:\n",
    "            print(loss)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fd68933f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class: giraffe layer: 0\n",
      "tensor(1.3297, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.0761, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: giraffe layer: 1\n",
      "tensor(0.5315, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "tensor(0.9078, device='cuda:0')\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.4250, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: giraffe layer: 2\n",
      "tensor(0.6084, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.8955, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: giraffe layer: 3\n",
      "tensor(0.5280, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "tensor(0.3779, device='cuda:0')\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.5031, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: giraffe layer: 4\n",
      "tensor(0.4825, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.3980, device='cuda:0')\n",
      "tensor(0.3980, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: giraffe layer: 5\n",
      "tensor(0.4636, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.0863, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: giraffe layer: 6\n",
      "tensor(0.0061, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.0670, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: giraffe layer: 7\n",
      "tensor(0.4673, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.4512, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: light layer: 0\n",
      "tensor(2.7780, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.7106, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: light layer: 1\n",
      "tensor(1.1615, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.6729, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: light layer: 2\n",
      "tensor(0.6013, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.5793, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: light layer: 3\n",
      "tensor(0.7046, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.4722, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: light layer: 4\n",
      "tensor(0.8190, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(3.0166, device='cuda:0')\n",
      "tensor(3.0166, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: light layer: 5\n",
      "tensor(0.1334, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.2523, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: light layer: 6\n",
      "tensor(0.9280, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.1526, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: light layer: 7\n",
      "tensor(0.6250, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.6288, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: vegetable layer: 0\n",
      "tensor(0.1460, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.1587, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: vegetable layer: 1\n",
      "tensor(0.6756, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "tensor(0.5389, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.5627, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: vegetable layer: 2\n",
      "tensor(0.7048, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.6018, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: vegetable layer: 3\n",
      "tensor(0.6423, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "tensor(0.3082, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.4546, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: vegetable layer: 4\n",
      "tensor(0.5460, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.5563, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: vegetable layer: 5\n",
      "tensor(0.1796, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.0733, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: vegetable layer: 6\n",
      "tensor(0.0030, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.0573, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: vegetable layer: 7\n",
      "tensor(0.8052, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.7168, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: fish layer: 0\n",
      "tensor(1.5436, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(2.5984, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: fish layer: 1\n",
      "tensor(0.8189, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.6104, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: fish layer: 2\n",
      "tensor(0.6627, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.6709, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: fish layer: 3\n",
      "tensor(0.7233, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "tensor(0.6064, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.4340, device='cuda:0')\n",
      "tensor(0.4340, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: fish layer: 4\n",
      "tensor(0.6853, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.3239, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: fish layer: 5\n",
      "tensor(0.1580, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.0900, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: fish layer: 6\n",
      "tensor(0.2021, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.0519, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: fish layer: 7\n",
      "tensor(0.4964, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.4625, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: book layer: 0\n",
      "tensor(0.2530, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(4.9922, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: book layer: 1\n",
      "tensor(0.6517, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.5743, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: book layer: 2\n",
      "tensor(0.6856, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.6002, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: book layer: 3\n",
      "tensor(0.6375, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.5002, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: book layer: 4\n",
      "tensor(0.5671, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "tensor(0.2062, device='cuda:0')\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.2491, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: book layer: 5\n",
      "tensor(0.3360, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.0677, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: book layer: 6\n",
      "tensor(0.0199, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.1093, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: book layer: 7\n",
      "tensor(0.6964, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "tensor(0.5681, device='cuda:0')\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.2622, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: baby layer: 0\n",
      "tensor(0.9358, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(1.3114, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: baby layer: 1\n",
      "tensor(0.7637, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.7595, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: baby layer: 2\n",
      "tensor(0.6844, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.7859, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: baby layer: 3\n",
      "tensor(0.6721, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.5159, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: baby layer: 4\n",
      "tensor(0.5029, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "tensor(0.2932, device='cuda:0')\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.3521, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: baby layer: 5\n",
      "tensor(0.3079, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.2628, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: baby layer: 6\n",
      "tensor(0.4206, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.1066, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: baby layer: 7\n",
      "tensor(0.6376, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "tensor(0.2665, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.1865, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: street layer: 0\n",
      "tensor(0.3077, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(1.0522, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: street layer: 1\n",
      "tensor(0.5125, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "tensor(0.1569, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.1669, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: street layer: 2\n",
      "tensor(0.5348, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "tensor(0.2308, device='cuda:0')\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.1900, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: street layer: 3\n",
      "tensor(0.5042, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "tensor(0.1065, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.0885, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: street layer: 4\n",
      "tensor(0.3652, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "tensor(0.0504, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.0745, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: street layer: 5\n",
      "tensor(0.2826, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "tensor(0.0143, device='cuda:0')\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.0116, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: street layer: 6\n",
      "tensor(0.0767, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.0249, device='cuda:0')\n",
      "trained a classifier\n",
      "training class: street layer: 7\n",
      "tensor(0.7953, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "tensor(0.2761, device='cuda:0')\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 1 of 3\n",
      "INFO: Early stopping counter 2 of 3\n",
      "INFO: Early stopping counter 3 of 3\n",
      "INFO: Early stopping\n",
      "tensor(0.8614, device='cuda:0')\n",
      "trained a classifier\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "for i in range(len(image_classes)):\n",
    "    for l in range(len(layers)):\n",
    "        classifier = classifiers[i,l]\n",
    "        dataloader = class_dataloaders[i,l,0]\n",
    "        val_dataloader = class_dataloaders[i,l,1]\n",
    "        \n",
    "        print(f\"training class: {image_classes[i]} layer: {l}\")\n",
    "        train_classifier(classifier, dataloader, val_dataloader)\n",
    "        print(\"trained a classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "543532fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"classifiers_perclass_perlayer_smeared_dotted_knitted_spiralled_chequered.pkl\",\"wb\") as f:\n",
    "#     pickle.dump(classifiers,f)\n",
    "# f = \"classifiers_perclass_perlayer_smeared_dotted_knitted_spiralled_chequered\"\n",
    "f = \"classifiers_perclass_perlayer_giraffe_light_vegetable_fish_book_baby_street\"\n",
    "np.save(f, classifiers, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "885182ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = np.load(f\"{f}.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ab24b308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 8)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dc5ca35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "#     y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4c1ae769",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "giraffe\n",
      "0.6060606060606061\n",
      "0.7575757575757576\n",
      "0.7878787878787878\n",
      "0.9696969696969697\n",
      "0.9696969696969697\n",
      "0.9696969696969697\n",
      "0.9696969696969697\n",
      "1.0\n",
      "light\n",
      "0.6176470588235294\n",
      "0.8823529411764706\n",
      "0.8823529411764706\n",
      "0.9705882352941176\n",
      "0.9705882352941176\n",
      "0.9705882352941176\n",
      "0.9411764705882353\n",
      "0.8529411764705882\n",
      "vegetable\n",
      "0.6060606060606061\n",
      "0.8787878787878788\n",
      "0.7878787878787878\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.8484848484848485\n",
      "fish\n",
      "0.7096774193548387\n",
      "0.7741935483870968\n",
      "0.8064516129032258\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.8387096774193549\n",
      "book\n",
      "0.6285714285714286\n",
      "0.8\n",
      "0.9428571428571428\n",
      "0.9714285714285714\n",
      "0.9714285714285714\n",
      "0.9714285714285714\n",
      "1.0\n",
      "1.0\n",
      "baby\n",
      "0.5294117647058824\n",
      "0.8823529411764706\n",
      "0.7941176470588235\n",
      "0.9705882352941176\n",
      "0.9705882352941176\n",
      "0.9705882352941176\n",
      "1.0\n",
      "1.0\n",
      "street\n",
      "0.6666666666666666\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "test_results=np.zeros((len(image_classes),len(layers)))\n",
    "for i in range(len(image_classes)):\n",
    "    print(image_classes[i])\n",
    "    for l in range(len(layers)):\n",
    "        clf = classifiers[i,l]\n",
    "        inputs, labels = class_dataloaders[i,l,2].dataset[:]\n",
    "        inputs = Variable(inputs)\n",
    "        outputs = clf(inputs.cuda().float())\n",
    "#         print(len(inputs),len(outputs),len(labels))\n",
    "#         print(binary_acc(inputs))\n",
    "        num_correct = 0\n",
    "#         print(outputs)\n",
    "        for t, true_val in enumerate(labels):\n",
    "            if true_val == 0:\n",
    "                if outputs[t] <= 0:\n",
    "                    num_correct += 1\n",
    "            else:\n",
    "                if outputs[t] > 0:\n",
    "                    num_correct += 1\n",
    "        acc = float(num_correct) / len(outputs)\n",
    "        print(acc)\n",
    "        test_results[i,l] = acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cfcb86dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"test_results_dec1_smeared_dotted_knitted_spiralled_chequered_perlayer\", test_results, allow_pickle=True)\n",
    "# np.save(\"test_results_dec1_smeared_dotted_knitted_spiralled_chequered_perlayer\", test_results, allow_pickle=True)\n",
    "np.save(\"test_results_dec1_classifiers_perclass_perlayer_giraffe_light_vegetable_fish_book_baby_street_perlayer\", test_results, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9b9943ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracies = np.load(\"test_results_dec1_smeared_dotted_knitted_spiralled_chequered_perlayer.npy\", allow_pickle=True)\n",
    "accuracies = np.load(\"test_results_dec1_classifiers_perclass_perlayer_giraffe_light_vegetable_fish_book_baby_street_perlayer.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bc3fff1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 8)\n"
     ]
    }
   ],
   "source": [
    "print(accuracies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "98c07b15",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Variable data has to be a tensor, but got DataLoader",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2507/2049730456.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassifiers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_dataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlayernames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Variable data has to be a tensor, but got DataLoader"
     ]
    }
   ],
   "source": [
    "classifiers[0,0](Variable(class_dataloaders[0,0,2]))\n",
    "layernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b5da88fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['layer0', 'layer1', 'layer3', 'layer5', 'layer7', 'layer9',\n",
       "       'layer11', 'full'], dtype='<U7')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layernames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f60c49",
   "metadata": {},
   "source": [
    "# Collect features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "06ac35f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.encode_image(all_img_tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "53ac0fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_inputs = [\"zebra\"] * len(positive_concept) + [\"not zebra\"] * len(negative_concept)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f3d5ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_inputs = [clip.tokenize([text_input]).to(device) for text_input in text_inputs]\n",
    "target = torch.vstack([model.encode_text(text_input).float() for text_input in text_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a26031a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 14.00 MiB (GPU 0; 14.76 GiB total capacity; 9.83 GiB already allocated; 7.75 MiB free; 10.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12822/3103676668.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# Do a forward and backward pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_img_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/VQGAN-CLIP/CLIP/clip/model.py\u001b[0m in \u001b[0;36mencode_image\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/maxreplearn/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1118\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/VQGAN-CLIP/CLIP/clip/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# NLD -> LND\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# LND -> NLD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/maxreplearn/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/VQGAN-CLIP/CLIP/clip/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/maxreplearn/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/maxreplearn/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/maxreplearn/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1118\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/VQGAN-CLIP/CLIP/clip/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/maxreplearn/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/VQGAN-CLIP/CLIP/clip/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0morig_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/maxreplearn/lib/python3.9/site-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         return F.layer_norm(\n\u001b[0m\u001b[1;32m    190\u001b[0m             input, self.normalized_shape, self.weight, self.bias, self.eps)\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/maxreplearn/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2345\u001b[0m             \u001b[0mlayer_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2346\u001b[0m         )\n\u001b[0;32m-> 2347\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 14.00 MiB (GPU 0; 14.76 GiB total capacity; 9.83 GiB already allocated; 7.75 MiB free; 10.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "all_layer_gradients = {}\n",
    "all_layer_activations = {}\n",
    "for layer, name in zip(layers, layernames):\n",
    "    layer_gradients = []\n",
    "    layer_activations = []\n",
    "    with Hook(layer) as hook:\n",
    "\n",
    "        # Do a forward and backward pass.\n",
    "        output = model.encode_image(all_img_tensors)\n",
    "        output.backward(target)\n",
    "\n",
    "        grad = hook.gradient.float()\n",
    "        act = hook.activation.float()\n",
    "        layer_gradients.append(grad)\n",
    "        layer_activations.append(act)\n",
    "    all_layer_gradients[name] = layer_gradients\n",
    "    all_layer_activations[name] = layer_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dd031139",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_layer_gradients.pkl\",\"wb\") as f:\n",
    "    pickle.dump(all_layer_gradients,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f691e309",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_layer_activations.pkl\",\"wb\") as f:\n",
    "    pickle.dump(all_layer_activations,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618b4f69",
   "metadata": {},
   "source": [
    "# Process features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "65e7cfef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_layer_gradients' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12822/3222073976.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtraining_data\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlinear_classifier_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_layer_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtraining_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_layer_gradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m85\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlinear_classifier_sizes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_layer_gradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m85\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_layer_gradients' is not defined"
     ]
    }
   ],
   "source": [
    "training_data =  []\n",
    "linear_classifier_sizes = []\n",
    "for key in all_layer_gradients.keys():\n",
    "    training_data.append(all_layer_gradients[key][0].view(85,-1))\n",
    "    linear_classifier_sizes.append(all_layer_gradients[key][0].view(85,-1).shape[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd8e374",
   "metadata": {},
   "source": [
    "# Assemble training data for all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc730e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_labels = torch.tensor(positive_concepts.shape[0] * [1])\n",
    "negative_labels = torch.tensor(negative_concepts.shape[0] * [0])\n",
    "# training_data = torch.vstack([positive_concepts, negative_concepts])\n",
    "class_labels = torch.cat([positive_labels, negative_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d1ea31",
   "metadata": {},
   "source": [
    "Assemble validation data for all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c6002583",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train = int( train.shape[0] * 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "af4db558",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [ len_train, train.shape[0]-len_train] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ba30f3",
   "metadata": {},
   "source": [
    "# Create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "624b050c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "dataloaders = []\n",
    "val_dataloaders = []\n",
    "for train in training_data:\n",
    "    dataset = TensorDataset(train, class_labels)\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [ len_train, train.shape[0] -len_train])\n",
    "    loader = DataLoader(train_dataset, batch_size=2,\n",
    "                    pin_memory=False, shuffle=True)\n",
    "    val_loader = DataLoader(train_dataset, batch_size=2,\n",
    "                    pin_memory=False, shuffle=True)\n",
    "    dataloaders.append(loader)\n",
    "    val_dataloaders.append(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b62cd62",
   "metadata": {},
   "source": [
    "# Create classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cdc0def2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = []\n",
    "for classifier_size in linear_classifier_sizes:    \n",
    "    classifiers.append(LinearClassifier(classifier_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaccf7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1116f271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(classifier, dataloader, val_dataloader):\n",
    "    clf = classifier.cuda()\n",
    "    early_stopping = EarlyStopping()\n",
    "    optimizer = torch.optim.SGD(clf.parameters(), lr=0.001)\n",
    "    for it in range(n_epochs):\n",
    "        for i, data in enumerate(dataloader,0):\n",
    "            inputs, labels = data\n",
    "            inputs = Variable(inputs, requires_grad=True)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = clf(inputs.cuda().float())\n",
    "\n",
    "            loss = criterion(outputs.cuda().float(), labels.cuda().reshape(-1,1).float())\n",
    "            loss.backward()\n",
    "            \n",
    "            \n",
    "            optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(val_dataloader,0):\n",
    "                inputs, labels = data\n",
    "                inputs = Variable(inputs)\n",
    "                outputs = clf(inputs.cuda().float())\n",
    "\n",
    "                loss = criterion(outputs.cuda().float(), labels.cuda().reshape(-1,1).float()) \n",
    "        \n",
    "            early_stopping(loss)\n",
    "        if it % 10 == 0:\n",
    "            pass\n",
    "        if early_stopping.early_stop:\n",
    "            print(loss)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "37b30d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torch.utils.data.dataloader.DataLoader at 0x7f1b65ade9a0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f1b64662850>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f1b64662c40>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f1b64662820>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f1b64662610>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f1b65a7fcd0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f1b65a854c0>]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9248d80",
   "metadata": {},
   "source": [
    "# Training Classifiers Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c223ded7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearClassifier(\n",
      "  (linear1): Linear(in_features=37632, out_features=1, bias=True)\n",
      ")\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 4 of 5\n",
      "INFO: Early stopping counter 5 of 5\n",
      "INFO: Early stopping\n",
      "tensor(0.0622, device='cuda:0')\n",
      "trained a classifier\n",
      "LinearClassifier(\n",
      "  (linear1): Linear(in_features=38400, out_features=1, bias=True)\n",
      ")\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 4 of 5\n",
      "INFO: Early stopping counter 5 of 5\n",
      "INFO: Early stopping\n",
      "tensor(0.4219, device='cuda:0')\n",
      "trained a classifier\n",
      "LinearClassifier(\n",
      "  (linear1): Linear(in_features=38400, out_features=1, bias=True)\n",
      ")\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 4 of 5\n",
      "INFO: Early stopping counter 5 of 5\n",
      "INFO: Early stopping\n",
      "tensor(0.4266, device='cuda:0')\n",
      "trained a classifier\n",
      "LinearClassifier(\n",
      "  (linear1): Linear(in_features=38400, out_features=1, bias=True)\n",
      ")\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 4 of 5\n",
      "INFO: Early stopping counter 5 of 5\n",
      "INFO: Early stopping\n",
      "tensor(0.4683, device='cuda:0')\n",
      "trained a classifier\n",
      "LinearClassifier(\n",
      "  (linear1): Linear(in_features=38400, out_features=1, bias=True)\n",
      ")\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 4 of 5\n",
      "INFO: Early stopping counter 5 of 5\n",
      "INFO: Early stopping\n",
      "tensor(0.5918, device='cuda:0')\n",
      "trained a classifier\n",
      "LinearClassifier(\n",
      "  (linear1): Linear(in_features=38400, out_features=1, bias=True)\n",
      ")\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 4 of 5\n",
      "INFO: Early stopping counter 5 of 5\n",
      "INFO: Early stopping\n",
      "tensor(0.7382, device='cuda:0')\n",
      "trained a classifier\n",
      "LinearClassifier(\n",
      "  (linear1): Linear(in_features=38400, out_features=1, bias=True)\n",
      ")\n",
      "INFO: Early stopping counter 1 of 5\n",
      "INFO: Early stopping counter 2 of 5\n",
      "INFO: Early stopping counter 3 of 5\n",
      "INFO: Early stopping counter 4 of 5\n",
      "INFO: Early stopping counter 5 of 5\n",
      "INFO: Early stopping\n",
      "tensor(0.7368, device='cuda:0')\n",
      "trained a classifier\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "for classifier, dataloader, val_dataloader in zip(classifiers, dataloaders, val_dataloaders):\n",
    "    print(classifier)\n",
    "    train_classifier(classifier, dataloader,val_dataloader)\n",
    "    print(\"trained a classifier\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "895c8c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"cached_classifiers.pkl\",\"wb\") as f:\n",
    "    pickle.dump(classifiers,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a01bbdb",
   "metadata": {},
   "source": [
    "# Get orthogonal vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2164907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_orthogonal_vector(classifier, classifier_size):\n",
    "    weight, bias = [param for param in classifier.parameters()]\n",
    "    cav_vector = weight.squeeze().cpu().detach().numpy()\n",
    "    orthonormal_vector = np.random.randn(classifier_size)  # take a random vector\n",
    "    orthonormal_vector -= orthonormal_vector.dot(cav_vector) * cav_vector / np.linalg.norm(cav_vector)**2\n",
    "    orthonormal_vector /= np.linalg.norm(orthonormal_vector) \n",
    "    return orthonormal_vector, cav_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e831105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cavs = [get_orthogonal_vector(classifier, classifier_size) for classifier, classifier_size in zip(classifiers, linear_classifier_sizes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599946ba",
   "metadata": {},
   "source": [
    "# Check orthogonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cb4f6821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.1899124090566926e-10,\n",
       " 5.035230956143555e-10,\n",
       " 4.686241134727043e-10,\n",
       " 2.495054813797526e-11,\n",
       " -3.7813513171364166e-11,\n",
       " -8.493784451821251e-12,\n",
       " 5.064932414450274e-11]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.dot(orthonormal_vector,cav_vector) for orthonormal_vector, cav_vector in cavs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b9e46e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(3.1576, device='cuda:0')\n",
      "1\n",
      "tensor(0.9237, device='cuda:0')\n",
      "2\n",
      "tensor(2.2916, device='cuda:0')\n",
      "3\n",
      "tensor(1.3362, device='cuda:0')\n",
      "4\n",
      "tensor(0.2581, device='cuda:0')\n",
      "5\n",
      "tensor(0.9651, device='cuda:0')\n",
      "6\n",
      "tensor(-0.2086, device='cuda:0')\n",
      "7\n",
      "tensor(3.5177, device='cuda:0')\n",
      "8\n",
      "tensor(1.9983, device='cuda:0')\n",
      "9\n",
      "tensor(2.2666, device='cuda:0')\n",
      "10\n",
      "tensor(2.7793, device='cuda:0')\n",
      "11\n",
      "tensor(1.3769, device='cuda:0')\n",
      "12\n",
      "tensor(2.6567, device='cuda:0')\n",
      "13\n",
      "tensor(3.3030, device='cuda:0')\n",
      "14\n",
      "tensor(-0.0600, device='cuda:0')\n",
      "15\n",
      "tensor(1.2082, device='cuda:0')\n",
      "16\n",
      "tensor(2.0105, device='cuda:0')\n",
      "17\n",
      "tensor(2.5700, device='cuda:0')\n",
      "18\n",
      "tensor(3.3431, device='cuda:0')\n",
      "19\n",
      "tensor(-0.1400, device='cuda:0')\n",
      "20\n",
      "tensor(1.3527, device='cuda:0')\n",
      "21\n",
      "tensor(1.8662, device='cuda:0')\n",
      "22\n",
      "tensor(-0.1866, device='cuda:0')\n",
      "23\n",
      "tensor(2.8525, device='cuda:0')\n",
      "24\n",
      "tensor(0.3161, device='cuda:0')\n",
      "25\n",
      "tensor(0.6625, device='cuda:0')\n",
      "26\n",
      "tensor(4.6133, device='cuda:0')\n",
      "27\n",
      "tensor(1.4815, device='cuda:0')\n",
      "28\n",
      "tensor(2.0673, device='cuda:0')\n",
      "29\n",
      "tensor(-1.6110, device='cuda:0')\n",
      "30\n",
      "tensor(-0.6313, device='cuda:0')\n",
      "31\n",
      "tensor(1.4852, device='cuda:0')\n",
      "32\n",
      "tensor(-0.9702, device='cuda:0')\n",
      "33\n",
      "tensor(1.2242, device='cuda:0')\n",
      "34\n",
      "tensor(0.7463, device='cuda:0')\n",
      "35\n",
      "tensor(-0.8205, device='cuda:0')\n",
      "36\n",
      "tensor(2.7733, device='cuda:0')\n",
      "37\n",
      "tensor(-0.8204, device='cuda:0')\n",
      "38\n",
      "tensor(-0.4126, device='cuda:0')\n",
      "39\n",
      "tensor(2.5732, device='cuda:0')\n",
      "40\n",
      "tensor(2.8331, device='cuda:0')\n",
      "41\n",
      "tensor(0.9775, device='cuda:0')\n",
      "42\n",
      "tensor(0.0273, device='cuda:0')\n",
      "43\n",
      "tensor(1.6418, device='cuda:0')\n",
      "44\n",
      "tensor(3.1546, device='cuda:0')\n",
      "45\n",
      "tensor(0.1406, device='cuda:0')\n",
      "46\n",
      "tensor(2.8893, device='cuda:0')\n",
      "47\n",
      "tensor(-0.6109, device='cuda:0')\n",
      "48\n",
      "tensor(1.7399, device='cuda:0')\n",
      "49\n",
      "tensor(1.3440, device='cuda:0')\n",
      "50\n",
      "tensor(0.4699, device='cuda:0')\n",
      "51\n",
      "tensor(-0.1536, device='cuda:0')\n",
      "52\n",
      "tensor(-1.2936, device='cuda:0')\n",
      "53\n",
      "tensor(-2.1460, device='cuda:0')\n",
      "54\n",
      "tensor(-2.5841, device='cuda:0')\n",
      "55\n",
      "tensor(-2.1245, device='cuda:0')\n",
      "56\n",
      "tensor(-1.6007, device='cuda:0')\n",
      "57\n",
      "tensor(-2.1399, device='cuda:0')\n",
      "58\n",
      "tensor(-1.6892, device='cuda:0')\n",
      "59\n",
      "tensor(-2.4402, device='cuda:0')\n",
      "60\n",
      "tensor(-1.4207, device='cuda:0')\n",
      "61\n",
      "tensor(-2.0596, device='cuda:0')\n",
      "62\n",
      "tensor(-1.7742, device='cuda:0')\n",
      "63\n",
      "tensor(-2.5629, device='cuda:0')\n",
      "64\n",
      "tensor(-1.1148, device='cuda:0')\n",
      "65\n",
      "tensor(-1.6726, device='cuda:0')\n",
      "66\n",
      "tensor(-1.4799, device='cuda:0')\n",
      "67\n",
      "tensor(-0.8493, device='cuda:0')\n",
      "68\n",
      "tensor(-2.1513, device='cuda:0')\n",
      "69\n",
      "tensor(-0.2904, device='cuda:0')\n",
      "70\n",
      "tensor(-1.0955, device='cuda:0')\n",
      "71\n",
      "tensor(-1.4819, device='cuda:0')\n",
      "72\n",
      "tensor(-1.3047, device='cuda:0')\n",
      "73\n",
      "tensor(1.4018, device='cuda:0')\n",
      "74\n",
      "tensor(-1.2494, device='cuda:0')\n",
      "75\n",
      "tensor(-2.3232, device='cuda:0')\n",
      "76\n",
      "tensor(-1.3106, device='cuda:0')\n",
      "77\n",
      "tensor(0.1450, device='cuda:0')\n",
      "78\n",
      "tensor(-2.8356, device='cuda:0')\n",
      "79\n",
      "tensor(-1.5138, device='cuda:0')\n",
      "80\n",
      "tensor(-0.6170, device='cuda:0')\n",
      "81\n",
      "tensor(0.7691, device='cuda:0')\n",
      "82\n",
      "tensor(-0.3107, device='cuda:0')\n",
      "83\n",
      "tensor(-2.4926, device='cuda:0')\n",
      "84\n",
      "tensor(-1.1642, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(85):\n",
    "    print(i)\n",
    "    print(torch.dot(all_layer_gradients['layer0'][0].view(85,-1)[i], torch.tensor(cavs[0][1]).cuda() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f9e039ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(5.6702, device='cuda:0')\n",
      "1\n",
      "tensor(3.9695, device='cuda:0')\n",
      "2\n",
      "tensor(1.4329, device='cuda:0')\n",
      "3\n",
      "tensor(0.9419, device='cuda:0')\n",
      "4\n",
      "tensor(0.0106, device='cuda:0')\n",
      "5\n",
      "tensor(1.2248, device='cuda:0')\n",
      "6\n",
      "tensor(-0.0851, device='cuda:0')\n",
      "7\n",
      "tensor(-0.1159, device='cuda:0')\n",
      "8\n",
      "tensor(0.7661, device='cuda:0')\n",
      "9\n",
      "tensor(0.6483, device='cuda:0')\n",
      "10\n",
      "tensor(0.0589, device='cuda:0')\n",
      "11\n",
      "tensor(0.8473, device='cuda:0')\n",
      "12\n",
      "tensor(0.0159, device='cuda:0')\n",
      "13\n",
      "tensor(0.9787, device='cuda:0')\n",
      "14\n",
      "tensor(1.2873, device='cuda:0')\n",
      "15\n",
      "tensor(0.5961, device='cuda:0')\n",
      "16\n",
      "tensor(0.4017, device='cuda:0')\n",
      "17\n",
      "tensor(-0.1369, device='cuda:0')\n",
      "18\n",
      "tensor(0.7163, device='cuda:0')\n",
      "19\n",
      "tensor(0.8413, device='cuda:0')\n",
      "20\n",
      "tensor(-0.0288, device='cuda:0')\n",
      "21\n",
      "tensor(0.6438, device='cuda:0')\n",
      "22\n",
      "tensor(0.8506, device='cuda:0')\n",
      "23\n",
      "tensor(0.8276, device='cuda:0')\n",
      "24\n",
      "tensor(0.8787, device='cuda:0')\n",
      "25\n",
      "tensor(1.0171, device='cuda:0')\n",
      "26\n",
      "tensor(1.0181, device='cuda:0')\n",
      "27\n",
      "tensor(-0.0558, device='cuda:0')\n",
      "28\n",
      "tensor(-0.0678, device='cuda:0')\n",
      "29\n",
      "tensor(0.5698, device='cuda:0')\n",
      "30\n",
      "tensor(0.7449, device='cuda:0')\n",
      "31\n",
      "tensor(-0.2129, device='cuda:0')\n",
      "32\n",
      "tensor(0.8939, device='cuda:0')\n",
      "33\n",
      "tensor(-0.0617, device='cuda:0')\n",
      "34\n",
      "tensor(0.4420, device='cuda:0')\n",
      "35\n",
      "tensor(0.8251, device='cuda:0')\n",
      "36\n",
      "tensor(0.7802, device='cuda:0')\n",
      "37\n",
      "tensor(0.8709, device='cuda:0')\n",
      "38\n",
      "tensor(0.7960, device='cuda:0')\n",
      "39\n",
      "tensor(0.7357, device='cuda:0')\n",
      "40\n",
      "tensor(-0.0484, device='cuda:0')\n",
      "41\n",
      "tensor(-0.0743, device='cuda:0')\n",
      "42\n",
      "tensor(0.7149, device='cuda:0')\n",
      "43\n",
      "tensor(1.0413, device='cuda:0')\n",
      "44\n",
      "tensor(-0.0377, device='cuda:0')\n",
      "45\n",
      "tensor(-0.1663, device='cuda:0')\n",
      "46\n",
      "tensor(-0.2460, device='cuda:0')\n",
      "47\n",
      "tensor(-0.0858, device='cuda:0')\n",
      "48\n",
      "tensor(0.7927, device='cuda:0')\n",
      "49\n",
      "tensor(0.9420, device='cuda:0')\n",
      "50\n",
      "tensor(-0.9635, device='cuda:0')\n",
      "51\n",
      "tensor(-1.0350, device='cuda:0')\n",
      "52\n",
      "tensor(-0.6800, device='cuda:0')\n",
      "53\n",
      "tensor(-0.7099, device='cuda:0')\n",
      "54\n",
      "tensor(0.0151, device='cuda:0')\n",
      "55\n",
      "tensor(-1.0709, device='cuda:0')\n",
      "56\n",
      "tensor(-0.4244, device='cuda:0')\n",
      "57\n",
      "tensor(-0.7772, device='cuda:0')\n",
      "58\n",
      "tensor(-1.0782, device='cuda:0')\n",
      "59\n",
      "tensor(-0.7267, device='cuda:0')\n",
      "60\n",
      "tensor(-0.9144, device='cuda:0')\n",
      "61\n",
      "tensor(-1.2305, device='cuda:0')\n",
      "62\n",
      "tensor(-0.6857, device='cuda:0')\n",
      "63\n",
      "tensor(-0.8735, device='cuda:0')\n",
      "64\n",
      "tensor(-0.8235, device='cuda:0')\n",
      "65\n",
      "tensor(-0.2781, device='cuda:0')\n",
      "66\n",
      "tensor(0.0222, device='cuda:0')\n",
      "67\n",
      "tensor(-1.2045, device='cuda:0')\n",
      "68\n",
      "tensor(-0.0633, device='cuda:0')\n",
      "69\n",
      "tensor(-0.6936, device='cuda:0')\n",
      "70\n",
      "tensor(-0.7994, device='cuda:0')\n",
      "71\n",
      "tensor(-0.7645, device='cuda:0')\n",
      "72\n",
      "tensor(-0.9656, device='cuda:0')\n",
      "73\n",
      "tensor(-1.8796, device='cuda:0')\n",
      "74\n",
      "tensor(-0.0593, device='cuda:0')\n",
      "75\n",
      "tensor(-1.3407, device='cuda:0')\n",
      "76\n",
      "tensor(-1.1507, device='cuda:0')\n",
      "77\n",
      "tensor(-1.1619, device='cuda:0')\n",
      "78\n",
      "tensor(-0.2690, device='cuda:0')\n",
      "79\n",
      "tensor(-0.0748, device='cuda:0')\n",
      "80\n",
      "tensor(-0.2692, device='cuda:0')\n",
      "81\n",
      "tensor(-1.1729, device='cuda:0')\n",
      "82\n",
      "tensor(-1.3065, device='cuda:0')\n",
      "83\n",
      "tensor(-1.4695, device='cuda:0')\n",
      "84\n",
      "tensor(-0.0657, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(85):\n",
    "    print(i)\n",
    "    print(torch.dot(all_layer_gradients['layer1'][0].view(85,-1)[i], torch.tensor(cavs[1][1]).cuda() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d62ef92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(7.8871, device='cuda:0')\n",
      "1\n",
      "tensor(4.2670, device='cuda:0')\n",
      "2\n",
      "tensor(1.5204, device='cuda:0')\n",
      "3\n",
      "tensor(0.9167, device='cuda:0')\n",
      "4\n",
      "tensor(0.0608, device='cuda:0')\n",
      "5\n",
      "tensor(-0.0854, device='cuda:0')\n",
      "6\n",
      "tensor(0.5544, device='cuda:0')\n",
      "7\n",
      "tensor(0.8682, device='cuda:0')\n",
      "8\n",
      "tensor(0.0067, device='cuda:0')\n",
      "9\n",
      "tensor(0.0300, device='cuda:0')\n",
      "10\n",
      "tensor(1.0211, device='cuda:0')\n",
      "11\n",
      "tensor(-0.0455, device='cuda:0')\n",
      "12\n",
      "tensor(-0.2739, device='cuda:0')\n",
      "13\n",
      "tensor(-0.0963, device='cuda:0')\n",
      "14\n",
      "tensor(1.0677, device='cuda:0')\n",
      "15\n",
      "tensor(0.6390, device='cuda:0')\n",
      "16\n",
      "tensor(-0.1569, device='cuda:0')\n",
      "17\n",
      "tensor(0.4333, device='cuda:0')\n",
      "18\n",
      "tensor(0.6834, device='cuda:0')\n",
      "19\n",
      "tensor(0.7324, device='cuda:0')\n",
      "20\n",
      "tensor(0.7751, device='cuda:0')\n",
      "21\n",
      "tensor(0.6463, device='cuda:0')\n",
      "22\n",
      "tensor(0.5030, device='cuda:0')\n",
      "23\n",
      "tensor(0.0405, device='cuda:0')\n",
      "24\n",
      "tensor(0.7992, device='cuda:0')\n",
      "25\n",
      "tensor(0.7743, device='cuda:0')\n",
      "26\n",
      "tensor(0.9330, device='cuda:0')\n",
      "27\n",
      "tensor(0.0239, device='cuda:0')\n",
      "28\n",
      "tensor(0.6674, device='cuda:0')\n",
      "29\n",
      "tensor(0.4182, device='cuda:0')\n",
      "30\n",
      "tensor(-0.0596, device='cuda:0')\n",
      "31\n",
      "tensor(0.8032, device='cuda:0')\n",
      "32\n",
      "tensor(0.9661, device='cuda:0')\n",
      "33\n",
      "tensor(1.0739, device='cuda:0')\n",
      "34\n",
      "tensor(-0.2209, device='cuda:0')\n",
      "35\n",
      "tensor(-0.0424, device='cuda:0')\n",
      "36\n",
      "tensor(0.7078, device='cuda:0')\n",
      "37\n",
      "tensor(0.7547, device='cuda:0')\n",
      "38\n",
      "tensor(0.6074, device='cuda:0')\n",
      "39\n",
      "tensor(-0.1312, device='cuda:0')\n",
      "40\n",
      "tensor(0.7353, device='cuda:0')\n",
      "41\n",
      "tensor(-0.1338, device='cuda:0')\n",
      "42\n",
      "tensor(-0.0642, device='cuda:0')\n",
      "43\n",
      "tensor(0.8749, device='cuda:0')\n",
      "44\n",
      "tensor(0.6490, device='cuda:0')\n",
      "45\n",
      "tensor(-0.0914, device='cuda:0')\n",
      "46\n",
      "tensor(-0.0699, device='cuda:0')\n",
      "47\n",
      "tensor(0.6181, device='cuda:0')\n",
      "48\n",
      "tensor(-0.1484, device='cuda:0')\n",
      "49\n",
      "tensor(0.8723, device='cuda:0')\n",
      "50\n",
      "tensor(-0.8999, device='cuda:0')\n",
      "51\n",
      "tensor(-0.8893, device='cuda:0')\n",
      "52\n",
      "tensor(-0.1330, device='cuda:0')\n",
      "53\n",
      "tensor(-0.5637, device='cuda:0')\n",
      "54\n",
      "tensor(-0.8073, device='cuda:0')\n",
      "55\n",
      "tensor(-0.9770, device='cuda:0')\n",
      "56\n",
      "tensor(-0.5557, device='cuda:0')\n",
      "57\n",
      "tensor(-0.8896, device='cuda:0')\n",
      "58\n",
      "tensor(-0.9036, device='cuda:0')\n",
      "59\n",
      "tensor(-0.0834, device='cuda:0')\n",
      "60\n",
      "tensor(-0.8381, device='cuda:0')\n",
      "61\n",
      "tensor(-0.2544, device='cuda:0')\n",
      "62\n",
      "tensor(-0.7759, device='cuda:0')\n",
      "63\n",
      "tensor(-0.8614, device='cuda:0')\n",
      "64\n",
      "tensor(-0.8106, device='cuda:0')\n",
      "65\n",
      "tensor(-0.7104, device='cuda:0')\n",
      "66\n",
      "tensor(-0.0001, device='cuda:0')\n",
      "67\n",
      "tensor(-0.8717, device='cuda:0')\n",
      "68\n",
      "tensor(-0.8157, device='cuda:0')\n",
      "69\n",
      "tensor(-0.0148, device='cuda:0')\n",
      "70\n",
      "tensor(-0.6609, device='cuda:0')\n",
      "71\n",
      "tensor(-0.7425, device='cuda:0')\n",
      "72\n",
      "tensor(-0.8536, device='cuda:0')\n",
      "73\n",
      "tensor(-1.7675, device='cuda:0')\n",
      "74\n",
      "tensor(-0.2177, device='cuda:0')\n",
      "75\n",
      "tensor(-1.3445, device='cuda:0')\n",
      "76\n",
      "tensor(-0.9319, device='cuda:0')\n",
      "77\n",
      "tensor(-1.0712, device='cuda:0')\n",
      "78\n",
      "tensor(-1.2991, device='cuda:0')\n",
      "79\n",
      "tensor(-1.1497, device='cuda:0')\n",
      "80\n",
      "tensor(-1.3629, device='cuda:0')\n",
      "81\n",
      "tensor(-0.9397, device='cuda:0')\n",
      "82\n",
      "tensor(-1.2208, device='cuda:0')\n",
      "83\n",
      "tensor(-1.4255, device='cuda:0')\n",
      "84\n",
      "tensor(-0.3417, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(85):\n",
    "    print(i)\n",
    "    print(torch.dot(all_layer_gradients['layer3'][0].view(85,-1)[i], torch.tensor(cavs[2][1]).cuda() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a2cf16f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(5.0756, device='cuda:0')\n",
      "1\n",
      "tensor(3.6719, device='cuda:0')\n",
      "2\n",
      "tensor(0.8010, device='cuda:0')\n",
      "3\n",
      "tensor(0.4374, device='cuda:0')\n",
      "4\n",
      "tensor(0.3537, device='cuda:0')\n",
      "5\n",
      "tensor(0.5322, device='cuda:0')\n",
      "6\n",
      "tensor(0.0891, device='cuda:0')\n",
      "7\n",
      "tensor(0.4082, device='cuda:0')\n",
      "8\n",
      "tensor(0.0384, device='cuda:0')\n",
      "9\n",
      "tensor(0.0883, device='cuda:0')\n",
      "10\n",
      "tensor(0.0774, device='cuda:0')\n",
      "11\n",
      "tensor(0.0869, device='cuda:0')\n",
      "12\n",
      "tensor(0.0322, device='cuda:0')\n",
      "13\n",
      "tensor(0.4059, device='cuda:0')\n",
      "14\n",
      "tensor(0.4620, device='cuda:0')\n",
      "15\n",
      "tensor(0.1910, device='cuda:0')\n",
      "16\n",
      "tensor(0.2752, device='cuda:0')\n",
      "17\n",
      "tensor(0.2014, device='cuda:0')\n",
      "18\n",
      "tensor(0.2736, device='cuda:0')\n",
      "19\n",
      "tensor(0.3711, device='cuda:0')\n",
      "20\n",
      "tensor(0.2790, device='cuda:0')\n",
      "21\n",
      "tensor(0.3665, device='cuda:0')\n",
      "22\n",
      "tensor(0.3064, device='cuda:0')\n",
      "23\n",
      "tensor(0.4076, device='cuda:0')\n",
      "24\n",
      "tensor(0.3593, device='cuda:0')\n",
      "25\n",
      "tensor(0.3061, device='cuda:0')\n",
      "26\n",
      "tensor(0.4341, device='cuda:0')\n",
      "27\n",
      "tensor(0.1547, device='cuda:0')\n",
      "28\n",
      "tensor(0.3427, device='cuda:0')\n",
      "29\n",
      "tensor(0.0096, device='cuda:0')\n",
      "30\n",
      "tensor(0.3548, device='cuda:0')\n",
      "31\n",
      "tensor(0.2923, device='cuda:0')\n",
      "32\n",
      "tensor(0.0512, device='cuda:0')\n",
      "33\n",
      "tensor(0.5004, device='cuda:0')\n",
      "34\n",
      "tensor(0.1411, device='cuda:0')\n",
      "35\n",
      "tensor(0.4610, device='cuda:0')\n",
      "36\n",
      "tensor(0.0963, device='cuda:0')\n",
      "37\n",
      "tensor(0.2951, device='cuda:0')\n",
      "38\n",
      "tensor(0.2799, device='cuda:0')\n",
      "39\n",
      "tensor(0.3092, device='cuda:0')\n",
      "40\n",
      "tensor(0.3391, device='cuda:0')\n",
      "41\n",
      "tensor(0.0430, device='cuda:0')\n",
      "42\n",
      "tensor(0.2921, device='cuda:0')\n",
      "43\n",
      "tensor(0.4156, device='cuda:0')\n",
      "44\n",
      "tensor(0.0296, device='cuda:0')\n",
      "45\n",
      "tensor(0.3932, device='cuda:0')\n",
      "46\n",
      "tensor(0.0044, device='cuda:0')\n",
      "47\n",
      "tensor(0.3052, device='cuda:0')\n",
      "48\n",
      "tensor(0.0503, device='cuda:0')\n",
      "49\n",
      "tensor(0.4611, device='cuda:0')\n",
      "50\n",
      "tensor(-0.0267, device='cuda:0')\n",
      "51\n",
      "tensor(-0.2034, device='cuda:0')\n",
      "52\n",
      "tensor(-0.2486, device='cuda:0')\n",
      "53\n",
      "tensor(0.0533, device='cuda:0')\n",
      "54\n",
      "tensor(0.0631, device='cuda:0')\n",
      "55\n",
      "tensor(-0.3616, device='cuda:0')\n",
      "56\n",
      "tensor(0.0976, device='cuda:0')\n",
      "57\n",
      "tensor(0.0491, device='cuda:0')\n",
      "58\n",
      "tensor(0.0217, device='cuda:0')\n",
      "59\n",
      "tensor(-0.2367, device='cuda:0')\n",
      "60\n",
      "tensor(0.0336, device='cuda:0')\n",
      "61\n",
      "tensor(-0.3322, device='cuda:0')\n",
      "62\n",
      "tensor(-0.2198, device='cuda:0')\n",
      "63\n",
      "tensor(-0.2160, device='cuda:0')\n",
      "64\n",
      "tensor(-0.2008, device='cuda:0')\n",
      "65\n",
      "tensor(-0.1879, device='cuda:0')\n",
      "66\n",
      "tensor(-0.2120, device='cuda:0')\n",
      "67\n",
      "tensor(-0.2405, device='cuda:0')\n",
      "68\n",
      "tensor(-0.1789, device='cuda:0')\n",
      "69\n",
      "tensor(-0.1901, device='cuda:0')\n",
      "70\n",
      "tensor(0.1109, device='cuda:0')\n",
      "71\n",
      "tensor(-0.1490, device='cuda:0')\n",
      "72\n",
      "tensor(0.0483, device='cuda:0')\n",
      "73\n",
      "tensor(-0.4914, device='cuda:0')\n",
      "74\n",
      "tensor(-0.0435, device='cuda:0')\n",
      "75\n",
      "tensor(-0.3314, device='cuda:0')\n",
      "76\n",
      "tensor(-0.0133, device='cuda:0')\n",
      "77\n",
      "tensor(-0.3428, device='cuda:0')\n",
      "78\n",
      "tensor(-0.4205, device='cuda:0')\n",
      "79\n",
      "tensor(-0.3488, device='cuda:0')\n",
      "80\n",
      "tensor(-0.0808, device='cuda:0')\n",
      "81\n",
      "tensor(0.0256, device='cuda:0')\n",
      "82\n",
      "tensor(-0.3680, device='cuda:0')\n",
      "83\n",
      "tensor(-0.5857, device='cuda:0')\n",
      "84\n",
      "tensor(-0.3531, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(85):\n",
    "    print(i)\n",
    "    print(torch.dot(all_layer_gradients['layer5'][0].view(85,-1)[i], torch.tensor(cavs[3][1]).cuda() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fe0f731a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(-1.1681, device='cuda:0')\n",
      "1\n",
      "tensor(-0.4685, device='cuda:0')\n",
      "2\n",
      "tensor(0.0228, device='cuda:0')\n",
      "3\n",
      "tensor(0.1466, device='cuda:0')\n",
      "4\n",
      "tensor(0.1614, device='cuda:0')\n",
      "5\n",
      "tensor(0.0619, device='cuda:0')\n",
      "6\n",
      "tensor(0.1490, device='cuda:0')\n",
      "7\n",
      "tensor(0.1648, device='cuda:0')\n",
      "8\n",
      "tensor(0.1493, device='cuda:0')\n",
      "9\n",
      "tensor(0.1720, device='cuda:0')\n",
      "10\n",
      "tensor(0.2074, device='cuda:0')\n",
      "11\n",
      "tensor(0.1479, device='cuda:0')\n",
      "12\n",
      "tensor(0.3873, device='cuda:0')\n",
      "13\n",
      "tensor(0.1705, device='cuda:0')\n",
      "14\n",
      "tensor(0.2090, device='cuda:0')\n",
      "15\n",
      "tensor(0.2053, device='cuda:0')\n",
      "16\n",
      "tensor(0.0004, device='cuda:0')\n",
      "17\n",
      "tensor(0.0241, device='cuda:0')\n",
      "18\n",
      "tensor(0.1873, device='cuda:0')\n",
      "19\n",
      "tensor(0.1511, device='cuda:0')\n",
      "20\n",
      "tensor(0.0658, device='cuda:0')\n",
      "21\n",
      "tensor(0.2161, device='cuda:0')\n",
      "22\n",
      "tensor(0.1166, device='cuda:0')\n",
      "23\n",
      "tensor(0.2141, device='cuda:0')\n",
      "24\n",
      "tensor(0.0278, device='cuda:0')\n",
      "25\n",
      "tensor(0.0408, device='cuda:0')\n",
      "26\n",
      "tensor(0.2271, device='cuda:0')\n",
      "27\n",
      "tensor(0.1222, device='cuda:0')\n",
      "28\n",
      "tensor(0.0928, device='cuda:0')\n",
      "29\n",
      "tensor(0.1335, device='cuda:0')\n",
      "30\n",
      "tensor(0.1590, device='cuda:0')\n",
      "31\n",
      "tensor(0.0411, device='cuda:0')\n",
      "32\n",
      "tensor(0.2314, device='cuda:0')\n",
      "33\n",
      "tensor(0.0030, device='cuda:0')\n",
      "34\n",
      "tensor(0.1015, device='cuda:0')\n",
      "35\n",
      "tensor(0.3544, device='cuda:0')\n",
      "36\n",
      "tensor(0.0094, device='cuda:0')\n",
      "37\n",
      "tensor(0.0572, device='cuda:0')\n",
      "38\n",
      "tensor(0.1527, device='cuda:0')\n",
      "39\n",
      "tensor(0.1510, device='cuda:0')\n",
      "40\n",
      "tensor(0.1439, device='cuda:0')\n",
      "41\n",
      "tensor(0.0705, device='cuda:0')\n",
      "42\n",
      "tensor(0.2194, device='cuda:0')\n",
      "43\n",
      "tensor(0.0325, device='cuda:0')\n",
      "44\n",
      "tensor(0.1990, device='cuda:0')\n",
      "45\n",
      "tensor(0.2617, device='cuda:0')\n",
      "46\n",
      "tensor(0.2046, device='cuda:0')\n",
      "47\n",
      "tensor(0.0415, device='cuda:0')\n",
      "48\n",
      "tensor(0.1243, device='cuda:0')\n",
      "49\n",
      "tensor(0.2551, device='cuda:0')\n",
      "50\n",
      "tensor(-0.1673, device='cuda:0')\n",
      "51\n",
      "tensor(-0.0372, device='cuda:0')\n",
      "52\n",
      "tensor(-0.0547, device='cuda:0')\n",
      "53\n",
      "tensor(-0.0930, device='cuda:0')\n",
      "54\n",
      "tensor(-0.1184, device='cuda:0')\n",
      "55\n",
      "tensor(-0.1292, device='cuda:0')\n",
      "56\n",
      "tensor(0.0013, device='cuda:0')\n",
      "57\n",
      "tensor(-0.1781, device='cuda:0')\n",
      "58\n",
      "tensor(-0.0727, device='cuda:0')\n",
      "59\n",
      "tensor(-0.1088, device='cuda:0')\n",
      "60\n",
      "tensor(0.0291, device='cuda:0')\n",
      "61\n",
      "tensor(-0.0114, device='cuda:0')\n",
      "62\n",
      "tensor(0.0197, device='cuda:0')\n",
      "63\n",
      "tensor(0.0767, device='cuda:0')\n",
      "64\n",
      "tensor(0.0197, device='cuda:0')\n",
      "65\n",
      "tensor(-0.0225, device='cuda:0')\n",
      "66\n",
      "tensor(0.0664, device='cuda:0')\n",
      "67\n",
      "tensor(-0.1958, device='cuda:0')\n",
      "68\n",
      "tensor(0.0281, device='cuda:0')\n",
      "69\n",
      "tensor(-0.0661, device='cuda:0')\n",
      "70\n",
      "tensor(-0.0966, device='cuda:0')\n",
      "71\n",
      "tensor(0.0476, device='cuda:0')\n",
      "72\n",
      "tensor(0.0599, device='cuda:0')\n",
      "73\n",
      "tensor(-0.1180, device='cuda:0')\n",
      "74\n",
      "tensor(-0.0408, device='cuda:0')\n",
      "75\n",
      "tensor(-0.0827, device='cuda:0')\n",
      "76\n",
      "tensor(-0.0916, device='cuda:0')\n",
      "77\n",
      "tensor(-0.1130, device='cuda:0')\n",
      "78\n",
      "tensor(-0.1097, device='cuda:0')\n",
      "79\n",
      "tensor(-0.0906, device='cuda:0')\n",
      "80\n",
      "tensor(0.0612, device='cuda:0')\n",
      "81\n",
      "tensor(-0.0865, device='cuda:0')\n",
      "82\n",
      "tensor(-0.0639, device='cuda:0')\n",
      "83\n",
      "tensor(0.0776, device='cuda:0')\n",
      "84\n",
      "tensor(-0.1268, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(85):\n",
    "    print(i)\n",
    "    print(torch.dot(all_layer_gradients['layer7'][0].view(85,-1)[i], torch.tensor(cavs[4][1]).cuda() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6406c53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(4.5534, device='cuda:0')\n",
      "1\n",
      "tensor(0.9605, device='cuda:0')\n",
      "2\n",
      "tensor(0.0407, device='cuda:0')\n",
      "3\n",
      "tensor(0.0317, device='cuda:0')\n",
      "4\n",
      "tensor(0.0326, device='cuda:0')\n",
      "5\n",
      "tensor(0.0408, device='cuda:0')\n",
      "6\n",
      "tensor(0.0415, device='cuda:0')\n",
      "7\n",
      "tensor(0.0314, device='cuda:0')\n",
      "8\n",
      "tensor(0.0179, device='cuda:0')\n",
      "9\n",
      "tensor(0.0268, device='cuda:0')\n",
      "10\n",
      "tensor(0.0683, device='cuda:0')\n",
      "11\n",
      "tensor(0.0242, device='cuda:0')\n",
      "12\n",
      "tensor(0.0112, device='cuda:0')\n",
      "13\n",
      "tensor(0.0377, device='cuda:0')\n",
      "14\n",
      "tensor(0.0097, device='cuda:0')\n",
      "15\n",
      "tensor(0.0306, device='cuda:0')\n",
      "16\n",
      "tensor(0.0244, device='cuda:0')\n",
      "17\n",
      "tensor(0.0053, device='cuda:0')\n",
      "18\n",
      "tensor(0.0475, device='cuda:0')\n",
      "19\n",
      "tensor(0.0257, device='cuda:0')\n",
      "20\n",
      "tensor(0.0352, device='cuda:0')\n",
      "21\n",
      "tensor(0.0253, device='cuda:0')\n",
      "22\n",
      "tensor(0.0428, device='cuda:0')\n",
      "23\n",
      "tensor(0.0569, device='cuda:0')\n",
      "24\n",
      "tensor(0.0069, device='cuda:0')\n",
      "25\n",
      "tensor(0.0200, device='cuda:0')\n",
      "26\n",
      "tensor(0.0146, device='cuda:0')\n",
      "27\n",
      "tensor(0.0383, device='cuda:0')\n",
      "28\n",
      "tensor(0.0244, device='cuda:0')\n",
      "29\n",
      "tensor(0.0205, device='cuda:0')\n",
      "30\n",
      "tensor(0.0394, device='cuda:0')\n",
      "31\n",
      "tensor(0.0543, device='cuda:0')\n",
      "32\n",
      "tensor(0.0140, device='cuda:0')\n",
      "33\n",
      "tensor(0.0613, device='cuda:0')\n",
      "34\n",
      "tensor(0.0119, device='cuda:0')\n",
      "35\n",
      "tensor(0.0137, device='cuda:0')\n",
      "36\n",
      "tensor(0.0317, device='cuda:0')\n",
      "37\n",
      "tensor(0.0274, device='cuda:0')\n",
      "38\n",
      "tensor(0.0271, device='cuda:0')\n",
      "39\n",
      "tensor(0.0116, device='cuda:0')\n",
      "40\n",
      "tensor(0.0319, device='cuda:0')\n",
      "41\n",
      "tensor(0.0320, device='cuda:0')\n",
      "42\n",
      "tensor(0.0915, device='cuda:0')\n",
      "43\n",
      "tensor(0.0383, device='cuda:0')\n",
      "44\n",
      "tensor(0.0566, device='cuda:0')\n",
      "45\n",
      "tensor(0.0837, device='cuda:0')\n",
      "46\n",
      "tensor(0.0286, device='cuda:0')\n",
      "47\n",
      "tensor(0.0209, device='cuda:0')\n",
      "48\n",
      "tensor(0.0330, device='cuda:0')\n",
      "49\n",
      "tensor(0.0536, device='cuda:0')\n",
      "50\n",
      "tensor(-0.0311, device='cuda:0')\n",
      "51\n",
      "tensor(0.0091, device='cuda:0')\n",
      "52\n",
      "tensor(-0.0306, device='cuda:0')\n",
      "53\n",
      "tensor(0.0184, device='cuda:0')\n",
      "54\n",
      "tensor(-0.0045, device='cuda:0')\n",
      "55\n",
      "tensor(-0.0248, device='cuda:0')\n",
      "56\n",
      "tensor(0.0031, device='cuda:0')\n",
      "57\n",
      "tensor(-0.0172, device='cuda:0')\n",
      "58\n",
      "tensor(0.0039, device='cuda:0')\n",
      "59\n",
      "tensor(-0.0204, device='cuda:0')\n",
      "60\n",
      "tensor(0.0053, device='cuda:0')\n",
      "61\n",
      "tensor(0.0157, device='cuda:0')\n",
      "62\n",
      "tensor(0.0032, device='cuda:0')\n",
      "63\n",
      "tensor(0.0117, device='cuda:0')\n",
      "64\n",
      "tensor(0.0101, device='cuda:0')\n",
      "65\n",
      "tensor(0.0098, device='cuda:0')\n",
      "66\n",
      "tensor(0.0138, device='cuda:0')\n",
      "67\n",
      "tensor(-0.0306, device='cuda:0')\n",
      "68\n",
      "tensor(0.0066, device='cuda:0')\n",
      "69\n",
      "tensor(-0.0280, device='cuda:0')\n",
      "70\n",
      "tensor(0.0127, device='cuda:0')\n",
      "71\n",
      "tensor(0.0158, device='cuda:0')\n",
      "72\n",
      "tensor(0.0189, device='cuda:0')\n",
      "73\n",
      "tensor(0.0042, device='cuda:0')\n",
      "74\n",
      "tensor(0.0042, device='cuda:0')\n",
      "75\n",
      "tensor(5.2242e-05, device='cuda:0')\n",
      "76\n",
      "tensor(-0.0086, device='cuda:0')\n",
      "77\n",
      "tensor(-0.0018, device='cuda:0')\n",
      "78\n",
      "tensor(0.0203, device='cuda:0')\n",
      "79\n",
      "tensor(-0.0030, device='cuda:0')\n",
      "80\n",
      "tensor(-0.0015, device='cuda:0')\n",
      "81\n",
      "tensor(-0.0053, device='cuda:0')\n",
      "82\n",
      "tensor(0.0017, device='cuda:0')\n",
      "83\n",
      "tensor(-0.0010, device='cuda:0')\n",
      "84\n",
      "tensor(-0.0094, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(85):\n",
    "    print(i)\n",
    "    print(torch.dot(all_layer_gradients['layer9'][0].view(85,-1)[i], torch.tensor(cavs[5][1]).cuda() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "84944f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(4.5974, device='cuda:0')\n",
      "1\n",
      "tensor(5.0867, device='cuda:0')\n",
      "2\n",
      "tensor(0., device='cuda:0')\n",
      "3\n",
      "tensor(0., device='cuda:0')\n",
      "4\n",
      "tensor(0., device='cuda:0')\n",
      "5\n",
      "tensor(0., device='cuda:0')\n",
      "6\n",
      "tensor(0., device='cuda:0')\n",
      "7\n",
      "tensor(0., device='cuda:0')\n",
      "8\n",
      "tensor(0., device='cuda:0')\n",
      "9\n",
      "tensor(0., device='cuda:0')\n",
      "10\n",
      "tensor(0., device='cuda:0')\n",
      "11\n",
      "tensor(0., device='cuda:0')\n",
      "12\n",
      "tensor(0., device='cuda:0')\n",
      "13\n",
      "tensor(0., device='cuda:0')\n",
      "14\n",
      "tensor(0., device='cuda:0')\n",
      "15\n",
      "tensor(0., device='cuda:0')\n",
      "16\n",
      "tensor(0., device='cuda:0')\n",
      "17\n",
      "tensor(0., device='cuda:0')\n",
      "18\n",
      "tensor(0., device='cuda:0')\n",
      "19\n",
      "tensor(0., device='cuda:0')\n",
      "20\n",
      "tensor(0., device='cuda:0')\n",
      "21\n",
      "tensor(0., device='cuda:0')\n",
      "22\n",
      "tensor(0., device='cuda:0')\n",
      "23\n",
      "tensor(0., device='cuda:0')\n",
      "24\n",
      "tensor(0., device='cuda:0')\n",
      "25\n",
      "tensor(0., device='cuda:0')\n",
      "26\n",
      "tensor(0., device='cuda:0')\n",
      "27\n",
      "tensor(0., device='cuda:0')\n",
      "28\n",
      "tensor(0., device='cuda:0')\n",
      "29\n",
      "tensor(0., device='cuda:0')\n",
      "30\n",
      "tensor(0., device='cuda:0')\n",
      "31\n",
      "tensor(0., device='cuda:0')\n",
      "32\n",
      "tensor(0., device='cuda:0')\n",
      "33\n",
      "tensor(0., device='cuda:0')\n",
      "34\n",
      "tensor(0., device='cuda:0')\n",
      "35\n",
      "tensor(0., device='cuda:0')\n",
      "36\n",
      "tensor(0., device='cuda:0')\n",
      "37\n",
      "tensor(0., device='cuda:0')\n",
      "38\n",
      "tensor(0., device='cuda:0')\n",
      "39\n",
      "tensor(0., device='cuda:0')\n",
      "40\n",
      "tensor(0., device='cuda:0')\n",
      "41\n",
      "tensor(0., device='cuda:0')\n",
      "42\n",
      "tensor(0., device='cuda:0')\n",
      "43\n",
      "tensor(0., device='cuda:0')\n",
      "44\n",
      "tensor(0., device='cuda:0')\n",
      "45\n",
      "tensor(0., device='cuda:0')\n",
      "46\n",
      "tensor(0., device='cuda:0')\n",
      "47\n",
      "tensor(0., device='cuda:0')\n",
      "48\n",
      "tensor(0., device='cuda:0')\n",
      "49\n",
      "tensor(0., device='cuda:0')\n",
      "50\n",
      "tensor(0., device='cuda:0')\n",
      "51\n",
      "tensor(0., device='cuda:0')\n",
      "52\n",
      "tensor(0., device='cuda:0')\n",
      "53\n",
      "tensor(0., device='cuda:0')\n",
      "54\n",
      "tensor(0., device='cuda:0')\n",
      "55\n",
      "tensor(0., device='cuda:0')\n",
      "56\n",
      "tensor(0., device='cuda:0')\n",
      "57\n",
      "tensor(0., device='cuda:0')\n",
      "58\n",
      "tensor(0., device='cuda:0')\n",
      "59\n",
      "tensor(0., device='cuda:0')\n",
      "60\n",
      "tensor(0., device='cuda:0')\n",
      "61\n",
      "tensor(0., device='cuda:0')\n",
      "62\n",
      "tensor(0., device='cuda:0')\n",
      "63\n",
      "tensor(0., device='cuda:0')\n",
      "64\n",
      "tensor(0., device='cuda:0')\n",
      "65\n",
      "tensor(0., device='cuda:0')\n",
      "66\n",
      "tensor(0., device='cuda:0')\n",
      "67\n",
      "tensor(0., device='cuda:0')\n",
      "68\n",
      "tensor(0., device='cuda:0')\n",
      "69\n",
      "tensor(0., device='cuda:0')\n",
      "70\n",
      "tensor(0., device='cuda:0')\n",
      "71\n",
      "tensor(0., device='cuda:0')\n",
      "72\n",
      "tensor(0., device='cuda:0')\n",
      "73\n",
      "tensor(0., device='cuda:0')\n",
      "74\n",
      "tensor(0., device='cuda:0')\n",
      "75\n",
      "tensor(0., device='cuda:0')\n",
      "76\n",
      "tensor(0., device='cuda:0')\n",
      "77\n",
      "tensor(0., device='cuda:0')\n",
      "78\n",
      "tensor(0., device='cuda:0')\n",
      "79\n",
      "tensor(0., device='cuda:0')\n",
      "80\n",
      "tensor(0., device='cuda:0')\n",
      "81\n",
      "tensor(0., device='cuda:0')\n",
      "82\n",
      "tensor(0., device='cuda:0')\n",
      "83\n",
      "tensor(0., device='cuda:0')\n",
      "84\n",
      "tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(85):\n",
    "    print(i)\n",
    "    print(torch.dot(all_layer_gradients['layer11'][0].view(85,-1)[i], torch.tensor(cavs[6][1]).cuda() ) )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4c1cccef",
   "metadata": {},
   "source": [
    "Reference code from gradcam for backprop\n",
    "\n",
    "\n",
    "\n",
    "def gradCAM(\n",
    "    model: nn.Module,\n",
    "    input: torch.Tensor,\n",
    "    target: torch.Tensor,\n",
    "    layer: nn.Module\n",
    ") -> torch.Tensor:\n",
    "    # Zero out any gradients at the input.\n",
    "    if input.grad is not None:\n",
    "        input.grad.data.zero_()\n",
    "        \n",
    "    # Disable gradient settings.\n",
    "    requires_grad = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        requires_grad[name] = param.requires_grad\n",
    "        param.requires_grad_(False)\n",
    "        \n",
    "    # Attach a hook to the model at the desired layer.\n",
    "    assert isinstance(layer, nn.Module)\n",
    "    with Hook(layer) as hook:        \n",
    "        # Do a forward and backward pass.\n",
    "        output = model(input)\n",
    "        output.backward(target)\n",
    "\n",
    "        grad = hook.gradient.float()\n",
    "        act = hook.activation.float()\n",
    "    \n",
    "        # Global average pool gradient across spatial dimension\n",
    "        # to obtain importance weights.\n",
    "        alpha = grad.mean(dim=(2, 3), keepdim=True)\n",
    "        # Weighted combination of activation maps over channel\n",
    "        # dimension.\n",
    "        gradcam = torch.sum(act * alpha, dim=1, keepdim=True)\n",
    "        # We only want neurons with positive influence so we\n",
    "        # clamp any negative ones.\n",
    "        gradcam = torch.clamp(gradcam, min=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37233b85",
   "metadata": {},
   "source": [
    "You need labels to get gradients, to get a loss to backpropagate with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebda776",
   "metadata": {},
   "source": [
    "# Calculate TCAV score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e5e277ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = preprocess(Image.open('tcav/concepts/striped/striped_0086.jpg')).unsqueeze(0).to(device)\n",
    "image_features = model.encode_image(image.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "2295b480",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(image.cuda(), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "05d5c062",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.encode_image(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a32f1781",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward(torch.ones(1,1024).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "2496f7f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 512])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.visual.proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3ab68d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (maxreplearn)",
   "language": "python",
   "name": "maxreplearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
